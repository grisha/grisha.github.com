
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Grisha Trubetskoy</title>
  <meta name="author" content="Gregory Trubetskoy">

  
  <meta name="description" content="Back in my ISP days, we used data stored in RRDs to bill our
customers. I wouldn&#8217;t try this with Graphite. In this write up I try
to explain &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://grisha.org">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Grisha Trubetskoy" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-42971867-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Grisha Trubetskoy</a></h1>
  
    <h2>Notes to self.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:grisha.org" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/05/04/recording-time-series/">Time Series Accuracy - Graphite vs RRDTool</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-05-04T17:40:00-04:00" pubdate data-updated="true">May 4<span>th</span>, 2015</time>
        
         | <a href="/blog/2015/05/04/recording-time-series/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Back in my ISP days, we used data stored in RRDs to bill our
customers. I wouldn&#8217;t try this with Graphite. In this write up I try
to explain why it is so by comparing the method of recording time series
used by
<a href="http://graphite.readthedocs.org/en/latest/overview.html">Graphite</a>,
with the one used by <a href="https://oss.oetiker.ch/rrdtool/">RRDTool</a>.</p>

<p>Graphite uses
<a href="http://graphite.wikidot.com/whisper">Whisper</a> to store data, which in
the FAQ is portrayed as a <a href="http://graphite.wikidot.com/whisper#toc1">better alternative</a> to RRDTool, but
this is potentially misleading, because the flexibility afforded by the
design of Whisper comes at the price of inaccuracy.</p>

<p>A time series is most often described as a sequence of <code>(time, value)</code>
tuples [1]. The most naive method of recording a time series is to
store timestamps as is. Since the data points might arrive at
arbitrary and inexact intervals, to correlate the series with a
particular point in time might be tricky. If data points are arriving
somewhere in between one minute bounaries (as they always naturally
would), to answer the question of what happened during a particular
minute would require specifying a range, which is not as clean as
being able to specify a precise value. To join two series on a range
is even more problematic.</p>

<p>One way to improve upon this is to divide time into equal intervals
and assign data points to the intervals. We could then use the
beginning of the interval instead of the actual data point timestamp,
thereby giving us more uniformity. For example, if our interval size
is 10 seconds (I may sometimes refer to it as the <em>step</em>), we could
divide the entire timeline starting from the
<a href="http://en.wikipedia.org/wiki/Unix_time">beginning of the epoch</a>
and until the end of
universe into 10 second slots. Since the first slot begins at 0, any
10-second-step time series will have slots starting at the exact same
times. Now correlation across series or other time values becomes much
easier.</p>

<p>Calculating the slot is trivially easy: <code>time - time % step</code> (<code>%</code> being
the <a href="https://docs.python.org/3.4/reference/expressions.html#index-51">modulo operator</a>).
There is, however, a subtle complexity lurking when it comes to
storing the datapoint with the adjusted (or <em>aligned</em>) timestamp.
Graphite simply changes the timestamp of the data point to the
aligned one. If multiple data points arrive in the same
step, then the last one &#8220;wins&#8221;.</p>

<p>On the surface there is little wrong with Graphite&#8217;s approach. In fact,
under right circumstances, there is absolutely nothing wrong with
it. Consider the following example:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Graphite, 10 second step.
</span><span class='line'>
</span><span class='line'>Actual Time   Aligned Time
</span><span class='line'>1430701282    1430701280     50  &lt;-- This data point is lost
</span><span class='line'>1430701288    1430701280     10
</span><span class='line'>1430701293    1430701290     30
</span><span class='line'>1430701301    1430701300     30</span></code></pre></td></tr></table></div></figure>


<p>Let&#8217;s pretend those values are some system metric like the number of
files open. The consequnce of the 50 being dropped is that we will
never know it existed, but towards the end of the 10 second interval
it went down to 10, which is still a true fact. If we really wanted to
know about the variations within a 10 second interval, we should have
chosen a smaller step, e.g. 1 second. By deciding that the step is
going to be 10 seconds, we thus declared that <em>variations within a
smaller period are of no interest</em> to us, and from this perspective,
Graphite <em>is correct</em>.</p>

<p>But what if those numbers are the price of a stock. There may be
hundreds of thousand of trades within a 10 second interval, yet we do
not want to (or cannot, for technical reasons) record every single one
of them? In this scenario having the last value override all previous
ones doesn&#8217;t exactly seem correct.</p>

<p>Enter RRDTool which uses a different method. RRDTool keeps track of
the last timestamp and calculates a weight for every incoming
data point based on time since last update or beginning of the step and
the step length. Here is what the same sequence of points looks like
in RRDTool. The lines marked with a <code>*</code> are not actual data points,
but are the last value for the preceding step, it&#8217;s used for
computing the value for the remainder of the step after a new one has
begun.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>RRDTool, 10 second step.
</span><span class='line'>
</span><span class='line'>  Time          Value       Time since  Weight  Adjusted   Recorded
</span><span class='line'>                            last                value      value
</span><span class='line'>  1430701270    0           N/A
</span><span class='line'>* 1430701280    50         10s          1       50* 1= 50
</span><span class='line'>                                                           50
</span><span class='line'>  1430701282    50          2s          .2      50*.2= 10
</span><span class='line'>  1430701288    10          6s          .6      10*.6= 6
</span><span class='line'>* 1430701290    30          2s          .2      30*.2= 6
</span><span class='line'>                                                           10+6+6= 22
</span><span class='line'>  1430701293    30          3s          .3      30*.3= 9
</span><span class='line'>* 1430701300    30          7s          .7      30*.7= 21
</span><span class='line'>                                                           9+21=   30
</span><span class='line'>  1430701301    30   # this data point is incomplete</span></code></pre></td></tr></table></div></figure>


<p>Note, by the way, that the Whisper FAQ says that &#8220;RRD will store your
updates in a temporary workspace area and after the minute has passed,
aggregate them and store them in the archive&#8221;, which to me sounds like
there is some sort of a temporary storage area holding all the unsaved
updates. In fact, to be able to compute the weighted average, RRD only
needs to store the time of the last update and the current sum, i.e.
exactly just two variables, regardless of the number of updates in a
single step. This is evident from the above figure.</p>

<p>So to compare the results of the two tools:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Time Slot     Graphite    RRDTool
</span><span class='line'>1430701270       N/A        50
</span><span class='line'>1430701280       10         22
</span><span class='line'>1430701290       30         30
</span><span class='line'>1430701300       N/A        N/A
</span></code></pre></td></tr></table></div></figure>


<p>Before you say &#8220;so what, I don&#8217;t really understand the difference&#8221;,
let&#8217;s pretend that those numbers were actually the rate of sale of
trinkets from our website (per second). Here is a horizontal ascii-art
rendition of our timeline, 0 is 1430701270.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>0         10        20        30    time (seconds)
</span><span class='line'>+.........+.........+.........+.....
</span><span class='line'>|           |     |    |       |
</span><span class='line'>0           50    10   30      30   data points</span></code></pre></td></tr></table></div></figure>


<p>At 12 seconds we recorded selling 50 trinkets per second. Assuming we
started selling at the beginning of our timeline, i.e. 12 seconds
earlier, we can state that during the first step we sold exactly 500
trinkets. Then 2 seconds into the second step we sold another 100
(we&#8217;re still selling at 50/s). Then for the next 6 seconds we were
selling at 10/s, thus another 60 trinkets, and for the last 2 seconds
of the slot we sold another 60 at 30/s. In the third step we were
selling steadily at 30/s, thus exactly 300 were sold.</p>

<p>Comparing RRDTool and Graphite side-by-side, the stories are quite different:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Trinkets per second and sold:
</span><span class='line'>   Time Slot     Graphite Trinkets     RRDTool Trinkets
</span><span class='line'>1. 1430701270      N/A      N/A          50      500
</span><span class='line'>2. 1430701280       10      100          22      220 (100+60+60)
</span><span class='line'>3. 1430701290       30      300          30      300
</span><span class='line'>4. 1430701300       30      N/A          N/A     N/A
</span><span class='line'>                          -----                -----
</span><span class='line'>   TOTAL SOLD:              400                 1020
</span></code></pre></td></tr></table></div></figure>


<p>Two important observations here:</p>

<ol>
<li>The totals are vastly different.</li>
<li>The rate recorded by RRDTool for the second slot (22/s), yields
<em>exactly</em> the number of trinkets sold during that period: 220.</li>
</ol>


<p>Last, but hardly the least, consider what happens when we consolidate
data points into larger intervals by averaging the values. Let&#8217;s say
20 seconds, twice our step. If we consolidate the second and the third
steps, we would get:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Graphite:  average(10,30) = 20  =&gt; 400 trinkets in 20 seconds
</span><span class='line'>RRDTool:   average(22,30) = 26  =&gt; 520 trinkets in 20 seconds</span></code></pre></td></tr></table></div></figure>


<p>Since the Graphite numbers were off to begin with, we have no reason
to trust the 400 trinkets number. But using the RRDTool data, the new
number happens to still be 100% accurate even after the data points
have been consolidated. This is a very useful property of <em>rates</em> in
time series. It also explains why RRDTool does not permit updating
data prior to the last update: RRD is <em>always accurate</em>.</p>

<p>As an exercise, try seeing it for yourself: pretent the value of 10 in
the second step never arrived, which should make the final value of
the second slot 34. If the 10 arrived some time later, averaging it in
will not give you the correct 22.</p>

<p>Whisper allows past updates, but is quasi-accurate to begin with - I&#8217;m
not sure I understand which is better - <em>inaccurate</em> data with a data
point missing, or the <em>whole inaccurate</em> data. RRD could accomplish
the same thing by adding some <code>--inaccurate</code> flag, though it would
seem like more of a bug than a feature to me.</p>

<p>If you&#8217;re interested in learning more about this, I recommend reading
the documentation for
<a href="http://oss.oetiker.ch/rrdtool/doc/rrdcreate.en.html">rrdtool create</a>, in
particular the &#8220;It&#8217;s always a Rate&#8221; section, as well as
<a href="http://www.vandenbogaerdt.nl/rrdtool/process.php">this post</a>
by Alex van den Bogaerdt.</p>

<p>P.S. After this post was written, someone suggested that instead of
storing a rate, we coud store a <em>count delta</em>. In other words, instead
of recording that we&#8217;re selling 10 trinkets per second for the past 6
seconds, we would store the total count of trinkets sold, i.e. 60. At
first this seems like the solution to being able to update historical
data accurately: if later we found out that we sold another 75
trinkets in the second time slot, we could just add it to the total
and all would be well and most importantly <em>accurate</em>.</p>

<p>Here is the problem with this approach: note that in the previous
sentence I had to specify that the additional trinkets were sold <em>in
the second time slot</em>, a small, but crucial detail. If time series
data point is a timestamp and a value, then there isn&#8217;t even a way to
relay this information in a single data point - we&#8217;d need two
timestamps. On the other hand if every data point arrived with two
timestamps, i.e. as a duration, then which to store, rate or count,
becomes a moot point, we can infer one from the other.</p>

<p>So perhaps another way of explaining the historical update problem is
that it <em>is</em> possible, but the datapoint must specify a <em>time
interval</em>. This is something that neither RRDTool or Graphite
currently support, even though it&#8217;d be a very useful feature in my
opinion.</p>

<p>[1] Perhaps the biggest misconception about time series is that it is
a series of data points. What time series represent is <em>continuous</em>
rather than <em>descrete</em>, i.e. it&#8217;s the line that connects the points
that matters, not the specific points themselves, they are just
samples at semi-random intervals that help define the line. And as we
know, a line cannot be defined by a single point.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/03/28/on-time-series/">On Time Series</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-03-28T15:40:00-04:00" pubdate data-updated="true">Mar 28<span>th</span>, 2015</time>
        
         | <a href="/blog/2015/03/28/on-time-series/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>Is it even a thing?</h2>

<p>Time Series is on its way to becoming a buzzword in the Information
Technology circles. This has to do with the looming Internet of Things
which shall cause the Great Reversal of Internet whereby upstream flow
of data produced by said Things is expected to exceed the downstream
flow. Much of this data is expected to be of the Time Series kind.</p>

<p>This, of course, is a money-making opportunity of the Big Data
proportions all over again, and I predict we&#8217;re going to see a lot of
Time Series support of various shapes and forms appearing in all
manners of (mostly commercial) software.</p>

<p>But is there really such a thing as the problem specifically inherent
to Time Series data which warrants a specialized solution? I&#8217;ve been
pondering this for some time now, and I am still undecided. This
here is my attempt at arguing that TS is <em>not</em> a special problem and
that it can be done by using a database like PostgreSQL.</p>

<h2>Influx of data and write speeds</h2>

<p>One frequently cited issue with time series data is that it arrives in
large volumes at a steady pace which renders buffered writes
useless. The number of incoming data streams can also be large
typically causing a disk seek per stream and further complicating the
write situation. TS data also has a property where often more data is
written than read because it&#8217;s possible for a datapoint to be
collected and examined only once, if ever. In short, TS is very
write-heavy.</p>

<p>But is this unique? For example logs have almost identical
properties. The real question here is whether our tried and true
databases such as PostgreSQL are ill-equipped to deal with large
volumes of incoming data requiring an alternative solution.</p>

<p>When considering incoming data I am tempted to imagine every US
household sending it, which, of course, would require massive
infrastructure. But this (unrealistic) scenario is not a TS data
problem, it&#8217;s one of scale, the same one from which the Hadoops and
Cassandras of this world were born. What is really happening here is
that TS happens to be yet another thing that requires the difficult to
deal with &#8220;big data&#8221; infrastructure and reiterates the need for an
easy-to-setup horizontally scalable database (which PostgreSQL isn&#8217;t).</p>

<h2>The backfill problem</h2>

<p>This is the problem of having to import vast amounts of historical
data. For example OpenTSDB goes to great lengths to optimize
back-filling by structuring it in specific ways and storing compressed
blobs of data.</p>

<p>But just like the write problem, it&#8217;s not unique to TS. It
is another problem that is becoming more and more pertinent as our
backlogs of data going back to when we stopped using paper keep
growing and growing.</p>

<h2>Downsampling</h2>

<p>Very often TS data is used to generate charts. This is an artifact of
the human brain being spectacularly good at interpreting a visual
representation of a relationship between streams of numbers while
nearly incapable of making sense of data in tabular form. When
plotting, no matter how much data is being examined, the end result is
limited to however many pixels are available on the display. Even
plotting aside, most any use of time series data is in an aggregated
form.</p>

<p>The process of consolidating datapoints into a smaller number (e.g.
the pixel width of the chart), sometimes called <em>downsampling</em>, involves
aggregation around a particular time interval or simply picking every
Nth datapoint.</p>

<p>As an aside, selecting every Nth row of a table is an interesting SQL
challenge, in PostgreSQL it looks like this (for every 100th row):</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> SELECT time, data FROM
</span><span class='line'>   (SELECT *, row_number() OVER (ORDER BY time) as n FROM data_points) dp
</span><span class='line'>      WHERE dp.n % 100 = 0 ORDER BY time</span></code></pre></td></tr></table></div></figure>


<p>Aggregation over a time interval similar to how InfluxDB does it with
the <code>GROUP BY time(1d)</code> syntax can be easily achieved via the
<code>date_trunc('day', time)</code>.</p>

<p>Another aspect of downsampling is that since TS data is immutable,
there is no need to repeatedly recompute the consolidated version. It
makes more sense to downsample immediately upon the receipt of the
data and to store it permanently in this form. RRDTool&#8217;s Round-Robin
database is based entirely on this notion. InfluxDB&#8217;s continuous
queries is another way persistent downsampling is addressed.</p>

<p>Again, there is nothing TS-specific here. Storing data in summary form
is quite common in the data analytics world and a &#8220;continuous query&#8221;
is easily implemented via a trigger.</p>

<h2>Derivatives</h2>

<p>Sometimes the data from various devices exists in the form of a
counter, which requires the database to derive a rate by comparing
with a previous datapoint. An example of this is number of bytes sent
over a network interface. Only the rate of change of this value is
relevant, not the number itself. The rate of change is the difference
with the previous value divided over the time interval passed.</p>

<p>Referring to a previous row is also a bit tricky but perfectly doable
in SQL. It can accomplished by using windowing functions such as
<code>lag()</code>.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>SELECT time,
</span><span class='line'>  (bytes - lag(bytes, 1) OVER w) / extract(epoch from (time - lag(time, 1) OVER w))::numeric
</span><span class='line'>    AS bytes_per_sec
</span><span class='line'>  FROM data_points
</span><span class='line'>  WINDOW w AS (ORDER BY time)
</span><span class='line'>  ORDER BY time</span></code></pre></td></tr></table></div></figure>


<h2>Expiration</h2>

<p>It is useful to downsample data to a less granular form as it ages,
aggregating over an ever larger period of time and possibly purging
records eventually. For example we might want to store minutely data
for a week, hourly for 3 months, daily for 3 years and drop all data
beyond 3 years.</p>

<p>Databases do not expire rows &#8220;natively&#8221; like Cassandra or Redis, but it
shouldn&#8217;t be too hard to accomplish via some sort of a periodic cron
job or possibly even just triggers.</p>

<h2>Heartbeat and Interval Filling</h2>

<p>It is possible for a time series stream to pause, and this can be
interpreted in different ways: we can attempt to fill in missing data,
or treat it as unknown. More likely we&#8217;d want to start treating it as
unknown after some period of silence. RRDTool addresses this by
introducing the notion of a <em>heartbeat</em> and the number of missed beats
before data is treated as unknown.</p>

<p>Regardless of whether the value is unknown, it is useful to be able to
fill in a gap (missing rows) in data. In PostgreSQL this can be
accomplished by a join with a result set from the <code>generate_series()</code>
function.</p>

<h2>Data Seclusion</h2>

<p>With many specialized Time Series tools the TS data ends up being
secluded in a separate system not easily accessible from the rest of
the business data. You cannot join your customer records with data in
RRDTool or Graphite or InfluxDB, etc.</p>

<h2>Conclusion</h2>

<p>If there is a problem with using PosgreSQL or some other database for
Time Series data, it is mainly that of having to use advanced SQL
syntax and possibly requiring some cookie-cutter method for managing
Time Series, especially when it is a large number or series and high
volume.</p>

<p>There is also complexity in horizontally scaling a relational database
because it involves setting up replication, sharding, methods for
recovery from failure and balancing the data. But these are not
TS-specific problems, they are scaling problems.</p>

<p>Having written this up, I&#8217;m inclined to think that perhaps there is
no need for a specialized &#8220;Time Series Database&#8221;, instead it can be
accomplished by an application which uses a database for storage and
abstracts the users from the complexities of SQL and potentially even
scaling, while still allowing for direct access to the data via the
rich set of tools that a database like PostgreSQL provides.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/03/20/influxdb-data/">How InfluxDB Stores Data</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-03-20T15:52:00-04:00" pubdate data-updated="true">Mar 20<span>th</span>, 2015</time>
        
         | <a href="/blog/2015/03/20/influxdb-data/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>A nice, reliable, horizontally scalable database that is designed
specifically to tackle the problem of Time Series data (and does not
require you to stand up a Hadoop cluster) is very much missing from the
Open Source Universe right now.</p>

<p><a href="https://github.com/influxdb/influxdb">InfluxDB</a> might be able to fill this gap, it certainly aims to.</p>

<p>I was curious about how it structures and stores data and since there
wasn&#8217;t much documentation on the subject and I ended up just reading
the code, I figured I&#8217;d write this up. I only looked at the new
(currently 0.9.0 in RC stage) version, the previous versions are
significantly different.</p>

<p>First of all, InfluxDB is distributed. You can run one node, or a
bunch, it seems like a more typical number may be 3 or 5. The nodes
use <a href="https://github.com/goraft/raft">Raft</a> to establish consensus and maintain data consistency.</p>

<p>InfluxDB feels a little like a relational database in some aspects
(e.g. it has a SQL-like query language) but not in others.</p>

<p>The top level container is a <em>database</em>. An InfluxDB database is very
much like what a database is in MySQL, it&#8217;s a collection of other
things.</p>

<p>&#8220;Other things&#8221; are called <em>data points</em>, <em>series</em>, <em>measurements</em>,
<em>tags</em> and <em>retention policies</em>. Under the hood (i.e. you never deal
with them directly) there are <em>shards</em> and <em>shard groups</em>.</p>

<p>The very first thing you need to do in InfluxDB is create a database
and at least one retention policy for this database. Once you have
these two things, you can start writing data.</p>

<p>A retention policy is the time period after which the data expires. It
can be set to be infinite. A data point, which is a measurement
consisting of any number of values and tags associated with a
particular point in time, must be associated with a database and a
retention policy. A retention policy also specifies the <em>replication
factor</em> for the data point.</p>

<p>Let&#8217;s say we are tracking disk usage across a whole bunch of
servers. Each server runs some sort of an agent which periodically
reports the usage of each disk to InfluxDB. Such a report might look
like this (in JSON):</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{"database" : "foo", "retentionPolicy" : "bar",
</span><span class='line'> "points" : [
</span><span class='line'>   {"name" : "disk",
</span><span class='line'>    "tags" : {"server" : "bwi23", "unit" : "1"},
</span><span class='line'>    "timestamp" : "2015-03-16T01:02:26.234Z",
</span><span class='line'>    "fields" : {"total" : 100, "used" : 40, "free" : 60}}]}</span></code></pre></td></tr></table></div></figure>


<p>In the above example, &#8220;disk&#8221; is a measurement. Thus we can operate on
anything &#8220;disk&#8221;, regardless of what &#8220;server&#8221; or &#8220;unit&#8221; it applies
to. The data point as a whole belongs to a (time) series identified by
the combination of the measurement name and the tags.</p>

<p>There is no need to create series or measurements, they are created on
the fly.</p>

<p>To list the measurements, we can use <code>SHOW MEASUREMENTS</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; show measurements
</span><span class='line'>name            tags    name
</span><span class='line'>----            ----    ----
</span><span class='line'>measurements            disk</span></code></pre></td></tr></table></div></figure>


<p>We can use <code>SHOW SERIES</code> to list the series:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; show series
</span><span class='line'>name    tags    id      server   unit
</span><span class='line'>----    ----    --      -------  ----
</span><span class='line'>disk            1       bw123    1</span></code></pre></td></tr></table></div></figure>


<p>If we send a record that contains different tags, we automatically
create a different series (or so it seems), for example if we send
this (note we changed &#8220;unit&#8221; to &#8220;foo&#8221;):</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{"database" : "foo", "retentionPolicy" : "bar",
</span><span class='line'> "points" : [
</span><span class='line'>   {"name" : "disk",
</span><span class='line'>    "tags" : {"server" : "bwi23", "foo" : "bar"},
</span><span class='line'>    "timestamp" : "2015-03-16T01:02:26.234Z",
</span><span class='line'>    "fields" : {"total" : 100, "used" : 40, "free" : 60}}]}</span></code></pre></td></tr></table></div></figure>


<p>we get</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; show series
</span><span class='line'>name    tags    id      foo     server  unit
</span><span class='line'>----    ----    --      ---     ------  ----
</span><span class='line'>disk            1               bwi23   1
</span><span class='line'>disk            2       bar     bwi23</span></code></pre></td></tr></table></div></figure>


<p>This is where the distinction between measurement and series becomes a
little confusing to me. In actuality (from looking at the code and the
actual files InfluxDB created) there is only one series here called
&#8220;disk&#8221;. I understand the intent, but not sure that <em>series</em> is the
right terminology here. I think I&#8217;d prefer if measurements were simply
called series, and to get the equivalent of <code>SHOW SERIES</code> you&#8217;d use
something like <code>SHOW SERIES TAGS</code>. (May be I&#8217;m missing something.)</p>

<p>Under the hood the data is stored in shards, which are grouped by
shard groups, which in turn are grouped by retention policies, and
finally databases.</p>

<p>A database contains one or more retention policies. Somewhat
surprisingly a retention policy is actually a bucket. It makes sense
if you think about the problem of having to expire data points - you
can remove them all by simply dropping the entire bucket.</p>

<p>If we declare a retention policy of 1 day, then we can logically
divide the timeline into a sequence of single days from beginning of
the epoch. Any incoming data point falls into its corresponding
segment, which is a retention policy bucket. When clean up time comes
around, we can delete all days except for the most current day.</p>

<p>To better understand the following paragraphs, consider that having
multiple nodes provides the option for two things: <em>redundancy</em> and
<em>distribution</em>. Redundancy gives you the ability to lose a node
without losing any data. The number of copies of the data is
controlled by the replication factor specified as part of the
retention policy. Distribution spreads the data across nodes which
allows for concurrency: data can be written, read and processed in
parallel. For example if we become constrained by write performance,
we can solve this by simply adding more nodes. InfluxDB favors
redundancy over distribution when having to choose between the two.</p>

<p>Each retention policy bucket is further divided into shard groups, one
shard group per series. The purpose of a shard group is to balance
series data across the nodes of the cluster. If we have a cluster of 3
nodes, we want the data points to be evenly distributed across these
nodes. InfluxDB will create 3 shards, one on each of the nodes. The 3
shards comprise the shard group. This is assuming the replication
factor is 1.</p>

<p>But if the replication factor was 2, then there needs to be 2
identical copies of every shard. The shard copies must be on separate
nodes. With 3 nodes and replication factor of 2, it is impossible to
do any distribution across the nodes - the shard group will have a
size of 1, and contain 1 shard, replicated across 2 nodes. In this set
up, the third node will have no data for this particular retention
policy.</p>

<p>If we had a cluster of 5 nodes and the replication factor of 2, then
the shard group can have a size of 2, for 2 shards, replicated across
2 nodes each. Shard one replicas could live on nodes 1 and 3, while
shard two replicas on nodes 2 and 4. Now the data is distributed as
well as redundant. Note that the 5th node doesn&#8217;t do anything. If we
up the replication factor to 3 then just like before, the cluster is
too small to have any distribution, we only have enough nodes for
redundancy.</p>

<p>As of RC15 distributed queries are not yet implemented, so you will
always get an error if you have more than one shard in a group.</p>

<p>The shards themselves are instances of <a href="https://github.com/boltdb/bolt">Bolt db</a> - a simple to use key/value store
written in Go. There is also a separate Bolt db file called meta which
stores the metadata, i.e. information about databases, retention
policies, measurements, series, etc.</p>

<p>I couldn&#8217;t quite figure out the process for typical cluster operations
such as recovery from node failure or what happens (or should happen)
when nodes are added to existing cluster, whether there is a way to
decommission a node or re-balance the cluster similar to the Hadoop
balancer, etc. I think as of this writing this has not been fully
implemented yet, and there is no documentation, but hopefully it&#8217;s
coming soon.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/08/19/ruby_hiveserver2_and_kerberos/">Ruby, HiveServer2 and Kerberos</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-08-19T08:03:00-04:00" pubdate data-updated="true">Aug 19<span>th</span>, 2014</time>
        
         | <a href="/blog/2014/08/19/ruby_hiveserver2_and_kerberos/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Recently I found myself needing to connect to HiveServer2 with
Kerberos authentication enabled from a Ruby app. As it turned out
<a href="https://github.com/forward3d/rbhive">rbhive gem</a> we were using did not have
support for Kerberos authentication. So I had to
<a href="https://github.com/forward3d/rbhive/pull/23">roll my own</a>.</p>

<p>This post is to document the experience of figuring out the details of
a SASL/GSSAPI connection before it is lost forever in my neurons and synapses.</p>

<p>First, the terminology. The authentication system that Hadoop uses is
<em>Kerberos</em>. Note that <a href="http://www.ietf.org/rfc/rfc4120.txt">Kerberos</a> is not a
network protocol. It describes the method by which
authentication happens, but not the format of how to send Kerberos
tickets and what not over the wire. For that, you need <em>SASL</em> and
<em>GSSAPI</em>.</p>

<p><a href="http://tools.ietf.org/html/rfc2222">SASL</a> is a generic protocol
designed to be able to wrap just about any authentication
handshake. It&#8217;s very simple: the client sends a START followed by some
payload, and expects an OK, BAD or COMPLETE from the server. OK means
that there are more steps to this conversation, BAD is
self-explanatory and COMPLETE means &#8220;I&#8217;m satisfied&#8221;. The objective is
to go from START via a series of OK&#8217;s to each side sending the other a
COMPLETE.</p>

<p>SASL doesn&#8217;t define the payload of each message. The payload is
specified by <a href="http://tools.ietf.org/html/rfc2743">GSSAPI</a>
protocol. GSSAPI is another generic protocol. Unlike SASL it is
actually very complex and covers a variety of authentication methods,
including Kerberos.</p>

<p>The combination of SASL and GSSAPI and what happens at the network
layer is documented in
<a href="http://tools.ietf.org/html/rfc4752">RFC4752</a>.</p>

<p>Bottom line is you need to read at least four RFC&#8217;s to be able to
understand every detail of this process:
<a href="http://tools.ietf.org/html/rfc4120">RFC4120</a>,
<a href="http://tools.ietf.org/html/rfc2222">RFC2222</a>,
<a href="http://tools.ietf.org/html/rfc2743">RFC2743</a> and
<a href="http://tools.ietf.org/html/rfc4752">RFC4752</a>. Fun!</p>

<h2>The Handshake in Ruby</h2>

<p>First, you&#8217;ll need some form of binding to the GSSAPI libraries. I&#8217;ve
been using the most excellent <a href="https://github.com/zenchild/gssapi">GSSAPI gem</a>
by <a href="http://distributed-frostbite.blogspot.ru/">Dan Wanek</a> which wraps the MIT GSSAPI library.</p>

<p>If you follow the code in
<a href="https://github.com/grisha/rbhive/blob/gssapi/lib/thrift/sasl_client_transport.rb">sasl_client_transport.rb</a>,
you&#8217;ll see the following steps are required to establish a connection.</p>

<p>First, we instantiate a GSSAPI object passing it the remote host and
the remote principal. Note that there is no TCP port number to be
specifies anywhere, because this isn&#8217;t to establish a TCP connection,
but only for Kerberos <em>host authentication</em>. (Kerberos requires that
not only the client authenticates itself to the host, but also that
the host authenticates itself to the client.)</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="c1"># Thrift::SaslClientTransport.initialize()</span>
</span><span class='line'><span class="vi">@gsscli</span> <span class="o">=</span> <span class="ss">GSSAPI</span><span class="p">:</span><span class="ss">:Simple</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="vi">@sasl_remote_host</span><span class="p">,</span> <span class="vi">@sasl_remote_principal</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>The rest of the action takes place in the
<code>initiate_hand_shake_gssapi()</code> method.</p>

<p>First, we call <code>@gsscli.init_context()</code> with no arguments. This call
creates a token based on our current Kerberos credentials. (If there
are no credentials in our cache, this call will fail).</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'>  <span class="n">token</span> <span class="o">=</span> <span class="vi">@gsscli</span><span class="o">.</span><span class="n">init_context</span>
</span></code></pre></td></tr></table></div></figure>


<p>Next we compose a SASL message which consists of START (0x01)
followed by payload length, followed by the actual payload, which is
the SASL mechanism name: &#8216;GSSAPI&#8217;. Without waiting for response, we
also send an OK (0x02) and the token returned from init_context().</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'>  <span class="n">header</span> <span class="o">=</span> <span class="o">[</span><span class="no">NEGOTIATION_STATUS</span><span class="o">[</span><span class="ss">:START</span><span class="o">]</span><span class="p">,</span> <span class="vi">@sasl_mechanism</span><span class="o">.</span><span class="n">length</span><span class="o">].</span><span class="n">pack</span><span class="p">(</span><span class="s1">&#39;cl&gt;&#39;</span><span class="p">)</span>
</span><span class='line'>  <span class="vi">@transport</span><span class="o">.</span><span class="n">write</span> <span class="n">header</span> <span class="o">+</span> <span class="vi">@sasl_mechanism</span>
</span><span class='line'>  <span class="n">header</span> <span class="o">=</span> <span class="o">[</span><span class="no">NEGOTIATION_STATUS</span><span class="o">[</span><span class="ss">:OK</span><span class="o">]</span><span class="p">,</span> <span class="n">token</span><span class="o">.</span><span class="n">length</span><span class="o">].</span><span class="n">pack</span><span class="p">(</span><span class="s1">&#39;cl&gt;&#39;</span><span class="p">)</span>
</span><span class='line'>  <span class="vi">@transport</span><span class="o">.</span><span class="n">write</span> <span class="n">header</span> <span class="o">+</span> <span class="n">token</span>
</span><span class='line'>  <span class="n">status</span><span class="p">,</span> <span class="n">len</span> <span class="o">=</span> <span class="vi">@transport</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="no">STATUS_BYTES</span> <span class="o">+</span> <span class="no">PAYLOAD_LENGTH_BYTES</span><span class="p">)</span><span class="o">.</span><span class="n">unpack</span><span class="p">(</span><span class="s1">&#39;cl&gt;&#39;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Next we read 5 bytes of response. The first byte is the status
returned from the server, which hopefully is OK, followed by the
length of the payload, and then we read the payload itself:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'>  <span class="n">status</span><span class="p">,</span> <span class="n">len</span> <span class="o">=</span> <span class="vi">@transport</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="no">STATUS_BYTES</span> <span class="o">+</span> <span class="no">PAYLOAD_LENGTH_BYTES</span><span class="p">)</span><span class="o">.</span><span class="n">unpack</span><span class="p">(</span><span class="s1">&#39;cl&gt;&#39;</span><span class="p">)</span>
</span><span class='line'>  <span class="k">case</span> <span class="n">status</span>
</span><span class='line'>  <span class="k">when</span> <span class="no">NEGOTIATION_STATUS</span><span class="o">[</span><span class="ss">:BAD</span><span class="o">]</span><span class="p">,</span> <span class="no">NEGOTIATION_STATUS</span><span class="o">[</span><span class="ss">:ERROR</span><span class="o">]</span>
</span><span class='line'>    <span class="k">raise</span> <span class="vi">@transport</span><span class="o">.</span><span class="n">to_io</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">len</span><span class="p">)</span>
</span><span class='line'>  <span class="k">when</span> <span class="no">NEGOTIATION_STATUS</span><span class="o">[</span><span class="ss">:COMPLETE</span><span class="o">]</span>
</span><span class='line'>    <span class="k">raise</span> <span class="s2">&quot;Not expecting COMPLETE at initial stage&quot;</span>
</span><span class='line'>  <span class="k">when</span> <span class="no">NEGOTIATION_STATUS</span><span class="o">[</span><span class="ss">:OK</span><span class="o">]</span>
</span><span class='line'>    <span class="n">challenge</span> <span class="o">=</span> <span class="vi">@transport</span><span class="o">.</span><span class="n">to_io</span><span class="o">.</span><span class="n">read</span> <span class="n">len</span>
</span></code></pre></td></tr></table></div></figure>


<p>The payload is a <em>challenge</em> created for us by the server. We can
verify this challenge by calling <code>init_context()</code> a second time, this
time passing in the challenge to verify it:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'>    <span class="n">challenge</span> <span class="o">=</span> <span class="vi">@transport</span><span class="o">.</span><span class="n">to_io</span><span class="o">.</span><span class="n">read</span> <span class="n">len</span>
</span><span class='line'>    <span class="k">unless</span> <span class="vi">@gsscli</span><span class="o">.</span><span class="n">init_context</span><span class="p">(</span><span class="n">challenge</span><span class="p">)</span>
</span><span class='line'>      <span class="k">raise</span> <span class="s2">&quot;GSSAPI: challenge provided by server could not be verified&quot;</span>
</span><span class='line'>    <span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>


<p>If the challenge verifies, then it is our turn to send an OK (with an
empty payload this time):</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'>    <span class="n">header</span> <span class="o">=</span> <span class="o">[</span><span class="no">NEGOTIATION_STATUS</span><span class="o">[</span><span class="ss">:OK</span><span class="o">]</span><span class="p">,</span> <span class="mi">0</span><span class="o">].</span><span class="n">pack</span><span class="p">(</span><span class="s1">&#39;cl&gt;&#39;</span><span class="p">)</span>
</span><span class='line'>    <span class="vi">@transport</span><span class="o">.</span><span class="n">write</span> <span class="n">header</span>
</span></code></pre></td></tr></table></div></figure>


<p>At this point in the SASL &#8216;conversation&#8217; we have verified that the
server is who they claim to be.</p>

<p>Next the server sends us another challenge, this one is so that we can
authenticate ourselves to the server and at the same time agree on the
<em>protection level</em> for the communication channel.</p>

<p>We need to decrypt (&#8220;unwrap&#8221; in the GSSAPI terminology) the challenge,
examine the protection level and if it is acceptable, encrypt it on
our side and send it back to the server in a SASL COMPLETE message. In
this particular case we&#8217;re agreeable to any level of protection (which
is none in case of HiveServer2, i.e. the conversation is not
encrypted). Otherwise there are additional steps that RFC4752
describes whereby the client can select an acceptable protection
level.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'>    <span class="n">status2</span><span class="p">,</span> <span class="n">len</span> <span class="o">=</span> <span class="vi">@transport</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="no">STATUS_BYTES</span> <span class="o">+</span> <span class="no">PAYLOAD_LENGTH_BYTES</span><span class="p">)</span><span class="o">.</span><span class="n">unpack</span><span class="p">(</span><span class="s1">&#39;cl&gt;&#39;</span><span class="p">)</span>
</span><span class='line'>    <span class="k">case</span> <span class="n">status2</span>
</span><span class='line'>    <span class="k">when</span> <span class="no">NEGOTIATION_STATUS</span><span class="o">[</span><span class="ss">:BAD</span><span class="o">]</span><span class="p">,</span> <span class="no">NEGOTIATION_STATUS</span><span class="o">[</span><span class="ss">:ERROR</span><span class="o">]</span>
</span><span class='line'>      <span class="k">raise</span> <span class="vi">@transport</span><span class="o">.</span><span class="n">to_io</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">len</span><span class="p">)</span>
</span><span class='line'>    <span class="k">when</span> <span class="no">NEGOTIATION_STATUS</span><span class="o">[</span><span class="ss">:COMPLETE</span><span class="o">]</span>
</span><span class='line'>      <span class="k">raise</span> <span class="s2">&quot;Not expecting COMPLETE at second stage&quot;</span>
</span><span class='line'>    <span class="k">when</span> <span class="no">NEGOTIATION_STATUS</span><span class="o">[</span><span class="ss">:OK</span><span class="o">]</span>
</span><span class='line'>      <span class="n">challenge</span> <span class="o">=</span> <span class="vi">@transport</span><span class="o">.</span><span class="n">to_io</span><span class="o">.</span><span class="n">read</span> <span class="n">len</span>
</span><span class='line'>      <span class="n">unwrapped</span> <span class="o">=</span> <span class="vi">@gsscli</span><span class="o">.</span><span class="n">unwrap_message</span><span class="p">(</span><span class="n">challenge</span><span class="p">)</span>
</span><span class='line'>      <span class="n">rewrapped</span> <span class="o">=</span> <span class="vi">@gsscli</span><span class="o">.</span><span class="n">wrap_message</span><span class="p">(</span><span class="n">unwrapped</span><span class="p">)</span>
</span><span class='line'>      <span class="n">header</span> <span class="o">=</span> <span class="o">[</span><span class="no">NEGOTIATION_STATUS</span><span class="o">[</span><span class="ss">:COMPLETE</span><span class="o">]</span><span class="p">,</span> <span class="n">rewrapped</span><span class="o">.</span><span class="n">length</span><span class="o">].</span><span class="n">pack</span><span class="p">(</span><span class="s1">&#39;cl&gt;&#39;</span><span class="p">)</span>
</span><span class='line'>      <span class="vi">@transport</span><span class="o">.</span><span class="n">write</span> <span class="n">header</span> <span class="o">+</span> <span class="n">rewrapped</span>
</span></code></pre></td></tr></table></div></figure>


<p>The server should then respond with COMPLETE as well, at which point
we&#8217;re done with the authentication process and cat start sending
whatever we want over this connection:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'>      <span class="n">status3</span><span class="p">,</span> <span class="n">len</span> <span class="o">=</span> <span class="vi">@transport</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="no">STATUS_BYTES</span> <span class="o">+</span> <span class="no">PAYLOAD_LENGTH_BYTES</span><span class="p">)</span><span class="o">.</span><span class="n">unpack</span><span class="p">(</span><span class="s1">&#39;cl&gt;&#39;</span><span class="p">)</span>
</span><span class='line'>      <span class="k">case</span> <span class="n">status3</span>
</span><span class='line'>      <span class="k">when</span> <span class="no">NEGOTIATION_STATUS</span><span class="o">[</span><span class="ss">:BAD</span><span class="o">]</span><span class="p">,</span> <span class="no">NEGOTIATION_STATUS</span><span class="o">[</span><span class="ss">:ERROR</span><span class="o">]</span>
</span><span class='line'>        <span class="k">raise</span> <span class="vi">@transport</span><span class="o">.</span><span class="n">to_io</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">len</span><span class="p">)</span>
</span><span class='line'>      <span class="k">when</span> <span class="no">NEGOTIATION_STATUS</span><span class="o">[</span><span class="ss">:COMPLETE</span><span class="o">]</span>
</span><span class='line'>        <span class="vi">@transport</span><span class="o">.</span><span class="n">to_io</span><span class="o">.</span><span class="n">read</span> <span class="n">len</span>
</span><span class='line'>        <span class="vi">@sasl_complete</span> <span class="o">=</span> <span class="kp">true</span>
</span><span class='line'>      <span class="k">when</span> <span class="no">NEGOTIATION_STATUS</span><span class="o">[</span><span class="ss">:OK</span><span class="o">]</span>
</span><span class='line'>        <span class="k">raise</span> <span class="s2">&quot;Failed to complete GSS challenge exchange&quot;</span>
</span><span class='line'>      <span class="k">end</span>
</span></code></pre></td></tr></table></div></figure>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/06/03/graceful-restart-in-golang/">Graceful Restart in Golang</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-06-03T12:49:00-04:00" pubdate data-updated="true">Jun 3<span>rd</span>, 2014</time>
        
         | <a href="/blog/2014/06/03/graceful-restart-in-golang/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Update (Apr 2015): <a href="https://github.com/fvbock">Florian von Bock</a> has
turned what is described in this article into a nice Go package called
<a href="https://github.com/fvbock/endless">endless</a>.</p>

<p>If you have a Golang HTTP service, chances are, you will need to restart it
on occasion to upgrade the binary or change some configuration. And if
you (like me) have been taking graceful restart for granted because
the webserver took care of it, you may find this recipe very handy
because with Golang you need to roll your own.</p>

<p>There are actually two problems that need to be solved here. First is
the UNIX side of the graceful restart, i.e. the mechanism by which a
process can restart itself without closing the listening socket. The
second problem is ensuring that all in-progress requests are properly
completed or timed-out.</p>

<h2>Restarting without closing the socket</h2>

<ul>
<li>Fork a new process which inherits the listening socket.</li>
<li>The child performs initialization and starts accepting connections on
the socket.</li>
<li>Immediately after, child sends a signal to the parent causing the
parent to stop accepting connecitons and terminate.</li>
</ul>


<h3>Forking a new process</h3>

<p>There is more than one way to fork a process using the Golang lib, but
for this particular case
<a href="http://golang.org/pkg/os/exec/#Command">exec.Command</a> is the way to
go. This is because the <a href="http://golang.org/pkg/os/exec/#Cmd">Cmd struct</a> this function returns has
this <code>ExtraFiles</code> member, which specifies open files (in addition to
stdin/err/out) to be inherited by new process.</p>

<p>Here is what this looks like:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='go'><span class='line'><span class="nx">file</span> <span class="o">:=</span> <span class="nx">netListener</span><span class="p">.</span><span class="nx">File</span><span class="p">()</span> <span class="c1">// this returns a Dup()</span>
</span><span class='line'><span class="nx">path</span> <span class="o">:=</span> <span class="s">&quot;/path/to/executable&quot;</span>
</span><span class='line'><span class="nx">args</span> <span class="o">:=</span> <span class="p">[]</span><span class="kt">string</span><span class="p">{</span>
</span><span class='line'>    <span class="s">&quot;-graceful&quot;</span><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="nx">cmd</span> <span class="o">:=</span> <span class="nx">exec</span><span class="p">.</span><span class="nx">Command</span><span class="p">(</span><span class="nx">path</span><span class="p">,</span> <span class="nx">args</span><span class="o">...</span><span class="p">)</span>
</span><span class='line'><span class="nx">cmd</span><span class="p">.</span><span class="nx">Stdout</span> <span class="p">=</span> <span class="nx">os</span><span class="p">.</span><span class="nx">Stdout</span>
</span><span class='line'><span class="nx">cmd</span><span class="p">.</span><span class="nx">Stderr</span> <span class="p">=</span> <span class="nx">os</span><span class="p">.</span><span class="nx">Stderr</span>
</span><span class='line'><span class="nx">cmd</span><span class="p">.</span><span class="nx">ExtraFiles</span> <span class="p">=</span> <span class="p">[]</span><span class="o">*</span><span class="nx">os</span><span class="p">.</span><span class="nx">File</span><span class="p">{</span><span class="nx">file</span><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="nx">err</span> <span class="o">:=</span> <span class="nx">cmd</span><span class="p">.</span><span class="nx">Start</span><span class="p">()</span>
</span><span class='line'><span class="k">if</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">log</span><span class="p">.</span><span class="nx">Fatalf</span><span class="p">(</span><span class="s">&quot;gracefulRestart: Failed to launch, error: %v&quot;</span><span class="p">,</span> <span class="nx">err</span><span class="p">)</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>In the above code <code>netListener</code> is a pointer to
<a href="http://golang.org/pkg/net/#Listener">net.Listener</a> listening for HTTP
requests. The <code>path</code> variable should contain the path to the new
executable if you&#8217;re upgrading (which may be the same as the currently
running one).</p>

<p>An important point in the above code is that <code>netListener.File()</code>
returns a
<a href="http://pubs.opengroup.org/onlinepubs/009695399/functions/dup.html">dup(2)</a>
of the file descriptor. The duplicated file descriptor will not have
the <a href="http://pubs.opengroup.org/onlinepubs/009695399/functions/fcntl.html"><code>FD_CLOEXEC</code> flag</a> set,
which would cause the file to be closed in the child (not what we want).</p>

<p>You may come across examples that pass the inherited file descriptor
number to the child via a command line argument, but the way
<code>ExtraFiles</code> is implemented makes it unnecessary. The documentation
states that &#8220;If non-nil, entry i becomes file descriptor 3+i.&#8221; This
means that in the above code snippet, the inherited file descriptor in
the child will always be 3, thus no need to explicitely pass it.</p>

<p>Finally, <code>args</code> array contains a <code>-graceful</code> option: your program will
need some way of informing the child that this is a part of a graceful
restart and the child should re-use the socket rather than try opening
a new one. Another way to do this might be via an environment
variable.</p>

<h3>Child initialization</h3>

<p>Here is part of the program startup sequence</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='go'><span class='line'>    <span class="nx">server</span> <span class="o">:=</span> <span class="o">&amp;</span><span class="nx">http</span><span class="p">.</span><span class="nx">Server</span><span class="p">{</span><span class="nx">Addr</span><span class="p">:</span> <span class="s">&quot;0.0.0.0:8888&quot;</span><span class="p">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="kd">var</span> <span class="nx">gracefulChild</span> <span class="kt">bool</span>
</span><span class='line'>    <span class="kd">var</span> <span class="nx">l</span> <span class="nx">net</span><span class="p">.</span><span class="nx">Listever</span>
</span><span class='line'>    <span class="kd">var</span> <span class="nx">err</span> <span class="kt">error</span>
</span><span class='line'>
</span><span class='line'>    <span class="nx">flag</span><span class="p">.</span><span class="nx">BoolVar</span><span class="p">(</span><span class="o">&amp;</span><span class="nx">gracefulChild</span><span class="p">,</span> <span class="s">&quot;graceful&quot;</span><span class="p">,</span> <span class="kc">false</span><span class="p">,</span> <span class="s">&quot;listen on fd open 3 (internal use only)&quot;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">if</span> <span class="nx">gracefulChild</span> <span class="p">{</span>
</span><span class='line'>        <span class="nx">log</span><span class="p">.</span><span class="nx">Print</span><span class="p">(</span><span class="s">&quot;main: Listening to existing file descriptor 3.&quot;</span><span class="p">)</span>
</span><span class='line'>        <span class="nx">f</span> <span class="o">:=</span> <span class="nx">os</span><span class="p">.</span><span class="nx">NewFile</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s">&quot;&quot;</span><span class="p">)</span>
</span><span class='line'>        <span class="nx">l</span><span class="p">,</span> <span class="nx">err</span> <span class="p">=</span> <span class="nx">net</span><span class="p">.</span><span class="nx">FileListener</span><span class="p">(</span><span class="nx">f</span><span class="p">)</span>
</span><span class='line'>    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
</span><span class='line'>        <span class="nx">log</span><span class="p">.</span><span class="nx">Print</span><span class="p">(</span><span class="s">&quot;main: Listening on a new file descriptor.&quot;</span><span class="p">)</span>
</span><span class='line'>        <span class="nx">l</span><span class="p">,</span> <span class="nx">err</span> <span class="p">=</span> <span class="nx">net</span><span class="p">.</span><span class="nx">Listen</span><span class="p">(</span><span class="s">&quot;tcp&quot;</span><span class="p">,</span> <span class="nx">server</span><span class="p">.</span><span class="nx">Addr</span><span class="p">)</span>
</span><span class='line'>    <span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Signal parent to stop</h3>

<p>At this point we&#8217;re ready to accept requests, but just before we do
that, we need to tell our parent to stop accepting requests and exit,
which could be something like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='go'><span class='line'><span class="k">if</span> <span class="nx">gracefulChild</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">parent</span> <span class="o">:=</span> <span class="nx">syscall</span><span class="p">.</span><span class="nx">Getppid</span><span class="p">()</span>
</span><span class='line'>    <span class="nx">log</span><span class="p">.</span><span class="nx">Printf</span><span class="p">(</span><span class="s">&quot;main: Killing parent pid: %v&quot;</span><span class="p">,</span> <span class="nx">parent</span><span class="p">)</span>
</span><span class='line'>    <span class="nx">syscall</span><span class="p">.</span><span class="nx">Kill</span><span class="p">(</span><span class="nx">parent</span><span class="p">,</span> <span class="nx">syscall</span><span class="p">.</span><span class="nx">SIGTERM</span><span class="p">)</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="nx">server</span><span class="p">.</span><span class="nx">Serve</span><span class="p">(</span><span class="nx">l</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<h2>In-progress requests completion/timeout</h2>

<p>For this we will need to keep track of open connections with a
<a href="http://golang.org/pkg/sync/#WaitGroup">sync.WaitGroup</a>. We will need
to increment the wait group on every accepted connection and decrement
it on every connection close.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='go'><span class='line'><span class="kd">var</span> <span class="nx">httpWg</span> <span class="nx">sync</span><span class="p">.</span><span class="nx">WaitGroup</span>
</span></code></pre></td></tr></table></div></figure>


<p>At first glance, the Golang standard http package does not provide any
hooks to take action on Accept() or Close(), but this is where the
interface magic comes to the rescue. (Big thanks and credit to <a href="http://nella.org/jra/">Jeff R. Allen</a>
for <a href="http://blog.nella.org/zero-downtime-upgrades-of-tcp-servers-in-go/">this post</a>).</p>

<p>Here is an example of a listener which increments a wait group on
every Accept(). First, we &#8220;subclass&#8221; <code>net.Listener</code> (you&#8217;ll see why we
need <code>stop</code> and <code>stopped</code> below):</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='go'><span class='line'><span class="kd">type</span> <span class="nx">gracefulListener</span> <span class="kd">struct</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">net</span><span class="p">.</span><span class="nx">Listener</span>
</span><span class='line'>    <span class="nx">stop</span>    <span class="kd">chan</span> <span class="kt">error</span>
</span><span class='line'>    <span class="nx">stopped</span> <span class="kt">bool</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Next we &#8220;override&#8221; the Accept method. (Nevermind <code>gracefulConn</code> for
now, it will be introduced later).</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='go'><span class='line'><span class="kd">func</span> <span class="p">(</span><span class="nx">gl</span> <span class="o">*</span><span class="nx">gracefulListener</span><span class="p">)</span> <span class="nx">Accept</span><span class="p">()</span> <span class="p">(</span><span class="nx">c</span> <span class="nx">net</span><span class="p">.</span><span class="nx">Conn</span><span class="p">,</span> <span class="nx">err</span> <span class="kt">error</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">c</span><span class="p">,</span> <span class="nx">err</span> <span class="p">=</span> <span class="nx">gl</span><span class="p">.</span><span class="nx">Listener</span><span class="p">.</span><span class="nx">Accept</span><span class="p">()</span>
</span><span class='line'>    <span class="k">if</span> <span class="nx">err</span> <span class="o">!=</span> <span class="kc">nil</span> <span class="p">{</span>
</span><span class='line'>        <span class="k">return</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="nx">c</span> <span class="p">=</span> <span class="nx">gracefulConn</span><span class="p">{</span><span class="nx">Conn</span><span class="p">:</span> <span class="nx">c</span><span class="p">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="nx">httpWg</span><span class="p">.</span><span class="nx">Add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>We also need a &#8220;constructor&#8221;:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='go'><span class='line'><span class="kd">func</span> <span class="nx">newGracefulListener</span><span class="p">(</span><span class="nx">l</span> <span class="nx">net</span><span class="p">.</span><span class="nx">Listener</span><span class="p">)</span> <span class="p">(</span><span class="nx">gl</span> <span class="o">*</span><span class="nx">gracefulListener</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">gl</span> <span class="p">=</span> <span class="o">&amp;</span><span class="nx">gracefulListener</span><span class="p">{</span><span class="nx">Listener</span><span class="p">:</span> <span class="nx">l</span><span class="p">,</span> <span class="nx">stop</span><span class="p">:</span> <span class="nb">make</span><span class="p">(</span><span class="kd">chan</span> <span class="kt">error</span><span class="p">)}</span>
</span><span class='line'>    <span class="k">go</span> <span class="kd">func</span><span class="p">()</span> <span class="p">{</span>
</span><span class='line'>        <span class="nx">_</span> <span class="p">=</span> <span class="o">&lt;-</span><span class="nx">gl</span><span class="p">.</span><span class="nx">stop</span>
</span><span class='line'>        <span class="nx">gl</span><span class="p">.</span><span class="nx">stopped</span> <span class="p">=</span> <span class="kc">true</span>
</span><span class='line'>        <span class="nx">gl</span><span class="p">.</span><span class="nx">stop</span> <span class="o">&lt;-</span> <span class="nx">gl</span><span class="p">.</span><span class="nx">Listener</span><span class="p">.</span><span class="nx">Close</span><span class="p">()</span>
</span><span class='line'>    <span class="p">}()</span>
</span><span class='line'>    <span class="k">return</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The reason the function above starts a goroutine is because this
cannot be done in our <code>Accept()</code> above since it will block on
<code>gl.Listener.Accept()</code>. The goroutine will unblock it by closing file
descriptor.</p>

<p>Our <code>Close()</code> method simply sends a <code>nil</code> to the stop channel for the
above goroutine to do the rest of the work.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='go'><span class='line'><span class="kd">func</span> <span class="p">(</span><span class="nx">gl</span> <span class="o">*</span><span class="nx">gracefulListener</span><span class="p">)</span> <span class="nx">Close</span><span class="p">()</span> <span class="kt">error</span> <span class="p">{</span>
</span><span class='line'>    <span class="k">if</span> <span class="nx">gl</span><span class="p">.</span><span class="nx">stopped</span> <span class="p">{</span>
</span><span class='line'>        <span class="k">return</span> <span class="nx">syscall</span><span class="p">.</span><span class="nx">EINVAL</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>    <span class="nx">gl</span><span class="p">.</span><span class="nx">stop</span> <span class="o">&lt;-</span> <span class="kc">nil</span>
</span><span class='line'>    <span class="k">return</span> <span class="o">&lt;-</span><span class="nx">gl</span><span class="p">.</span><span class="nx">stop</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Finally, this little convenience method extracts the file descriptor
from the <code>net.TCPListener</code>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='go'><span class='line'><span class="kd">func</span> <span class="p">(</span><span class="nx">gl</span> <span class="o">*</span><span class="nx">gracefulListener</span><span class="p">)</span> <span class="nx">File</span><span class="p">()</span> <span class="o">*</span><span class="nx">os</span><span class="p">.</span><span class="nx">File</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">tl</span> <span class="o">:=</span> <span class="nx">gl</span><span class="p">.</span><span class="nx">Listener</span><span class="p">.(</span><span class="o">*</span><span class="nx">net</span><span class="p">.</span><span class="nx">TCPListener</span><span class="p">)</span>
</span><span class='line'>    <span class="nx">fl</span><span class="p">,</span> <span class="nx">_</span> <span class="o">:=</span> <span class="nx">tl</span><span class="p">.</span><span class="nx">File</span><span class="p">()</span>
</span><span class='line'>    <span class="k">return</span> <span class="nx">fl</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>And, of course we also need a variant of a
<a href="http://golang.org/pkg/net/#Conn"><code>net.Conn</code></a> which decrements the
wait group on <code>Close()</code>:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='go'><span class='line'><span class="kd">type</span> <span class="nx">gracefulConn</span> <span class="kd">struct</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">net</span><span class="p">.</span><span class="nx">Conn</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="kd">func</span> <span class="p">(</span><span class="nx">w</span> <span class="nx">gracefulConn</span><span class="p">)</span> <span class="nx">Close</span><span class="p">()</span> <span class="kt">error</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">httpWg</span><span class="p">.</span><span class="nx">Done</span><span class="p">()</span>
</span><span class='line'>    <span class="k">return</span> <span class="nx">w</span><span class="p">.</span><span class="nx">Conn</span><span class="p">.</span><span class="nx">Close</span><span class="p">()</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>To start using the above graceful version of the Listener, all we need
is to change the <code>server.Serve(l)</code> line to:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='go'><span class='line'><span class="nx">netListener</span> <span class="p">=</span> <span class="nx">newGracefulListener</span><span class="p">(</span><span class="nx">l</span><span class="p">)</span>
</span><span class='line'><span class="nx">server</span><span class="p">.</span><span class="nx">Serve</span><span class="p">(</span><span class="nx">netListener</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>And there is one more thing. You should avoid hanging connections that
the client has no intention of closing (or not this week). It is
better to create your server as follows:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='go'><span class='line'><span class="nx">server</span> <span class="o">:=</span> <span class="o">&amp;</span><span class="nx">http</span><span class="p">.</span><span class="nx">Server</span><span class="p">{</span>
</span><span class='line'>        <span class="nx">Addr</span><span class="p">:</span>           <span class="s">&quot;0.0.0.0:8888&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="nx">ReadTimeout</span><span class="p">:</span>    <span class="mi">10</span> <span class="o">*</span> <span class="nx">time</span><span class="p">.</span><span class="nx">Second</span><span class="p">,</span>
</span><span class='line'>        <span class="nx">WriteTimeout</span><span class="p">:</span>   <span class="mi">10</span> <span class="o">*</span> <span class="nx">time</span><span class="p">.</span><span class="nx">Second</span><span class="p">,</span>
</span><span class='line'>        <span class="nx">MaxHeaderBytes</span><span class="p">:</span> <span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="mi">16</span><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/11/07/mod-python-performance-revisited/">Mod_python Performance Part 2: High(er) Concurrency</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-11-07T17:51:00-05:00" pubdate data-updated="true">Nov 7<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/11/07/mod-python-performance-revisited/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h3>Tl;dr</h3>

<p>As is evident from the table below, mod_python <a href="https://github.com/grisha/mod_python/tree/3.5.x">3.5</a>
(in pre-release testing as of this writing) is currently the fastest tool when it
comes to running Python in your web server, and second-fastest as a
WSGI container.</p>

<table border="1">
  <tr>
    <th>Server</th>
    <th>Version</th>
    <th>Req/s</th>
    <th>% of httpd static</th>
    <th>Notes</th>
  </tr>
  <tr>
    <th><a href="https://bitbucket.org/yarosla/nxweb/wiki/Benchmarks">nxweb</a> static file</th>
    <td>3.2.0-dev</td>
    <td>512,767</td>
    <td> 347.1 % </td>
    <td>&#8220;memcache&#8221;:false. (626,270 if true)</td>
  </tr>
  <tr>
    <th><a href="http://nginx.com/">nginx</a> static file</th>
    <td>1.0.15</td>
    <td>430,135</td>
    <td> 291.1 %</td>
    <td>stock CentOS 6.3 rpm</td>
  </tr>
  <tr>
    <th><a href="http://httpd.apache.org/">httpd</a> static file</th>
    <td>2.4.4, mpm_event</td>
    <td>147,746</td>
    <td> 100.0 % </td>
    <td></td>
  </tr>
  <tr>
    <th>mod_python <a href="http://modpython.org/live/current/doc-html/pythonapi.html#overview-of-a-request-handler">handler</a></th>
    <td>3.5, Python 2.7.5</td>
    <td>125,139</td>
    <td> 84.7 % </td>
    <td></td>
  </tr>
  <tr>
    <th><a href="https://uwsgi-docs.readthedocs.org/en/latest/">uWSGI</a></th>
    <td>1.9.18.2</td>
    <td>119,175</td>
    <td> 80.7 % </td>
    <td>-p 16 &#8211;threads 1</td>
  </tr>
  <tr>
    <th>mod_python <a href="http://modpython.org/live/current/doc-html/handlers.html#wsgi-handler">wsgi</a></th>
    <td>3.5, Python 2.7.5</td>
    <td>87,304</td>
    <td> 59.1 % </td>
    <td></td>
  </tr>
  <tr>
    <th><a href="http://code.google.com/p/modwsgi/">mod_wsgi</a></th>
    <td>3.4</td>
    <td>76,251</td>
    <td> 51.6 % </td>
    <td>embedded mode</td>
  </tr>
  <tr>
    <th>nxweb wsgi</th>
    <td>3.2.0-dev, Python 2.7.5</td>
    <td>15,141</td>
    <td> 10.2 % </td>
    <td>posibly misconfigured?</td>
  </tr>
</table>


<h2>The point of this test</h2>

<p>I wanted to see how mod_python compares to other tools of similar
purpose on high-end hardware and with relatively high concurrency. As
I&#8217;ve <a href="http://grisha.org/blog/2013/10/10/mod-python-performance/">written before</a>
you&#8217;d be foolish to base your platform decision on these numbers
because speed in this case matters very little. So the point of this
is just make sure that mod_python is in the ballpark with the rest and
that there isn&#8217;t anything seriously wrong with it. And surprisingly,
mod_python is actually pretty fast, <em>fastest</em>, even, though in its own
category (a raw mod_python handler).</p>

<h2>Test rig</h2>

<p>The server is a 24-core Intel Xeon 3GHz with 64GB RAM, running Linux
2.6.32 (CentOS 6.3).</p>

<p>The testing was done with
<a href="https://bitbucket.org/yarosla/httpress/wiki/Home">httpress</a>, which
was chosen after having tried
<a href="http://httpd.apache.org/docs/2.4/programs/ab.html">ab</a>,
<a href="http://www.hpl.hp.com/research/linux/httperf/">httperf</a> and
<a href="http://redmine.lighttpd.net/projects/weighttp/wiki">weighttp</a>. The exact command was:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>httpress -n 5000000 -c 120 -t 8 -k http://127.0.0.1/</span></code></pre></td></tr></table></div></figure>


<p>Concurrency of 120 was chosen as the highest number I could run across
all setups without getting strange errors. &#8220;Strange errors&#8221; could be
disconnects, delays and stuck connections, all tunable by anything
from Linux kernel configuration to specific tool configs. I very much
wanted concurrency to be at least a few times higher but it quickly
became apparent that getting to that level would require very
significant system tweaking for which I just didn&#8217;t have the time. 120
concurrent requests is nothing to sneeze at though: if you sustained
this rate for a day of python handler serving, you&#8217;d have processed
10,812,009,600 requests (on a single server!).</p>

<p>I should also note that in my tweaking of various configurations I
couldn&#8217;t get the requests/s numbers any significantly higher than what
you see above. Increasing concurrency and number of workers mostly
increased errors rather than r/s, which is also interesting because
it&#8217;s important how gracefuly each of these tools fails, but failure
mode is a whole different subject.</p>

<p>The tests were done via the loopback (127.0.0.1) because having tried
hitting the server from outside it became apparent that the network
was the bottleneck.</p>

<p>Keepalives were in use (-k), which means that all of the 5 million
requests are processed over only about fifty thousand TCP
connections. Without keepalives this would be more of the Linux kernel
test because the bulk of the work establishing and taking down a
connection happens in the kernel.</p>

<p>Before running the 5 million requests I ran 100,000 as a &#8220;warm up&#8221;.</p>

<p>This post does not include the actual code for the WSGI app and mod_python handlers because it was same as
in my <a href="http://grisha.org/blog/2013/10/10/mod-python-performance/">last post on mod_python performance testing</a>.</p>

<h2>Why httpress</h2>

<p><a href="http://httpd.apache.org/docs/2.4/programs/ab.html">ab</a> simply can&#8217;t run more than about 150K requests per second, so it
couldn&#8217;t adequately test nxweb and nginx static file serving.</p>

<p><a href="http://www.hpl.hp.com/research/linux/httperf/">httperf</a> looked
promising at first, but as is <a href="http://gwan.com/en_apachebench_httperf.html">noted here</a> its requests per
second cannot be trusted because it gradually increases the
load.</p>

<p><a href="http://redmine.lighttpd.net/projects/weighttp/wiki">weighttp</a> seemed
good, but somehow got stuck on idle but not yet closed connections
which affected the request/s negatively.</p>

<p><a href="https://bitbucket.org/yarosla/httpress/wiki/Home">httpress</a> claimed that it &#8220;promptly timeouts stucked connections,
forces all hanging connections to close after the main run, does not
allow hanging or interrupted connections to affect the measurement&#8221;,
which is just what I needed. And it worked really great too.</p>

<h2>The choice of contenders</h2>

<p>mod_python and mod_wsgi are the obvious choices, uWSGI/Nginx combo is
known as a low-resource and fast alternative. I came across nxweb
while looking at httpress (it&#8217;s written by the same person
(<a href="https://bitbucket.org/yarosla">Yaroslav Stavnichiy</a>), it looks to be the
fastest (open source) web server currently out there, faster than (closed source)
G-WAN, even.</p>

<h2>Specific tool notes</h2>

<p>The code used for testing and the configs were essentially same as what
I used in my <a href="http://grisha.org/blog/2013/10/10/mod-python-performance/">previous post on mod_python performance testing</a>.
The key differences are listed below.</p>

<h3>Apache</h3>

<p>The key config on Apache was:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ThreadsPerChild 25    # default
</span><span class='line'>StartServers 16
</span><span class='line'>MinSpareThreads 400</span></code></pre></td></tr></table></div></figure>


<p>MinSpareThreads ensures that Apache starts all possible processes and
threads on startup (25 * 16 = 400) so that there is no ramp up
period and it&#8217;s tsunami-ready right away.</p>

<h3>uWSGI</h3>

<p>The comparison with uWSGI isn&#8217;t entriely appropriate because it was
running listening on a unix domain socket behind Nginx. The -p 16
&#8211;threads 1 (16 worker processes with a single thread each) was chosen
as the best performing option after some experimentation. Upping -p to
32 reduced r/s to 86233, 64 to 47296. Upping &#8211;threads to 2 (with 16
workers) reduced r/s to 55925 (by half, which is weird - mod_python has no
problems with 25 threads). &#8211;single-interpreter didn&#8217;t seem to have
any significant impact.</p>

<p>The actual uWSGI command was:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>uwsgi -s logs/uwsgi.sock --pp htdocs  -M -p 16 --threads 1 -w mp_wsgi -z 30 -l 120 -L</span></code></pre></td></tr></table></div></figure>


<p>A note on the uWSGI performance. Initially it seemed to be
outperforming the mod_python handler by nearly a factor of two. Then
after all kinds of puzzled head-scratching, I decided to verify that
every hit ran my Python code - I did this by writing a dot to a file
and making sure that the file size matches the number of hits in the
end. It turned out that about one third of the requests from Nginx to
uWSGI were erroring out, but httpress didn&#8217;t see them as errors. So if
you&#8217;re going to attempt to replicate this, watch out for this
condition. EDIT: Thanks to uWSGI&#8217;s author Roberto De Loris&#8217; help, it
turned out that this was a result of misconfiguration on my part - the
-l parameter should be set higher than 120. (This explains how I
arrived at 120 as the concurrency chosen for the test too). The
request/s number and uWSGI&#8217;s position in my table is still correct.</p>

<h3>Nginx</h3>

<p>The relevant parts of the nginx config were (Note: this is not the
complete config for brevity):</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>worker_processes 24;
</span><span class='line'>...
</span><span class='line'>events {
</span><span class='line'>  worker_connections 1024;
</span><span class='line'>}
</span><span class='line'>...
</span><span class='line'>http {
</span><span class='line'>  server_tokens off;
</span><span class='line'>  keepalive_timeout 65;
</span><span class='line'>  sendfile on;
</span><span class='line'>  tcp_nopush on;
</span><span class='line'>  tcp_nodelay on;
</span><span class='line'>
</span><span class='line'>  access_log /dev/null main;
</span><span class='line'>...
</span><span class='line'>  upstream uwsgi {
</span><span class='line'>     ip_hash;
</span><span class='line'>     server unix:logs/uwsgi.sock;
</span><span class='line'>  }
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<h3>Conclusion</h3>

<p>Mod_python is plenty fast. Considering that unlike with other
contenders large parts of the code are written in Python and thus are
readable and debuggable by not just C programmers, it&#8217;s quite a feat.</p>

<p>I was surprised by Apache&#8217;s slow static file serving compared to Nginx
and Nxweb (the latter, although still young and in development seems like a
very cool web server).</p>

<p>On the other hand I am not all that convinced that the Nginx/uWSGI set
up is as cool as it is touted everywhere. Unquestionably Nginx is a
super solid server and Apache has some catching up to do when it comes
to acting as a static file server or a reverse proxy. But when it
comes to serving Python-generated content, my money would be on Apache
rather than uWSGI. The &#8220;low&#8221; 120 concurrency level for this test was
largely chosen because of uWSGI (Apache started going haywire on me at
about 400+ concurrent connections). EDIT: Thanks to Roberto&#8217;s comment,
this turned out to be an error on my part (see comments). uWSGI can
handle higher concurrencies if -l is set higher.</p>

<p>It&#8217;s also interesting that on my laptop a mod_python handler
outperformed the Apache static file, but it wasn&#8217;t the case on the big
server.</p>

<p>I didn&#8217;t do Python 3 testing, it would be interesting to see how much
difference it makes as well.</p>

<p>I realize this post may be missing key config data - I had to leave
out a lot because of time contraints (and my lazyness) - so if you see
any obvious gaps, please comment, I will try to address them.</p>

<p>P.S. Did I mention mod_python 3.5 supports Python 3? Please help
me <a href="https://github.com/grisha/mod_python/issues/9">test it</a>!</p>

<p>
<iframe src="http://ghbtns.com/github-btn.html?user=grisha&repo=mod_python&type=watch&count=true&size=large"
  allowtransparency="true" frameborder="0" scrolling="0" width="170" height="30"></iframe>

<iframe src="http://ghbtns.com/github-btn.html?user=grisha&repo=mod_python&type=fork&count=true&size=large"
  allowtransparency="true" frameborder="0" scrolling="0" width="170" height="30"></iframe>

<a href="https://twitter.com/mod_python" class="twitter-follow-button" data-show-count="false" data-size="large">Follow @mod_python</a>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/10/30/separate-request-and-response-or-a-single-request-object/">Separate Request and Response or a Single Request Object?</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-10-30T13:18:00-04:00" pubdate data-updated="true">Oct 30<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/10/30/separate-request-and-response-or-a-single-request-object/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Are you in favor of a single request object, or two separate objects:
request and response?  Could it be that the two options are not
contradictory or even mutually exclusive?</p>

<p>I thouhgt I always was in favor of a single request object which I
<a href="https://mail.python.org/pipermail/web-sig/2003-October/000162.html">expressed on the Web-SIG mailing list thread</a>
dating back to October 2003 (ten years ago!). But it is only now that
I’ve come to realize that both proponents of a single object and two
separate objects were correct, they were just talking about different
things.</p>

<p>The confusion lies in the distinction between what I am going to term
a web application and a request handler.</p>

<p>A <em>request handler</em> exists in the realm of an HTTP server, which
(naturally) serves HTTP requests. An HTTP request consists of a
request (a method, such as “GET”, along with some HTTP headers and
possibly a body) and a response (a status line, some HTTP headers and
possibly a body) sent over the TCP connection. There is a one-to-one
correspondence between a request and a response established by the
commonality of the connection. An HTTP request is incomplete if the
response is missing, and a response cannot exist without a
request. (Yes, the term &#8220;request&#8221; is used to denote both the request
and response, as well as just the request part of the request, and
that&#8217;s confusing).</p>

<p>A <em>web application</em> is a layer on top of the HTTP request handler. A web
application operates in requests and responses as well, but those
should not be confused with the HTTP request/response pairs.</p>

<p>Making the conceptual distinction between a web application request
and an HTTP request is difficult because both web applications and
request handlers use HTTP headers and status to accomplish their
objectives. The difference is that strictly speaking a web application
does not have to use HTTP and ideally should be protocol-agnostic,
though it is very common for a web application to rely on
HTTP-specific features these days. Not every HTTP request exists as
part of a web application. But because it is difficult to imagine a
web application without HTTP, we tend to lump the two concepts
together. It is also exacerbated by the fact that HTTP headers carry
both application-specific and HTTP-specific information.</p>

<p>A good example of the delineation between a web application response
and an HTTP response is handling of an error condition. A web
application error is typically not an HTTP error.  Imagine an “invalid
login” page. It is a web application error, but not an HTTP error. An
“invalid login” page should send a “200 OK” status line and a body
explaining that the credentials supplied were not valid. But then HTTP
provides its own authentication mechanism, and an HTTP “401
Unauthorized” (which ought not be used by web applications) is often
misunderstood as something that web applications should incorporate
into how they do things.</p>

<p>Another example of a place where the line gets blurry is a redirect. A
redirect is quite common in a web application, and it is typically
accomplished by way of an HTTP redirect (3XX status code), yet the two
are not the same. An HTTP redirect, for example, may happen
unbeknownst to the web application for purely infrastructural reasons,
and a web application redirect does not always cause an HTTP redirect.</p>

<p>Yet another example: consider a website serving static content where
same URI responds with different content according to the
Accept-Language header in the request. Is this a “web application”?
Hardly. Could you have some Python (or whatever you favorite language
is) help along with this process? Certainly. Wouldn’t this code be
part of a “web application”?  Good question. It is not uncommon for a
web application to consider the Accept-Language header in its
response. You could also accomplish this entirely in an http server by
configuring it correctly. Sometimes whether something is a web
application just depends on how you&#8217;re looking at it, but you do have
to decide for yourself which it is.</p>

<p>Getting to the original problem, the answer to the question of whether
to use separate response/request objects or not depends very much on
which realm you’re operating in. A request handler only needs one
request object representing the HTTP request because it is
conceptually similar to a file - you don’t typically open a file twice
once for reading and once for writing. Whereas a web application,
which may chose between different responses depending on what’s in the
request is possibly best served with two separate objects.</p>

<p>I think that misunderstanding of what a “web application” is happens
to be the cause of a lot of bad decisions plaguing the world of web
development these days. It is not uncommon to see people get stuck on
low-level HTTP subtleties while referring to web application issues and
vise-versa. We’d all get along better if we took some time to think
about the distinction between web applications and HTTP request
handlers.</p>

<p>P.S. This will get even more complicated when HTTP 2.0 comes around
where responses may exist without a request. And I haven’t even
mentioned SSL/TLS.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/10/26/my-thoughts-on-wsgi/">My Thoughts on WSGI</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-10-26T11:24:00-04:00" pubdate data-updated="true">Oct 26<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/10/26/my-thoughts-on-wsgi/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I&#8217;m not very fond of it. Here is why.</p>

<h2>CGI Origins</h2>

<p>WSGI is based on CGI, as the &#8220;GI&#8221; (Gateway Interface) suggests right
there in the name.</p>

<p>CGI solved a very important problem using the very limited tools at
hand available at the time. Though CGI wasn&#8217;t a standard, it was
ubiquitous in the early days of the WWW, despite its inherent slowness
and other limitations. It became popular because it worked with any
language, was easy to turn on and provided such a thick wall of
isolation that admins could turn it on for their users without too much concern
for problems caused by user-generated CGI scripts.</p>

<p>There is now an RFC (<a href="http://www.ietf.org/rfc/rfc3875">RFC3875</a>)
describing CGI, but I hazard that
<a href="http://ken.coar.org/">Ken Coar</a> wrote the RFC not because he thought CGI was great, but rather
out of discontent with the present state of affairs - everyone was
using CGI, yet there never was a formal document describing it.</p>

<p>So if I were to attempt to unite all Python web applications under the
same standard, CGI wouldn&#8217;t be the first thing I would consider. There are
other efforts at solving the same problem in more elegant ways which
could be used as a model, e.g. (dare I mention?) Java Servlets.</p>

<h2>Headers</h2>

<p>CGI dictated that HTTP headers be passed to the CGI script by way of
<a href="http://en.wikipedia.org/wiki/Environment_variable">environment variables</a>. The
same environment that contain your <code>$PATH</code> and <code>$TERM</code>.  (Note this
also explains the origin of the term <em>environment</em> in WSGI - in HTTP
there is no <em>request environment</em>, there is simply a <em>request</em>). So as
to not clash with any other environment variables, CGI would prepend
<code>HTTP_</code> to every header name. It also swapped dashes with underscores
because dashes are not allowed in shell variable names. And because
environment variables in DOS and Unix are typically case-insensitive,
they were capitalized. Thus <code>"content-type"</code> would become <code>"HTTP_CONTENT_TYPE"</code>.</p>

<p>And how much sense applying the same transformation make in the realm
in which WSGI operates? The headers are typically read by the
webserver and stored in some kind of a structure, which ought to be
directly accessible so the application can get headers in the
original, unmodified format. For example in Apache this would be the
<code>req.headers_in</code> table.  What is the benefit of combing through that
structure converting every key to some capitalized HTTP_ string at
every request? Why are WSGI developers forced to use
<code>env['HTTP_CONTENT_LENGTH']</code> rather than <code>env['Content-length']</code>?</p>

<p>Another thing about the environment is that the WSGI standard states
that it must be a real Python dictionary, thereby dictating that a
memory allocation happen to satisfy this requirement, <em>at every
request</em>.</p>

<h2>start_response()</h2>

<p>In order to be able to write anything to the client a WSGI application
must envoke the start_response() function passed to it which would
return a write() method.</p>

<p>Ten points for cuteness here, but the practicality of this solution
eludes me. This is certainly a clever way to make the fact that the start
of a response is an irreversible action in HTTP because the headers are
sent first, but seriosly - do programmers who code at this level not
know it? Why can&#8217;t the header sending part happen implicitly at the
first write(), and why can&#8217;t an application write without sending any
headers?</p>

<p>There is also another problem here - function calls are relatively
expensive in Python. The requirement that the app must beg for the
write object every time introduces a completely unnecessary function
call.</p>

<p>The request object with a write() method should simply be passed
in. This is how it has always worked in mod_python (cited in PEP3333 a
number of times!).</p>

<h2>Error handling</h2>

<p>First, I must confess that after re-reading the section of the PEP3333
describing the <code>exc_info</code> argument several times I still can&#8217;t say I
grok what it&#8217;s saying. Looking at some implementations out there I am
releived to know I am not the only one.</p>

<p>But the gist of it that an exception can be supplied along with some
headers. It seems to me there is confusion between HTTP errors and
Python errors here, the two are not related. What is the expected
outcome of passing a Python exception to an HTTP server? The server
would probably convert it to a 500 Internal Server Error (well it only
has so many possibilities to chose from), and what&#8217;s the point of that?</p>

<p>Wouldn&#8217;t the outcome be same if the application simply raised an
exception?</p>

<p>If the spec wanted to provide means for the application Python errors
to somehow map to HTTP errors, why not define a special exception
class which could be used to send HTTP errors? What was wrong with
mod_python&#8217;s:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>raise apache.SERVER_RETURN, apache.HTTP_INTERNAL_SERVER_ERROR</span></code></pre></td></tr></table></div></figure>


<p>I think it&#8217;s simple and self-explanatory.</p>

<h2>Other things</h2>

<p>What is <code>wsgi.run_once</code>, why does it matter and why should the web
server provide it? What would be a good use case for such a thing?</p>

<p>There is a long section describing &#8220;middleware&#8221;. Middleware is a
wrapper, an example of the <a href="http://www.cise.ufl.edu/research/ParallelPatterns/PatternLanguage/AlgorithmStructure/Pipeline.htm">pipeline design pattern</a>
and there doesn&#8217;t seem to be anything special with this concept that
the WSGI spec should even mention it. (I also object to the term
&#8220;middleware&#8221; - my intuition suggests it&#8217;s a layer between &#8220;hardware&#8221;
and &#8220;software&#8221;, not a wrapper.)</p>

<h2>SCRIPT_NAME and PATH_INFO</h2>

<p>Perhaps the most annoying part of CGI were these two mis-understood
variables, and sadly WSGI uses them too.</p>

<p>Remember that in CGI we always had a script. A typical CGI script
resided somewhere on the filesystem to which the request URI maps. As
part of serving the request the server traversed the URI mapping each
element to an element of the filesystem path to locate the
script. Once the script was found, the portion of the URI used thus far
was assigned to the SCRIPT_NAME variable, while the remainder of the
URI got assigned to PATH_INFO.</p>

<p>But where is <em>the script</em> in WSGI? Is my Python module the script?
What relatioship does there exist between the request URI and the
(non-existent) script?</p>

<h2>Bottom line</h2>

<p>I am not convinced that there should be a universal standard for
Python web applications to begin with. I think that what we refer to
as &#8220;web applications&#8221; is still not very well understood by us
programmers.</p>

<p>But if we are to have one, I think that WSGI approach is not the right
one. It brings the world of Python web development to the lowest
common denominator - CGI and introduces some problems of its own on
top of it.</p>

<h2>Other notes</h2>

<h3>What is the Gateway in CGI</h3>

<p>I did some digging into the etymology of “Common Gateway Interface”,
because I wanted to know what the original author (Rob McCool) meant
by it when he came up with it. From reading <a href="http://web.archive.org/web/20100127191128/http://hoohoo.ncsa.illinois.edu/cgi/intro.html">this</a>
it’s apparent that he saw it as the Web daemon’s gateway to an outside
program:</p>

<p>“For example, let&#8217;s say that you wanted to &#8220;hook up&#8221; your Unix
database to the World Wide Web, to allow people from all over the
world to query it. Basically, you need to create a CGI program that
the Web daemon will execute to transmit information to the database
engine, and receive the results back again and display them to the
client. This is an example of a gateway, and this is where CGI,
currently version 1.1, got its origins.”</p>

<p>I always perceived it the other way around, I thought the “gateway”
was a gateway to the web server. I think that when Phillip J. Eby
first proposed the name WSGI he was under the same misperception as I.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/10/25/mod-python-the-long-story/">Mod_python: The Long Story</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-10-25T20:05:00-04:00" pubdate data-updated="true">Oct 25<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/10/25/mod-python-the-long-story/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>This story started back in 1996. I was in my early twenties, working
as a programmer at a small company specializing in on-line reporting of
certain pharmaceutical data.</p>

<p>There was a web-based application (which was extremely cool
considering how long ago this was), but unfortunately it was written
in Visual Basic by a contractor and I was determined to do something
about it. As was very fashionable at the time, I was very pro Open
Source, had Linux running on my home 386 and had recently heard
<a href="http://boston-linux-unix-general-discussion-list.996279.n3.nabble.com/fwd-LOCAL-Washington-DC-Linux-User-Group-meeting-and-Python-talk-td3733.html">Guido’s talk</a>
at the DC Linux user group presenting his new language he called
Python. Python seemed like a perfect alternative to the VB
monstrosity.</p>

<p>I spent a few weeks quietly in my cubicle learning Python and
rewriting the whole app in it. (Back in those days this is how
programmers worked, there was no “agile” and “daily stand ups”,
everyone understood that things take time. I miss those days very
much). Python was fantastic, and soon the app was completely
re-written.</p>

<p>Then I realized that explaining what I’ve been working on to my bosses
might be a bit of a challenge. You see, for a while there nobody knew
that the web app they’ve been using had been re-written in Python, but
sooner or later I would have to reveal the truth and, more
importantly, justify my decision. I needed a good reason, and stuff
about object-oriented programming, clean code, open source, etc would
have fallen on deaf ears.</p>

<p>Just around that time the Internet Programming with Python book came
out, and in it there was a chapter on how to embed the Python
interpreter in the Netscape Enterprise web server. The idea seemed
very intriguing to me and it might have contained exactly the
justification I was looking for - it would make the app
faster. (&#8220;Faster&#8221; is nearly as good as &#8220;cheaper&#8221; when it comes to
selling to the management). I can’t say that I knew much C back then,
but with enough tinkering around I was able to make something work,
and lo and behold it was quite noticeably faster.</p>

<p>And so a few days later I held a presentation in the big conference
room regarding this new tool we’ve started using called Python which
can crunch yall’s numbers an order of magnitude faster than the
Microsoft product we’ve been using. And oh, by the way, I quickly
hacked something together last night - let’s do a live demo, look how
fast this is!  They were delighted.</p>

<p>Little did they know, the app had been running in Python for months,
and the reason for the speed up had little to do with the language
itself. It was all because I was able to embed the interpreter within
the web server. Then I thought that to make it all complete I would
make my little tool open source and put it on my website free for
everyone to use. I called it
<a href="http://www.ispol.com/home/grisha/nsapy/">NSAPy</a> as a combination of
the Netscape Server API and Python.</p>

<p>But I didn’t stop there, and soon I was able to replicate this on an
Apache web server, which was taking the Internet by storm back
then. The name mod_python came naturally since there already was a
mod_perl.</p>

<p>Things were going very well back then. These were the late nineties,
the dawn of e-commerce on the World Wide Web. I started working for a
tiny ISP which soon transformed into a humongous Web Hosting company,
we ran millions of sites, built new data centers with thousands of
servers pushing gigabits of traffic and (in short) were taking over
the world (or so it seemed). With the rise of our company’s stock
price, me and my colleagues were on our way to becoming
millionaires. Mod_python was doing very well too. It had a busy
website, a large and very active mailing list and an ever growing
number of devoted users. I went to various Open Source conferences to
present about it (and couldn’t really believe that without exception
everyone knew what mod_python was).</p>

<p>Then came 2001. We just bought a house and our second son was not even
a year old when one beautiful sunny summer day I was summoned to a
mandatory meeting. In that meeting about two thirds of our office was
let go. Even though we all felt it was coming, it was still a shock. I
remember coming home that morning and having to explain my wife that
I’d just been fired. This after constant all-nighters, neglect for
family life under the excuse of having the most important job doing
the most important thing and changing the world and rants about how
we’d be all set financially in just a year or two. In my personally
opinion the 2007 financial crash was nothing compared to the dot-com
bust. Everyone was getting laid off everywhere, the Internet became a
dirty word, software development was being outsourced to India.</p>

<p>For the next couple of years I made a living doing contracting work
here and there. Needless to say, mod_python wasn’t exactly at the top
of my priority list. But it was getting ever more popular, the mailing
list busier, though it didn’t make any money (for me at least). I
tried my best to keep everything running in whatever spare time I had,
answering emails and releasing new versions periodically. Finding time
for it was increasingly difficult, especially given that most of the
work I was doing had nothing to do with mod_python or Python.</p>

<p>One day I had this thought that donating mod_python to the Apache
Software Foundation would ensure its survival, even if I can no longer
contribute. And so it was done. Initially things went very well - the
donation did affiliate mod_python with the solid reputation of Apache
and that was great. Mod_python gained a multitude more users and most
importantly contributors.</p>

<p>At the same time my life was becoming ever more stressful. Free time
for mod_python hacking was getting more and more scarce until there
was none. I also think I was experiencing burnout. Answering questions
on the mailing list became an annoyance. I had to read through
enormous threads with proposals for various features or how things
ought to work and respond to them, and it was just never ending. It
wasn’t fun anymore.</p>

<p>I also felt that people didn’t understand what mod_python was and that
I’m not able to explain it very well. (For what it’s worth, I still
feel this way). In my mind it was primarily an interface to the Apache
internals, but since making every structure and API accessible from
within Python was impractical, only selected pieces were
exposed. Secondly, mod_python provided means to perform certain things
that were best done in Apache, e.g. global locking, caching. Lastly,
it provided certain common tasks but implemented in Apache-specific
ways (using Apache pools, APR, etc.) for maximal performance; things
like cookies and sessions fell into that category. Publisher and PSP
didn’t strictly belong in mod_python, but were there for the sake of
battery-includedness - you could build a rudimentary app without any
additional tool.</p>

<p>The rest of the world saw it as a web-development framework. It wasn’t
a particularly good one, especially when it came to development,
because it required root privileges to run. It also didn’t do a very
good job at reloading changed modules very well which complicated
development. A very considerable effort was put in by one of the
contributors to address the particular issue of module loading and
caching, and I never thought it to be important because to me
restarting Apache seemed like the answer, I didn’t think that people
without root access would ever use mod_python.</p>

<p>As I was growing more disinterested in mod_python it got to a point
where I just let it be. I would skim through emails from people I
trusted and responded affirmatively to whatever they proposed without
giving it much thought. I didn’t see any point in keeping and
defending my vision for mod_python. I think that by about 2006 or so I
was so disconnected I no longer had a good grasp of what the latest
features of mod_python were being worked on. Not sure if it was my
lack of interest or that other contributors felt burned out as well,
but new commits slowed down to a trickle and stopped eventually, and
my quarterly reports to the ASF Board became a cut-and-paste email of
“no new activity”.</p>

<p>This is where the negative aspect of the ASF patronage begun to
surface. Sadly, the ASF rules are that projects and their community
must be active, and soon the project got moved to the attic. And even
though I kept telling myself that I couldn’t care less, I must admit
it hurt. The attic is a like a one-way trash can - once there, a
project cannot go back, other than through the incubation process.</p>

<p>Fast forward to 2013. Why get back to hacking on it? First of all I
got tired of “mod_python is dead” plastered all over the web.  Every
time I see some kid who wasn’t old enough to speak back when I first
released it tweet that it is this or that, I can’t help but take it a
little personally. It’s an open source project people, it’s only dead
if you do not contribute to it.</p>

<p>For the skeptics in the crowd I most certainly disagree that
mod_python as a concept is dead, I’d even argue that its time hasn’t
come yet. The vision has not changed. Mod_python is still an interface
to Apache which lets you take advantage of its versatile architecture
to do some very powerful things. It’s not quite a web development
framework, and it’s not even a tool for running your favorite web
development framework in production (though it can certainly do that
quite nicely).</p>

<p>These days there is more demand than ever for high volume servers that
do not have a user interface and thus do not need a WSGI framework to
power them - I think this is one of the areas where mod_python could
be most useful. There are also all kinds of possibilities for using
Apache and mod_python for distributed computing and big data stuff
taking advantage of the fact that Apache is an excellent job
supervisor - anyone up for writing a map/reduce framework in
mod_python?</p>

<p>I must also note that hacking on it in the past weeks has been fun
once again. I wanted to get up to speed with the latest on Python 3
and Apache internals, especially the event/epoll stuff and this has
been a great way to do just that. I also very much enjoy that I can
once again do whatever I want without any scrutiny.</p>

<p>If there is one thing I’ve learned it’s that few open source projects
can exist without their founders’ continuous involvement. The Little
Prince once said - “You become responsible forever for what you have
tamed”. It seems like mod_python is my rose and if I don’t water it,
no one will.</p>

<p>P.S. Did I mention mod_python now supports Python 3? Please help
me <a href="https://github.com/grisha/mod_python/issues/9">test it</a>!</p>

<p>
<iframe src="http://ghbtns.com/github-btn.html?user=grisha&repo=mod_python&type=watch&count=true&size=large"
  allowtransparency="true" frameborder="0" scrolling="0" width="170" height="30"></iframe>

<iframe src="http://ghbtns.com/github-btn.html?user=grisha&repo=mod_python&type=fork&count=true&size=large"
  allowtransparency="true" frameborder="0" scrolling="0" width="170" height="30"></iframe>

<a href="https://twitter.com/mod_python" class="twitter-follow-button" data-show-count="false" data-size="large">Follow @mod_python</a>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/10/10/mod-python-performance/">Mod_python Performance and Why It Matters Not.</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-10-10T13:04:00-04:00" pubdate data-updated="true">Oct 10<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/10/10/mod-python-performance/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><em>TL;DR: mod_python is faster than you think.</em></p>

<p>Tonight I thought I&#8217;d spend some time looking into how the new
<a href="http://www.modpython.org/">mod_python</a>
fares against other frameworks of similar purpose. In this article I
am going to show the results of my findings, and then I will explain
<em>why it really does not matter</em>.</p>

<p>I am particularly interested in the following:</p>

<ul>
<li>a pure mod_python handler, because this is as fast as mod_python gets.</li>
<li>a mod_python wsgi app, because WSGI is so popular these days.</li>
<li>mod_wsgi, because it too runs under Apache and is written entirely in C.</li>
<li>uWSGI, because it claims to be super fast.</li>
<li>Apache serving a static file (as a point of reference).</li>
</ul>


<h1>The Test</h1>

<p>I am testing this on a CentOS instance running inside VirtualBox on an
early 2011 MacBook Pro. The VirtualBox has 2 CPU&#8217;s and 6GB of RAM
allocated to it. Granted this configuration can&#8217;t possibly be very
performant [if there is such a word], but it should be enough to
compare.</p>

<p>Real-life performance is very much affected by issues related to
concurrency and load. I don&#8217;t have the resources or tools to
comprehensively test such scenarios, and so I&#8217;m just using concurrency
of 1 and seeing how fast each of the afore-listed set ups can process
small requests.</p>

<p>I&#8217;m using mod_python 3.4.1 (pre-release), revision
<a href="https://github.com/grisha/mod_python/tree/35f35dc2a8d23e92e5c8dc7dccea2a1b6bcc353e">35f35dc</a>,
compiled against Apache 2.4.4 and Python 2.7.5. Version of mod_wsgi is
3.4, for uWSGI I use 1.9.17.1.</p>

<p>The Apache configuration is pretty minimal (It could probably trimmed
even more, but this is good enough):</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>LoadModule unixd_module /home/grisha/mp_test/modules/mod_unixd.so
</span><span class='line'>LoadModule authn_core_module /home/grisha/mp_test/modules/mod_authn_core.so
</span><span class='line'>LoadModule authz_core_module /home/grisha/mp_test/modules/mod_authz_core.so
</span><span class='line'>LoadModule authn_file_module /home/grisha/mp_test/modules/mod_authn_file.so
</span><span class='line'>LoadModule authz_user_module /home/grisha/mp_test/modules/mod_authz_user.so
</span><span class='line'>LoadModule auth_basic_module /home/grisha/mp_test/modules/mod_auth_basic.so
</span><span class='line'>LoadModule python_module /home/grisha/src/mod_python/src/mod_python/src/mod_python.so
</span><span class='line'>
</span><span class='line'>ServerRoot /home/grisha/mp_test
</span><span class='line'>PidFile logs/httpd.pid
</span><span class='line'>ServerName 127.0.0.1
</span><span class='line'>Listen 8888
</span><span class='line'>MaxRequestsPerChild 1000000
</span><span class='line'>
</span><span class='line'>&lt;Location /&gt;
</span><span class='line'>      SetHandler mod_python
</span><span class='line'>      PythonHandler mp
</span><span class='line'>      PythonPath "sys.path+['/home/grisha/mp_test/htdocs']"
</span><span class='line'>&lt;/Location&gt;</span></code></pre></td></tr></table></div></figure>


<p>I should note that <code>&lt;Location /&gt;</code> is there for a purpose - the latest
mod_python forgoes the map_to_storage phase when inside a <code>&lt;Location&gt;</code>
section, so this makes it a little bit faster.</p>

<p>And the <code>mp.py</code> file referred to by the <code>PythonHandler</code> in the config
above looks like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">mod_python</span> <span class="kn">import</span> <span class="n">apache</span>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">handler</span><span class="p">(</span><span class="n">req</span><span class="p">):</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">req</span><span class="o">.</span><span class="n">content_type</span> <span class="o">=</span> <span class="s">&#39;text/plain&#39;</span>
</span><span class='line'>    <span class="n">req</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s">&#39;Hello World!&#39;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="n">apache</span><span class="o">.</span><span class="n">OK</span>
</span></code></pre></td></tr></table></div></figure>


<p>As the benchmark tool, I&#8217;m using the good old
<a href="http://httpd.apache.org/docs/2.4/programs/ab.html">ab</a>, as follows:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>ab -n 10  http://localhost:8888/
</span></code></pre></td></tr></table></div></figure>


<p>For each test in this article I run 500 requests first as a &#8220;warm up&#8221;,
then another 500K for the actual measurement.</p>

<p>For the mod_python WSGI handler test I use the following config (relevant section):</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>&lt;Location /&gt;
</span><span class='line'>    PythonHandler mod_python.wsgi
</span><span class='line'>    PythonPath <span class="s2">&quot;sys.path+[&#39;/home/grisha/mp_test/htdocs&#39;]&quot;</span>
</span><span class='line'>    PythonOption mod_python.wsgi.application mp_wsgi
</span><span class='line'>&lt;/Location&gt;
</span></code></pre></td></tr></table></div></figure>


<p>And the <code>mp_wsgi.py</code> file looks like this:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">application</span><span class="p">(</span><span class="n">environ</span><span class="p">,</span> <span class="n">start_response</span><span class="p">):</span>
</span><span class='line'>    <span class="n">status</span> <span class="o">=</span> <span class="s">&#39;200 OK&#39;</span>
</span><span class='line'>    <span class="n">output</span> <span class="o">=</span> <span class="s">&#39;Hello World!&#39;</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">response_headers</span> <span class="o">=</span> <span class="p">[(</span><span class="s">&#39;Content-type&#39;</span><span class="p">,</span> <span class="s">&#39;text/plain&#39;</span><span class="p">),</span>
</span><span class='line'>                        <span class="p">(</span><span class="s">&#39;Content-Length&#39;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)))]</span>
</span><span class='line'>    <span class="n">start_response</span><span class="p">(</span><span class="n">status</span><span class="p">,</span> <span class="n">response_headers</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">return</span> <span class="p">[</span><span class="n">output</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure>


<p>For mod_wsgi test I use the exact same file, and the config as follows:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">LoadModule</span> <span class="n">wsgi_module</span> <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">grisha</span><span class="o">/</span><span class="n">mp_test</span><span class="o">/</span><span class="n">modules</span><span class="o">/</span><span class="n">mod_wsgi</span><span class="o">.</span><span class="n">so</span>
</span><span class='line'><span class="n">WSGIScriptAlias</span> <span class="o">/</span> <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">grisha</span><span class="o">/</span><span class="n">mp_test</span><span class="o">/</span><span class="n">htdocs</span><span class="o">/</span><span class="n">mp_wsgi</span><span class="o">.</span><span class="n">py</span>
</span></code></pre></td></tr></table></div></figure>


<p>For uWSGI (I am not an expert), I first used the following command:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">grisha</span><span class="o">/</span><span class="n">src</span><span class="o">/</span><span class="n">mp_test</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">uwsgi</span> \
</span><span class='line'>   <span class="o">--</span><span class="n">http</span> <span class="mf">0.0</span><span class="o">.</span><span class="mf">0.0</span><span class="p">:</span><span class="mi">8888</span> \
</span><span class='line'>   <span class="o">-</span><span class="n">M</span> <span class="o">-</span><span class="n">p</span> <span class="mi">1</span> <span class="o">-</span><span class="n">w</span> <span class="n">mysite</span><span class="o">.</span><span class="n">wsgi</span> <span class="o">-</span><span class="n">z</span> <span class="mi">30</span> <span class="o">-</span><span class="n">l</span> <span class="mi">120</span> <span class="o">-</span><span class="n">L</span>
</span></code></pre></td></tr></table></div></figure>


<p>Which yielded a pretty dismal result, so I tried using a unix socket
<code>-s /home/grisha/mp_test/uwsgi.sock</code> and ngnix as
the front end as described
<a href="http://nichol.as/benchmark-of-python-web-servers">here</a>, which did
make uWSGI come out on top (even if proxied uWSGI is an orange among
the apples).</p>

<h3>The results, requests per second, fastest at the top:</h3>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="o">|</span> <span class="n">uWSGI</span><span class="o">/</span><span class="n">nginx</span>         <span class="o">|</span> <span class="mi">2391</span> <span class="o">|</span>
</span><span class='line'><span class="o">|</span> <span class="n">mod_python</span> <span class="n">handler</span>  <span class="o">|</span> <span class="mi">2332</span> <span class="o">|</span>
</span><span class='line'><span class="o">|</span> <span class="n">static</span> <span class="nb">file</span>         <span class="o">|</span> <span class="mi">2312</span> <span class="o">|</span>
</span><span class='line'><span class="o">|</span> <span class="n">mod_wsgi</span>            <span class="o">|</span> <span class="mi">2143</span> <span class="o">|</span>
</span><span class='line'><span class="o">|</span> <span class="n">mod_python</span> <span class="n">wsgi</span>     <span class="o">|</span> <span class="mi">1937</span> <span class="o">|</span>
</span><span class='line'><span class="o">|</span> <span class="n">uWSGI</span> <span class="o">--</span><span class="n">http</span>        <span class="o">|</span> <span class="mi">1779</span> <span class="o">|</span>
</span></code></pre></td></tr></table></div></figure>


<p>What&#8217;s interesting and unexpected at first is that uWSGI and the
mod_python handler perform better than sending a static file, which I
expected to be the fastest. On a second thought though it does make
sense, once you consider that no (on average pretty expensive)
filesystem operations are performed to serve the request.</p>

<p>Mod_wsgi performs better than the mod_python WSGI handler, and that is
expected, because the mod_python version is mostly Python, vs
mod_wsgi&#8217;s C version.</p>

<p>I think that with a little work mod_python wsgi handler could perform
on par with uWSGI, though I&#8217;m not sure the effort would be worth
it. Because as we all know,
<a href="http://en.wikiquote.org/wiki/Donald_Knuth#Computer_Programming_as_an_Art_.281974.29">premature optimization is the root of all evil</a>.</p>

<h1>Why It Doesn&#8217;t Really Matter</h1>

<p>Having seen the above you may be tempted to jump on the uWSGI wagon,
because after all, what matters more than speed?</p>

<p>But let&#8217;s imagine a more real world scenario, because it&#8217;s not likely
that all your application does is send <code>"Hello World!".</code></p>

<p>To illustrate the point a little better I created a very simple Django
app, which too sends <code>"Hello World!"</code>, only it does it using a template:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">hello</span><span class="p">(</span><span class="n">request</span><span class="p">):</span>
</span><span class='line'>    <span class="n">t</span> <span class="o">=</span> <span class="n">get_template</span><span class="p">(</span><span class="s">&quot;hello.txt&quot;</span><span class="p">)</span>
</span><span class='line'>    <span class="n">c</span> <span class="o">=</span> <span class="n">Context</span><span class="p">({</span><span class="s">&#39;name&#39;</span><span class="p">:</span><span class="s">&#39;World&#39;</span><span class="p">})</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">HttpResponse</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">c</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p>Using the mod_python wsgi handler (the slowest), we can process 455
req/s, using uWSGI (the fastest) 474. This means that by moving this
&#8220;application&#8221; from mod_pyhton to uWSGI we would improve performance by
a measley 5%.</p>

<p>Now let&#8217;s add some database action to our so-called &#8220;application&#8221;. For
every request I&#8217;m going to pull my user record from the Django
auth_users table:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">django.contrib.auth.models</span> <span class="kn">import</span> <span class="n">User</span>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">hello</span><span class="p">(</span><span class="n">request</span><span class="p">):</span>
</span><span class='line'>    <span class="n">grisha</span> <span class="o">=</span> <span class="n">User</span><span class="o">.</span><span class="n">objects</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">username</span><span class="o">=</span><span class="s">&#39;grisha&#39;</span><span class="p">)</span>
</span><span class='line'>    <span class="n">t</span> <span class="o">=</span> <span class="n">get_template</span><span class="p">(</span><span class="s">&quot;hello.txt&quot;</span><span class="p">)</span>
</span><span class='line'>    <span class="n">c</span> <span class="o">=</span> <span class="n">Context</span><span class="p">({</span><span class="s">&#39;name&#39;</span><span class="p">:</span><span class="nb">str</span><span class="p">(</span><span class="n">grisha</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]})</span> <span class="c"># world was 5 characters</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">HttpResponse</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">c</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now we are down to 237 req/s for the mod_python WSGI handler and 245
req/s in uWSGI, and the difference between the two has shrunk to just
over 3%.</p>

<p>Mind you, our &#8220;application&#8221; still has less than 10 lines of code. In a
real-world situation the difference in performance is more likely to
amount to less than a tenth of a percent.</p>

<p>Bottom line: it&#8217;s foolish to pick your web server based on speed
alone. Factors such as your comfort level with using it, features,
documentation, security, etc., are far more important than how fast it
can crank out &#8220;Hello world!&#8221;.</p>

<p>Last, but not least, mod_python 3.4.1 (used in this article) is
ready for pre-release testing, please help me <a href="https://github.com/grisha/mod_python/issues/8">test it</a>!</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    

<section>
<script type="text/javascript"><!--
google_ad_client = "pub-9718360309690383";
google_ad_width = 200;
google_ad_height = 200;
google_ad_format = "200x200_as";
google_ad_type = "image";
//-->
</script>
<div style="text-align: center;">
  <div style="text-align: left; width: 200px; display: block; margin-left: auto; margin-right: auto;">
    <script type="text/javascript"
            src="http://pagead2.googlesyndication.com/pagead/show_ads.js">
    </script>
  </div>
</div>
</section>

<section>
  <h1>About Me</h1>

  <p>
  <div style="width: 50%; margin: 0 auto;">
  <a href="http://twitter.com/humblehack" class="twitter-follow-button"
    data-show-count="">Follow @humblehack</a>
  </div>
  </p>

  <p>I am currently a (Big Data) Hacker at <a href="http://livingsocial.com">LivingSocial</a>.</p>
  <p>Grisha is a common Russian short name for Gregory. It is pronounced more like Greesha.</p>
  <p>Years ago I wrote <a href="http://modpython.org">mod_python</a>, which became a hugely succesful OSS Project and is still in use by millions of sites.</p>
  <p>I am a former VP and member emeritus of the <a href="http://apache.org">Apache Software Foundation</a>.</p>
  <p>I started programming professionally back when I was a teenager.
  I&#8217;ve spent most of my early career working at large ISP&#8217;s solving industrial-scale hosting challenges. Since around 2009 I&#8217;ve become more intersted in and now work exclusively on &#8220;Big Data&#8221; type stuff.</p>
  <p>I was born and grew up in Moscow, Russia, though I&#8217;ve lived in the Washington, DC (USA) area for more than half of my life now. Our kids were born and go to school here, it&#8217;s gradually become home for us.</p>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2015/05/04/recording-time-series/">Time Series Accuracy - Graphite vs RRDTool</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/03/28/on-time-series/">On Time Series</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/03/20/influxdb-data/">How InfluxDB Stores Data</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/08/19/ruby_hiveserver2_and_kerberos/">Ruby, HiveServer2 and Kerberos</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/06/03/graceful-restart-in-golang/">Graceful restart in Golang</a>
      </li>
    
  </ul>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  <img src="http://www.ispol.com/grisha_org.gif" height="1" width="1">
  Copyright &copy; 2015 - Gregory Trubetskoy -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'grisha';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
