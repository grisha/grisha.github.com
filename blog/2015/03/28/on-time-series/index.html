<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>On Time Series | Gregory Trubetskoy</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="Is it even a thing?
Time Series is on its way to becoming a buzzword in the Information
Technology circles. This has to do with the looming Internet of Things
which shall cause the Great Reversal of Internet whereby upstream flow
of data produced by said Things is expected to exceed the downstream
flow. Much of this data is expected to be of the Time Series kind.
This, of course, is a money-making opportunity of the Big Data
proportions all over again, and I predict we&rsquo;re going to see a lot of
Time Series support of various shapes and forms appearing in all
manners of (mostly commercial) software.">
    <meta name="generator" content="Hugo 0.146.0">
    
    
    
      <meta name="robots" content="index, follow">
    
    <meta name="author" content="Gregory Trubetskoy">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.d05fb5f317fcf33b3a52936399bdf6f47dc776516e1692e412ec7d76f4a5faa2.css" >




    


    
      

    

    

    
      <link rel="canonical" href="https://grisha.org/blog/2015/03/28/on-time-series/">
    

    
    
    <meta property="og:url" content="https://grisha.org/blog/2015/03/28/on-time-series/">
  <meta property="og:site_name" content="Gregory Trubetskoy">
  <meta property="og:title" content="On Time Series">
  <meta property="og:description" content="Is it even a thing? Time Series is on its way to becoming a buzzword in the Information Technology circles. This has to do with the looming Internet of Things which shall cause the Great Reversal of Internet whereby upstream flow of data produced by said Things is expected to exceed the downstream flow. Much of this data is expected to be of the Time Series kind.
This, of course, is a money-making opportunity of the Big Data proportions all over again, and I predict we’re going to see a lot of Time Series support of various shapes and forms appearing in all manners of (mostly commercial) software.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2015-03-28T15:40:00+00:00">
    <meta property="article:modified_time" content="2015-03-28T15:40:00+00:00">

  <meta itemprop="name" content="On Time Series">
  <meta itemprop="description" content="Is it even a thing? Time Series is on its way to becoming a buzzword in the Information Technology circles. This has to do with the looming Internet of Things which shall cause the Great Reversal of Internet whereby upstream flow of data produced by said Things is expected to exceed the downstream flow. Much of this data is expected to be of the Time Series kind.
This, of course, is a money-making opportunity of the Big Data proportions all over again, and I predict we’re going to see a lot of Time Series support of various shapes and forms appearing in all manners of (mostly commercial) software.">
  <meta itemprop="datePublished" content="2015-03-28T15:40:00+00:00">
  <meta itemprop="dateModified" content="2015-03-28T15:40:00+00:00">
  <meta itemprop="wordCount" content="1260">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="On Time Series">
  <meta name="twitter:description" content="Is it even a thing? Time Series is on its way to becoming a buzzword in the Information Technology circles. This has to do with the looming Internet of Things which shall cause the Great Reversal of Internet whereby upstream flow of data produced by said Things is expected to exceed the downstream flow. Much of this data is expected to be of the Time Series kind.
This, of course, is a money-making opportunity of the Big Data proportions all over again, and I predict we’re going to see a lot of Time Series support of various shapes and forms appearing in all manners of (mostly commercial) software.">

      
      
    
	
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'] ],
      displayMath: [ ['$$', '$$']],
      processEscapes: true,
    },
    messageStyle: "none",
    "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
  });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  </head><body class="ma0 avenir bg-near-white production">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l center items-center justify-between">
    <a href="/" class="f3 fw2 hover-white white-90 dib no-underline">
      
        Gregory Trubetskoy
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/archives/" title="Archives page">
              Archives
            </a>
          </li>
          
        </ul>
      
      <div class="ananke-socials"></div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l mw7 center ph3 flex-wrap justify-between">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked ttu">
          
        Posts
      </aside><div id="sharing" class="mt3 ananke-socials"></div>
<h1 class="f1 athelas mt3 mb1">On Time Series</h1>
      
      <p class="tracked"><strong>Gregory Trubetskoy</strong>
      </p>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2015-03-28T15:40:00Z">March 28, 2015</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-100-l"><h2 id="is-it-even-a-thing">Is it even a thing?</h2>
<p>Time Series is on its way to becoming a buzzword in the Information
Technology circles. This has to do with the looming Internet of Things
which shall cause the Great Reversal of Internet whereby upstream flow
of data produced by said Things is expected to exceed the downstream
flow. Much of this data is expected to be of the Time Series kind.</p>
<p>This, of course, is a money-making opportunity of the Big Data
proportions all over again, and I predict we&rsquo;re going to see a lot of
Time Series support of various shapes and forms appearing in all
manners of (mostly commercial) software.</p>
<p>But is there really such a thing as the problem specifically inherent
to Time Series data which warrants a specialized solution? I&rsquo;ve been
pondering this for some time now, and I am still undecided. This
here is my attempt at arguing that TS is <em>not</em> a special problem and
that it can be done by using a database like PostgreSQL.</p>
<h2 id="influx-of-data-and-write-speeds">Influx of data and write speeds</h2>
<p>One frequently cited issue with time series data is that it arrives in
large volumes at a steady pace which renders buffered writes
useless. The number of incoming data streams can also be large
typically causing a disk seek per stream and further complicating the
write situation. TS data also has a property where often more data is
written than read because it&rsquo;s possible for a datapoint to be
collected and examined only once, if ever. In short, TS is very
write-heavy.</p>
<p>But is this unique? For example logs have almost identical
properties. The real question here is whether our tried and true
databases such as PostgreSQL are ill-equipped to deal with large
volumes of incoming data requiring an alternative solution.</p>
<p>When considering incoming data I am tempted to imagine every US
household sending it, which, of course, would require massive
infrastructure. But this (unrealistic) scenario is not a TS data
problem, it&rsquo;s one of scale, the same one from which the Hadoops and
Cassandras of this world were born. What is really happening here is
that TS happens to be yet another thing that requires the difficult to
deal with &ldquo;big data&rdquo; infrastructure and reiterates the need for an
easy-to-setup horizontally scalable database (which PostgreSQL isn&rsquo;t).</p>
<h2 id="the-backfill-problem">The backfill problem</h2>
<p>This is the problem of having to import vast amounts of historical
data. For example OpenTSDB goes to great lengths to optimize
back-filling by structuring it in specific ways and storing compressed
blobs of data.</p>
<p>But just like the write problem, it&rsquo;s not unique to TS. It
is another problem that is becoming more and more pertinent as our
backlogs of data going back to when we stopped using paper keep
growing and growing.</p>
<h2 id="downsampling">Downsampling</h2>
<p>Very often TS data is used to generate charts. This is an artifact of
the human brain being spectacularly good at interpreting a visual
representation of a relationship between streams of numbers while
nearly incapable of making sense of data in tabular form. When
plotting, no matter how much data is being examined, the end result is
limited to however many pixels are available on the display. Even
plotting aside, most any use of time series data is in an aggregated
form.</p>
<p>The process of consolidating datapoints into a smaller number (e.g.
the pixel width of the chart), sometimes called <em>downsampling</em>, involves
aggregation around a particular time interval or simply picking every
Nth datapoint.</p>
<p>As an aside, selecting every Nth row of a table is an interesting SQL
challenge, in PostgreSQL it looks like this (for every 100th row):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span> <span style="color:#66d9ef">SELECT</span> time, <span style="color:#66d9ef">data</span> <span style="color:#66d9ef">FROM</span>
</span></span><span style="display:flex;"><span>   (<span style="color:#66d9ef">SELECT</span> <span style="color:#f92672">*</span>, row_number() OVER (<span style="color:#66d9ef">ORDER</span> <span style="color:#66d9ef">BY</span> time) <span style="color:#66d9ef">as</span> n <span style="color:#66d9ef">FROM</span> data_points) dp
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">WHERE</span> dp.n <span style="color:#f92672">%</span> <span style="color:#ae81ff">100</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#66d9ef">ORDER</span> <span style="color:#66d9ef">BY</span> time
</span></span></code></pre></div><p>Aggregation over a time interval similar to how InfluxDB does it with
the <code>GROUP BY time(1d)</code> syntax can be easily achieved via the
<code>date_trunc('day', time)</code>.</p>
<p>Another aspect of downsampling is that since TS data is immutable,
there is no need to repeatedly recompute the consolidated version. It
makes more sense to downsample immediately upon the receipt of the
data and to store it permanently in this form. RRDTool&rsquo;s Round-Robin
database is based entirely on this notion. InfluxDB&rsquo;s continuous
queries is another way persistent downsampling is addressed.</p>
<p>Again, there is nothing TS-specific here. Storing data in summary form
is quite common in the data analytics world and a &ldquo;continuous query&rdquo;
is easily implemented via a trigger.</p>
<h2 id="derivatives">Derivatives</h2>
<p>Sometimes the data from various devices exists in the form of a
counter, which requires the database to derive a rate by comparing
with a previous datapoint. An example of this is number of bytes sent
over a network interface. Only the rate of change of this value is
relevant, not the number itself. The rate of change is the difference
with the previous value divided over the time interval passed.</p>
<p>Referring to a previous row is also a bit tricky but perfectly doable
in SQL. It can accomplished by using windowing functions such as
<code>lag()</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">SELECT</span> time,
</span></span><span style="display:flex;"><span>  (bytes <span style="color:#f92672">-</span> lag(bytes, <span style="color:#ae81ff">1</span>) OVER w) <span style="color:#f92672">/</span> <span style="color:#66d9ef">extract</span>(epoch <span style="color:#66d9ef">from</span> (time <span style="color:#f92672">-</span> lag(time, <span style="color:#ae81ff">1</span>) OVER w))::numeric
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">AS</span> bytes_per_sec
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">FROM</span> data_points
</span></span><span style="display:flex;"><span>  WINDOW w <span style="color:#66d9ef">AS</span> (<span style="color:#66d9ef">ORDER</span> <span style="color:#66d9ef">BY</span> time)
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">ORDER</span> <span style="color:#66d9ef">BY</span> time
</span></span></code></pre></div><h2 id="expiration">Expiration</h2>
<p>It is useful to downsample data to a less granular form as it ages,
aggregating over an ever larger period of time and possibly purging
records eventually. For example we might want to store minutely data
for a week, hourly for 3 months, daily for 3 years and drop all data
beyond 3 years.</p>
<p>Databases do not expire rows &ldquo;natively&rdquo; like Cassandra or Redis, but it
shouldn&rsquo;t be too hard to accomplish via some sort of a periodic cron
job or possibly even just triggers.</p>
<h2 id="heartbeat-and-interval-filling">Heartbeat and Interval Filling</h2>
<p>It is possible for a time series stream to pause, and this can be
interpreted in different ways: we can attempt to fill in missing data,
or treat it as unknown. More likely we&rsquo;d want to start treating it as
unknown after some period of silence. RRDTool addresses this by
introducing the notion of a <em>heartbeat</em> and the number of missed beats
before data is treated as unknown.</p>
<p>Regardless of whether the value is unknown, it is useful to be able to
fill in a gap (missing rows) in data. In PostgreSQL this can be
accomplished by a join with a result set from the <code>generate_series()</code>
function.</p>
<h2 id="data-seclusion">Data Seclusion</h2>
<p>With many specialized Time Series tools the TS data ends up being
secluded in a separate system not easily accessible from the rest of
the business data. You cannot join your customer records with data in
RRDTool or Graphite or InfluxDB, etc.</p>
<h2 id="conclusion">Conclusion</h2>
<p>If there is a problem with using PosgreSQL or some other database for
Time Series data, it is mainly that of having to use advanced SQL
syntax and possibly requiring some cookie-cutter method for managing
Time Series, especially when it is a large number or series and high
volume.</p>
<p>There is also complexity in horizontally scaling a relational database
because it involves setting up replication, sharding, methods for
recovery from failure and balancing the data. But these are not
TS-specific problems, they are scaling problems.</p>
<p>Having written this up, I&rsquo;m inclined to think that perhaps there is
no need for a specialized &ldquo;Time Series Database&rdquo;, instead it can be
accomplished by an application which uses a database for storage and
abstracts the users from the complexities of SQL and potentially even
scaling, while still allowing for direct access to the data via the
rich set of tools that a database like PostgreSQL provides.</p>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
        
        <div id="disqus_thread"></div>
<script>
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "grisha" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
      
      
      </div>
    </div></article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white white-70 dn dib-ns pv2 ph3 no-underline" href="https://grisha.org/" >
    &copy;  Gregory Trubetskoy 2026 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

  </body>
</html>
