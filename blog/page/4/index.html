
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Grisha Trubetskoy</title>
  <meta name="author" content="Gregory Trubetskoy">

  
  <meta name="description" content="Short version Avro is better than Json for storing table data Avro supports schema resolution so that the schema can evolve over time Hive supports &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://grisha.org/blog/page/4">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Grisha Trubetskoy" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="https://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

<!-- MathJax -->
<!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
  },
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
  });
</script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-42971867-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Grisha Trubetskoy</a></h1>
  
    <h2>Notes to self.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:grisha.org" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/06/06/avro/">Apache Avro</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-06-06T22:53:00-04:00" pubdate data-updated="true">Jun 6<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/06/06/avro/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h2 id="short-version">Short version</h2>

<ul>
  <li>Avro is better than Json for storing table data</li>
  <li>Avro supports schema resolution so that the schema can evolve over time</li>
  <li>Hive supports Avro and schema resolution nicely</li>
  <li>Impala (1.0) can read Avro tables, but does <em>not</em> support schema resolution</li>
  <li>Mixing compression codecs in the same table works in both Hive and Impala</li>
</ul>

<h2 id="the-tldr-version">The TL;DR version</h2>

<h3 id="introduction">Introduction</h3>

<p>If you’re logging data into Hadoop to be analyzed, chances are you’re
using JSON. JSON is great because it’s easy to generate in most any
language, it’s human-readable, it’s universally supported and
infinitely flexible.</p>

<p>It is also space inefficient, prone to errors, the standard has a few
ambiguities, all of which eventually catches up to you. It only takes
one bad record to spoil a potentially massive amount of data, and
finding the bad record and figuring out the root cause of the problem
is usually difficult and often even impossible.</p>

<p>So you might be considering a slightly more rigid and space efficient
format, and in the Hadoop world it is <a href="http://en.wikipedia.org/wiki/Apache_Avro">Apache Avro</a>.
<a href="http://avro.apache.org/docs/current/">Avro</a> is especially
compelling because it is supported by
<a href="http://blog.cloudera.com/blog/2013/05/cloudera-impala-1-0-its-here-its-real-its-already-the-standard-for-sql-on-hadoop/">Impala</a>,
while JSON isn’t (not yet, at least).</p>

<p>Named after a <a href="http://en.wikipedia.org/wiki/Avro">British aircraft maker</a>, Avro is a schema-enforced
format for serializing arbitrary data. It is in the same category as
<a href="http://en.wikipedia.org/wiki/Thrift_%28protocol%29">Thrift</a>, only it seems like Thrift has found its niche in
RPC, whereas Avro appears more compelling as the on-disk
format (even though both Avro and Thrift were designed for both storage
and RPC). Thrift seems more insistent on you using its code
generator, whereas Avro does it the old-school way, but providing
you libraries you can use in your code. (It does code generation as
well, if that’s your thing. I prefer to hand-write all my code).</p>

<p>I actually don’t want to focus on the details of what Avro is as there
is plenty information on that elsewhere. I want to share my findings
regarding Avro’s suitability as an alternative to JSON used with Hive
and JSON SerDe.</p>

<h3 id="schema-and-its-resolution">Schema (and its Resolution)</h3>

<p>Every Avro file contains a header with the schema describing (in
JSON!) the contents of the file’s records. This is very nice, because
the file contains all the knowledge necessary to be able to read it.</p>

<p>Avro was designed with the understanding that the schema may change
over time (e.g. columns added or changed), and that software designed
for a newer schema may need to read older schema files. To support
this it provides something called Schema Resolution.</p>

<p>Imagine you’ve been storing people’s names in a file. Then later on
you decided to add “age” as another attribute. Now you’re got two
schemas, one with “age” and one without. In JSON world you’d have to
adjust your program to be able to read old files with some kind of an
if/then statement to make sure that when “age” is not there the
program knows what to do. In Avro, the new schema can specify a
default for the age (e.g. 0), and whatever Avro lib you’d be using
should be able to convert a record of the old schema to the new schema
automatically, without any code modifications necessary. This is
called <em>schema resolution</em>.</p>

<h3 id="avro-support-in-hive">Avro support in Hive</h3>

<p>First we need an Avro file. Our schema is just one string column named
“test”. Here’s a quick Ruby program to generate a file of 10 random
records (you’ll need to <code>gem install avro</code>):</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="nb">require</span> <span class="s1">&#39;rubygems&#39;</span>
</span><span class="line"><span class="nb">require</span> <span class="s1">&#39;avro&#39;</span>
</span><span class="line">
</span><span class="line"><span class="n">schema</span> <span class="o">=</span> <span class="ss">Avro</span><span class="p">:</span><span class="ss">:Schema</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s1">&#39;{&quot;name&quot;:&quot;test_record&quot;, &#39;</span> <span class="o">+</span>
</span><span class="line">                            <span class="s1">&#39; &quot;type&quot;:&quot;record&quot;, &#39;</span> <span class="o">+</span>
</span><span class="line">                            <span class="s1">&#39; &quot;fields&quot;: [&#39;</span> <span class="o">+</span>
</span><span class="line">                            <span class="s1">&#39;   {&quot;name&quot;:&quot;full_name&quot;,  &quot;type&quot;:&quot;string&quot;}]}&#39;</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">writer</span> <span class="o">=</span> <span class="ss">Avro</span><span class="p">:</span><span class="ss">:IO</span><span class="o">::</span><span class="no">DatumWriter</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">schema</span><span class="p">)</span>
</span><span class="line"><span class="n">file</span> <span class="o">=</span> <span class="no">File</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;test.avro&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span>
</span><span class="line"><span class="n">dw</span> <span class="o">=</span> <span class="ss">Avro</span><span class="p">:</span><span class="ss">:DataFile</span><span class="o">::</span><span class="no">Writer</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">writer</span><span class="p">,</span> <span class="n">schema</span><span class="p">)</span>
</span><span class="line"><span class="mi">3</span><span class="o">.</span><span class="n">times</span> <span class="k">do</span>
</span><span class="line">  <span class="n">dw</span> <span class="o">&lt;&lt;</span> <span class="p">{</span><span class="s1">&#39;full_name&#39;</span><span class="o">=&gt;</span><span class="s2">&quot;X</span><span class="si">#{</span><span class="nb">rand</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span><span class="si">}</span><span class="s2"> Y</span><span class="si">#{</span><span class="nb">rand</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">}</span>
</span><span class="line"><span class="k">end</span>
</span><span class="line"><span class="n">dw</span><span class="o">.</span><span class="n">flush</span>
</span><span class="line"><span class="n">dw</span><span class="o">.</span><span class="n">close</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Then we need to create a Hive table and load our file into it:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">test_avro</span>
</span><span class="line"> <span class="k">ROW</span> <span class="n">FORMAT</span> <span class="n">SERDE</span> <span class="s1">&#39;org.apache.hadoop.hive.serde2.avro.AvroSerDe&#39;</span>
</span><span class="line"> <span class="n">STORED</span> <span class="k">AS</span> <span class="n">INPUTFORMAT</span> <span class="s1">&#39;org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat&#39;</span>
</span><span class="line"> <span class="n">OUTPUTFORMAT</span> <span class="s1">&#39;org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat&#39;</span>
</span><span class="line"> <span class="n">TBLPROPERTIES</span> <span class="p">(</span>
</span><span class="line">    <span class="s1">&#39;avro.schema.literal&#39;</span><span class="o">=</span><span class="s1">&#39;{&quot;name&quot;:&quot;test_record&quot;,</span>
</span><span class="line"><span class="s1">                            &quot;type&quot;:&quot;record&quot;,</span>
</span><span class="line"><span class="s1">                            &quot;fields&quot;: [</span>
</span><span class="line"><span class="s1">                               {&quot;name&quot;:&quot;full_name&quot;, &quot;type&quot;:&quot;string&quot;}]}&#39;</span><span class="p">);</span>
</span><span class="line">
</span><span class="line"><span class="k">LOAD</span> <span class="k">DATA</span> <span class="k">LOCAL</span> <span class="n">INPATH</span> <span class="s1">&#39;test.avro&#39;</span> <span class="n">OVERWRITE</span> <span class="k">INTO</span> <span class="k">TABLE</span> <span class="n">test_avro</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Note that the table definition needs its own schema definition, even
though our file already contains a schema. This is not a mistake. This
is the schema Hive will expect. And if the file that it’s reading is of
a different schema, it will attempt to convert it using Avro schema
resolution. Also noteworthy is that this table defines <em>no
columns</em>. The entire definition is in the <code>avro.schema.literal</code>
property.</p>

<p>Let’s make sure this is working:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="n">hive</span><span class="o">&gt;</span> <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">test_avro</span><span class="p">;</span>
</span><span class="line"><span class="n">OK</span>
</span><span class="line"><span class="n">X1800</span> <span class="n">Y9002</span>
</span><span class="line"><span class="n">X3859</span> <span class="n">Y8971</span>
</span><span class="line"><span class="n">X6935</span> <span class="n">Y5523</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Now we also happen to have Impala running, let’s see if it’s able to read this file:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="o">&gt;</span> <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">test_avro</span><span class="p">;</span>
</span><span class="line"><span class="n">Query</span><span class="p">:</span> <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">test_avro</span>
</span><span class="line"><span class="n">Query</span> <span class="n">finished</span><span class="p">,</span> <span class="n">fetching</span> <span class="n">results</span> <span class="p">...</span>
</span><span class="line"><span class="o">+</span><span class="c1">-------------+</span>
</span><span class="line"><span class="o">|</span> <span class="n">full_name</span>   <span class="o">|</span>
</span><span class="line"><span class="o">+</span><span class="c1">-------------+</span>
</span><span class="line"><span class="o">|</span> <span class="n">X1800</span> <span class="n">Y9002</span> <span class="o">|</span>
</span><span class="line"><span class="o">|</span> <span class="n">X3859</span> <span class="n">Y8971</span> <span class="o">|</span>
</span><span class="line"><span class="o">|</span> <span class="n">X6935</span> <span class="n">Y5523</span> <span class="o">|</span>
</span><span class="line"><span class="o">+</span><span class="c1">-------------+</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>So far so good! Now let’s create a second avro file, with one
additional column <code>age</code>, using the following Ruby:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
</pre></td><td class="code"><pre><code class="ruby"><span class="line"><span class="n">schema</span> <span class="o">=</span> <span class="ss">Avro</span><span class="p">:</span><span class="ss">:Schema</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s1">&#39;{&quot;name&quot;:&quot;test_record&quot;, &#39;</span> <span class="o">+</span>
</span><span class="line">                            <span class="s1">&#39; &quot;type&quot;:&quot;record&quot;, &#39;</span> <span class="o">+</span>
</span><span class="line">                            <span class="s1">&#39; &quot;fields&quot;: [&#39;</span> <span class="o">+</span>
</span><span class="line">                            <span class="s1">&#39;   {&quot;name&quot;:&quot;full_name&quot;,  &quot;type&quot;:&quot;string&quot;},&#39;</span> <span class="o">+</span>
</span><span class="line">                            <span class="s1">&#39;   {&quot;name&quot;:&quot;age&quot;,        &quot;type&quot;:&quot;int&quot;}]}&#39;</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">writer</span> <span class="o">=</span> <span class="ss">Avro</span><span class="p">:</span><span class="ss">:IO</span><span class="o">::</span><span class="no">DatumWriter</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">schema</span><span class="p">)</span>
</span><span class="line"><span class="n">file</span> <span class="o">=</span> <span class="no">File</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;test2.avro&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span>
</span><span class="line"><span class="n">dw</span> <span class="o">=</span> <span class="ss">Avro</span><span class="p">:</span><span class="ss">:DataFile</span><span class="o">::</span><span class="no">Writer</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">writer</span><span class="p">,</span> <span class="n">schema</span><span class="p">)</span>
</span><span class="line"><span class="mi">3</span><span class="o">.</span><span class="n">times</span> <span class="k">do</span>
</span><span class="line">  <span class="n">dw</span> <span class="o">&lt;&lt;</span> <span class="p">{</span><span class="s1">&#39;full_name&#39;</span><span class="o">=&gt;</span><span class="s2">&quot;X</span><span class="si">#{</span><span class="nb">rand</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span><span class="si">}</span><span class="s2"> Y</span><span class="si">#{</span><span class="nb">rand</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s1">&#39;age&#39;</span><span class="o">=&gt;</span><span class="nb">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">)}</span>
</span><span class="line"><span class="k">end</span>
</span><span class="line"><span class="n">dw</span><span class="o">.</span><span class="n">flush</span>
</span><span class="line"><span class="n">dw</span><span class="o">.</span><span class="n">close</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Let’s load this into Hive and see if it still works. (No OVERWRITE
keyword this time, we’re appending a second file to our table).</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="n">hive</span><span class="o">&gt;</span> <span class="k">LOAD</span> <span class="k">DATA</span> <span class="k">LOCAL</span> <span class="n">INPATH</span> <span class="s1">&#39;test2.avro&#39;</span> <span class="k">INTO</span> <span class="k">TABLE</span> <span class="n">test_avro</span><span class="p">;</span>
</span><span class="line"><span class="n">OK</span>
</span><span class="line"><span class="n">hive</span><span class="o">&gt;</span> <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">test_avro</span><span class="p">;</span>
</span><span class="line"><span class="n">OK</span>
</span><span class="line"><span class="n">X1800</span> <span class="n">Y9002</span>
</span><span class="line"><span class="n">X3859</span> <span class="n">Y8971</span>
</span><span class="line"><span class="n">X6935</span> <span class="n">Y5523</span>
</span><span class="line"><span class="n">X4720</span> <span class="n">Y1361</span>
</span><span class="line"><span class="n">X4605</span> <span class="n">Y3067</span>
</span><span class="line"><span class="n">X7007</span> <span class="n">Y7852</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>This is working exactly as expected. Hive has shown the 3 original
records as before, and the 3 new ones got converted to Hive’s version
of the schema, where the “age” column does not exist.</p>

<p>Let’s see what Impala thinks of this:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="o">&gt;</span> <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">test_avro</span><span class="p">;</span>
</span><span class="line"><span class="n">Query</span><span class="p">:</span> <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">test_avro</span>
</span><span class="line"><span class="n">Query</span> <span class="n">finished</span><span class="p">,</span> <span class="n">fetching</span> <span class="n">results</span> <span class="p">...</span>
</span><span class="line"><span class="o">+</span><span class="c1">-------------+</span>
</span><span class="line"><span class="o">|</span> <span class="n">full_name</span>   <span class="o">|</span>
</span><span class="line"><span class="o">+</span><span class="c1">-------------+</span>
</span><span class="line"><span class="o">|</span> <span class="n">X1800</span> <span class="n">Y9002</span> <span class="o">|</span>
</span><span class="line"><span class="o">|</span> <span class="n">X3859</span> <span class="n">Y8971</span> <span class="o">|</span>
</span><span class="line"><span class="o">|</span> <span class="n">X6935</span> <span class="n">Y5523</span> <span class="o">|</span>
</span><span class="line"><span class="o">+</span><span class="c1">-------------+</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Alas - we’re only getting the 3 original rows. Bummer! What’s
worrisome is that <em>no indication</em> was given to us that 3 other rows got
swallowed because Impala didn’t do schema resolution. (I’ve posted
regarding this on the Impala users list, awaiting response).</p>

<p>Now let’s alter the table schema so that age is part of it. (This is
not your typical ALTER TABLE, we’re just changing <code>avro.schema.literal</code>).</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="n">hive</span><span class="o">&gt;</span> <span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">test_avro</span> <span class="k">SET</span> <span class="n">TBLPROPERTIES</span> <span class="p">(</span>
</span><span class="line">    <span class="s1">&#39;avro.schema.literal&#39;</span><span class="o">=</span><span class="s1">&#39;{&quot;name&quot;:&quot;test_record&quot;,</span>
</span><span class="line"><span class="s1">                            &quot;type&quot;:&quot;record&quot;,</span>
</span><span class="line"><span class="s1">                            &quot;fields&quot;: [</span>
</span><span class="line"><span class="s1">                              {&quot;name&quot;:&quot;full_name&quot;, &quot;type&quot;:&quot;string&quot;},</span>
</span><span class="line"><span class="s1">                              {&quot;name&quot;:&quot;age&quot;,  &quot;type&quot;:&quot;int&quot;}]}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="n">OK</span>
</span><span class="line"><span class="n">hive</span><span class="o">&gt;</span> <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">test_avro</span><span class="p">;</span>
</span><span class="line"><span class="n">OK</span>
</span><span class="line"><span class="n">Failed</span> <span class="k">with</span> <span class="n">exception</span> <span class="n">java</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">IOException</span><span class="p">:</span><span class="n">org</span><span class="p">.</span><span class="n">apache</span><span class="p">.</span><span class="n">avro</span><span class="p">.</span><span class="n">AvroTypeException</span><span class="p">:</span> <span class="k">Found</span> <span class="n">test_record</span><span class="p">,</span> <span class="n">expecting</span> <span class="n">test_record</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>This error should not be surprising. Hive is trying to provide a value
for <code>age</code> for those records where it did not exist, but we neglected
to specify a default. (The error message <em>is</em> a little cryptic,
though). So let’s try again, this time with a default:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="n">hive</span><span class="o">&gt;</span> <span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">test_avro</span> <span class="k">SET</span> <span class="n">TBLPROPERTIES</span> <span class="p">(</span>
</span><span class="line">    <span class="s1">&#39;avro.schema.literal&#39;</span><span class="o">=</span><span class="s1">&#39;{&quot;name&quot;:&quot;test_record&quot;,</span>
</span><span class="line"><span class="s1">                            &quot;type&quot;:&quot;record&quot;,</span>
</span><span class="line"><span class="s1">                            &quot;fields&quot;: [</span>
</span><span class="line"><span class="s1">                              {&quot;name&quot;:&quot;full_name&quot;, &quot;type&quot;:&quot;string&quot;},</span>
</span><span class="line"><span class="s1">                              {&quot;name&quot;:&quot;age&quot;,  &quot;type&quot;:&quot;int&quot;, &quot;default&quot;:999}]}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="n">OK</span>
</span><span class="line"><span class="n">hive</span><span class="o">&gt;</span> <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">test_avro</span><span class="p">;</span>
</span><span class="line"><span class="n">OK</span>
</span><span class="line"><span class="n">X1800</span> <span class="n">Y9002</span>     <span class="mi">999</span>
</span><span class="line"><span class="n">X3859</span> <span class="n">Y8971</span>     <span class="mi">999</span>
</span><span class="line"><span class="n">X6935</span> <span class="n">Y5523</span>     <span class="mi">999</span>
</span><span class="line"><span class="n">X4720</span> <span class="n">Y1361</span>     <span class="mi">10</span>
</span><span class="line"><span class="n">X4605</span> <span class="n">Y3067</span>     <span class="mi">34</span>
</span><span class="line"><span class="n">X7007</span> <span class="n">Y7852</span>     <span class="mi">17</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Woo-hoo!</p>

<h3 id="other-notes">Other notes</h3>

<ul>
  <li>There is a nice Avro-C library, but it currently does not support defaults (version 1.7.4).</li>
  <li>Some <a href="http://code.google.com/p/thrift-protobuf-compare/wiki/Benchmarking">benchmarks</a></li>
  <li>Avro’s integer encoding is same as Lucene with <a href="https://developers.google.com/protocol-buffers/docs/encoding#types">zigzag encoding</a>
 on top of it. (It’s just like SQLite, only little-endian). Curiously,
 it is used for <em>all</em> integers, including array indexes internal to
 Avro, which can never be negative and thus ZigZag is of no use. This
 is probably to keep all integer operation consistent.</li>
  <li>A curious post on how Lucene/Avro variable-integer format is <a href="http://blog.mikemccandless.com/2010/07/moving-readvint-to-c.html">CPU-unfriendly</a></li>
</ul>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/05/31/simple-solution-to-password-reuse/">Simple Solution to Password Reuse</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-05-31T17:12:00-04:00" pubdate data-updated="true">May 31<span>st</span>, 2013</time>
        
         | <a href="/blog/2013/05/31/simple-solution-to-password-reuse/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>
Here&#8217;s a <a href="http://en.wikipedia.org/wiki/KISS_principle">KISS</a> solution to all your password reuse
problems. It requires remembering only *one* strong password, lets you
have a virtually limitless number of passwords, and, most importantly,
does NOT store anything anywhere or transfer anything over the
network (100% browser-side Javascript).
</p>

<script type="text/javascript" src="/javascripts/sha.js"></script>

<script type="text/javascript" src="/javascripts/zxcvbn-async.js"></script>

<script type="text/javascript">
function calc_pw(n) {
  try {
    var pw_phrase = document.getElementById("pw_phrase");
    var keyword = document.getElementById("keyword"+n);
    var pw = document.getElementById("pw"+n);
    var strength = document.getElementById("strength");
    var hmacObj = new jsSHA(pw_phrase.value, "TEXT");
    pw.value = hmacObj.getHMAC(keyword.value, "TEXT", "SHA-512", "B64").substring(5,15);
    if (pw.value.search('!') === -1) pw.value = pw.value + '!'
    if (pw.value.search(/[0-9]/) === -1) pw.value = pw.value + '0'
  } catch(e) {
    pw.value = "ERROR: " + e;
  }
}
function pw_strength() {
    var pw_phrase = document.getElementById("pw_phrase");
    var score = zxcvbn(pw_phrase.value).score;
    if (score == '0') {strength.value = 'Very Weak'; strength.style.color = 'red'; }
    else if (score == '1') {strength.value = 'Weak'; strength.style.color = 'red'; }
    else if (score == '2') {strength.value = 'So so'; strength.style.color = 'orange'; }
    else if (score == '3') {strength.value = 'Okay'; strength.style.color = 'blue'; }
    else if (score == '4') {strength.value = 'Strong'; strength.style.color = 'green'; }
    else strength.value = '';
}
function check_pw2_same() {
  var pw_phrase = document.getElementById("pw_phrase");
  var pw_phrase2 = document.getElementById("pw_phrase2");
  var pw_same = document.getElementById("pw_same");
  if (pw_phrase.value === pw_phrase2.value)
    pw_same.value = 'Correct';
  else
    pw_same.value = 'Incorrect';
}
function clear_all() {
  document.getElementById("pw_phrase").value = '';
  document.getElementById("pw_phrase2").value = '';
  document.getElementById("strength").value = '';
  document.getElementById("pw_same").value = '';
  document.getElementById("keyword1").value = 'amazon';
  document.getElementById("keyword2").value = 'gmail';
  document.getElementById("keyword3").value = 'yahoo';
  document.getElementById("keyword4").value = 'foo';
  document.getElementById("keyword5").value = 'bar';
  document.getElementById("pw1").value = '';
  document.getElementById("pw2").value = '';
  document.getElementById("pw3").value = '';
  document.getElementById("pw4").value = '';
  document.getElementById("pw5").value = '';
}
</script>

<form action="#" method="get">
<fieldset style="margin: 3px 0px; border: 1px solid #000000; padding: 10px;">
<legend>Stupid Simple Password Generator</legend>
<h3>Step 1:</h3>
<p>
Think of a phrase you will always remember. Keep typing until the text
on the right says &#8220;strong&#8221;. Punctuation, spaces, unusual words and
mixed case while not required, are generally a good idea. The most
important thing is that the script considers it <span style="color: green; font-weight: bold;">strong</span>.
</p>

<p> Make sure this passphrase is impossible to guess by people who
know you, e.g. don&#8217;t pick quotes from your favorite song or
movie. Don&#8217;t <em>ever</em> write it down or save it on your computer in any way or form!
<table border="0">
<tr><th>Passphrase: </th><td><input type="password" size="60" name="pw_phrase" id="pw_phrase" style="margin-right: 1em; margin-left: 1em;" onkeyup="pw_strength()" />
<th>Strength: </th><td><input tpye="text" size="10" name="strength" id="strength" style="font-weight: bold; margin-left: 1em;" readonly="" /></td>
<tr><th>Verify: </th><td><input type="password" size="60" name="pw_phrase2" id="pw_phrase2" style="margin-right: 1em; margin-left: 1em;" onkeyup="check_pw2_same()" />
<th>Correct: </th><td><input tpye="text" size="10" name="pw_same" id="pw_same" style="font-weight: bold; margin-left: 1em;" readonly="" /></td>



<h3>Step 2:</h3>
<p> Think of a short keyword describing a password, e.g. &#8220;amazon&#8221;,
&#8220;gmail&#8221;, etc. This word has to be easy to remember and there is no need for
it to be unique or hard to guess.</p>

<table border="0">
<tr><th>Keyword</th><th>Password</th></tr>
<tr><td><input type="text" size="30" name="keyword1" id="keyword1" value="gmail" onkeyup="calc_pw(1)" /></td><td><input type="text" size="30" name="pw1" id="pw1" style="margin-left: 1em;" readonly="" /></td></tr>
<tr><td><input type="text" size="30" name="keyword2" id="keyword2" value="gmail" onkeyup="calc_pw(2)" /></td><td><input type="text" size="30" name="pw2" id="pw2" style="margin-left: 1em;" readonly="" /></td></tr>
<tr><td><input type="text" size="30" name="keyword3" id="keyword3" value="gmail" onkeyup="calc_pw(3)" /></td><td><input type="text" size="30" name="pw3" id="pw3" style="margin-left: 1em;" readonly="" /></td></tr>
<tr><td><input type="text" size="30" name="keyword4" id="keyword4" value="gmail" onkeyup="calc_pw(4)" /></td><td><input type="text" size="30" name="pw4" id="pw4" style="margin-left: 1em;" readonly="" /></td></tr>
<tr><td><input type="text" size="30" name="keyword5" id="keyword5" value="gmail" onkeyup="calc_pw(5)" /></td><td><input type="text" size="30" name="pw5" id="pw5" style="margin-left: 1em;" readonly="" /></td></tr>
</table>
<br />
<p>That&#8217;s it! You can regenerate any of the passwords above at any time by coming back to this page, all you need to know is the passphrase (and the keywords).</p>




<span style="font-size: 12px">Fine print: This is a proof-of-concept, use at your own risk!</span>
<body onload="clear_all()" />


<h2>How does it work?</h2>

First, credits where they are due: This page uses <a href="https://github.com/Caligatio/">Brian Turek&#8217;s</a>
excellent <a href="https://github.com/Caligatio/jsSHA">jsSHA</a> Javascript SHA lib and
<a href="https://github.com/lowe">Dan Wheeler&#8217;s</a> amazing <a href="https://github.com/lowe/zxcvbn">zxcvbn</a>
password strength checking lib.

All we are doing here is computing a SHA-512 of the passphrase +
keyword, then selecting a substring of the result. (We also append a 0
and/or a ! to satisfy most password checker requirements for numbers
and punctuation).

If you don&#8217;t trust that generated passwords are strong, just paste
them into the passphrase field, I assure you, no password here will
ever be weak. (Or, rather, it is <em>extremely</em> unlikely).

Some improvements could be made, but the point here is that there is
no reason to keep encrypted files with your passwords along with
software to open them around, all that&#8217;s needed is <em>one</em> strong
password and a well established and easily available algorithm.
</td></tr></td></tr></table></p></fieldset></form>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/05/31/compiling-impala-from-github/">Compiling Impala From Github</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-05-31T10:48:00-04:00" pubdate data-updated="true">May 31<span>st</span>, 2013</time>
        
         | <a href="/blog/2013/05/31/compiling-impala-from-github/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Apparently Impala has two versions of source code, one internal to
Cloudera, the other available on Github. I’m presuming that code gets
released to Github once undergone some level of internal scrutiny, but
I’ve not seen any documentation on how one could tie publically
available code to the official Impala (binary) release, currently 1.0.</p>

<p>Anyway, I tried compiling the github code last night, and here are the
steps that worked for me.</p>

<p>My setup:</p>

<ul>
  <li>
    <p>Linux CentOS 6.2 (running inside a VirtualBox instance on an Early 2011 MacBook, Intel i7).</p>
  </li>
  <li>
    <p>CDH 4.3 installed using Cloudera RPM’s. No configuration was done, I
just ran yum install as described in the installation guide.</p>
  </li>
  <li>
    <p>Impala checked out from Github, HEAD is 60cb0b75 (Mon May 13 09:36:37 2013).</p>
  </li>
  <li>
    <p>Boost 1.42, compiled and installed manually (see below).</p>
  </li>
</ul>

<p>The steps I followed:</p>

<ul>
  <li>Check out Impala:</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">git clone git://github.com/cloudera/impala.git
</span><span class="line">&lt;...&gt;
</span><span class="line">
</span><span class="line">git branch -v
</span><span class="line">* master 60cb0b7 Fixed formatting in README
</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>Install Impala pre-requisites as per Impala README, except for Boost:</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">sudo yum install libevent-devel automake libtool flex bison gcc-c++ openssl-devel <span class="se">\</span>
</span><span class="line">    make cmake doxygen.x86_64 glib-devel python-devel bzip2-devel svn <span class="se">\</span>
</span><span class="line">    libevent-devel cyrus-sasl-devel wget git unzip
</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>
    <p>Install LLVM. Follow the precise steps in the Impala README, it works.</p>
  </li>
  <li>
    <p>Make sure you have the Oracle JDK 6, not OpenJDK. I found <a href="http://www.if-not-true-then-false.com/2010/install-sun-oracle-java-jdk-jre-6-on-fedora-centos-red-hat-rhel/">this link</a> helpful.</p>
  </li>
  <li>
    <p>Remove the CentOS version of Boost (1.41) if you have it. Impala
needs uuid, which is only supported in 1.42 and later:</p>
  </li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="c"># YMMV - this is how I did it, you may want to be more cautious</span>
</span><span class="line">sudo yum erase <span class="sb">`</span>rpm -qa | grep boost<span class="sb">`</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>
    <p>Download and untar Boost 1.42 from [http://www.boost.org/users/history/version<em>1</em>42<em>0.html](http://www.boost.org/users/history/version</em>1<em>42</em>0.html)</p>
  </li>
  <li>
    <p>Compile and install Boost. Note that Boost <em>must</em> be compiled with multi-threaded support and the layout matters too. I ended up up using the following:</p>
  </li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nb">cd </span>boost_1_42_0/
</span><span class="line">./bootstrap.sh
</span><span class="line"><span class="c"># not sure how necessary the --libdir=/usr/lib64 is, there was a post mentioning it, i followed this advice blindly</span>
</span><span class="line">./bjam --libdir<span class="o">=</span>/usr/lib64 <span class="nv">threading</span><span class="o">=</span>multi --layout<span class="o">=</span>tagged
</span><span class="line">sudo ./bjam --libdir<span class="o">=</span>/usr/lib64 <span class="nv">threading</span><span class="o">=</span>multi --layout<span class="o">=</span>tagged install
</span></code></pre></td></tr></table></div></figure></notextile></div>

<ul>
  <li>
    <p>Install Maven, just like the README says, only the URL didn’t work, I used
<a href="http://archive.apache.org/dist/maven/binaries/apache-maven-3.0.4-bin.tar.gz">http://archive.apache.org/dist/maven/binaries/apache-maven-3.0.4-bin.tar.gz</a> instead</p>
  </li>
  <li>
    <p>Now you should be able to compile Impala - just follow the steps in the README starting with <code>. bin/impala-config.sh</code></p>
  </li>
</ul>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/05/29/sqlite-db-stored-in-a-redis-hash/">SQLite DB Stored in a Redis Hash</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-05-29T17:08:00-04:00" pubdate data-updated="true">May 29<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/05/29/sqlite-db-stored-in-a-redis-hash/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>In a <a href="/blog/2013/05/11/relational-database-on-top-of-key-value-store-explained/">recent post</a>
I explained how a relational database could be backed by a key-value
store by virtue of B-Trees. This sounded great in theory, but I wanted
to see that it actually works. And so last night I wrote a 
<a href="https://github.com/grisha/thredis/commit/2beaee3a13f0dbe0c161470da04ef8af21d78fc9">commit</a> to 
<a href="http://thredis.org/">Thredis</a>, which does exactly that.</p>

<p>If you’re not familiar with Thredis - it’s something I hacked together
last Christmas. Thredis started out as threaded Redis, but eventually
evolved into SQLite + Redis. Thredis uses a separate file to save
SQLite data. But with this patch it’s no longer necessary - a SQLite
DB is entirely stored in a Redis Hash object.</p>

<p>A very neat side-effect of this little hack is that it lets a SQLite
database be automatically replicated using Redis replication.</p>

<p>I was able to code this fairly easily because SQLite provides a very nice way of
implementing a custom <a href="http://www.sqlite.org/vfs.html">Virtual File System</a> (VFS).  </p>

<p>Granted this is only proof-of-concept and not anything you should dare
use anywhere near production, it’s enough to get a little taste, so
let’s start an empty Thredis instance and create a SQL table:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
</pre></td><td class="code"><pre><code class=""><span class="line">$ redis-cli
</span><span class="line">redis 127.0.0.1:6379&gt; sql "create table test (a int, b text)"
</span><span class="line">(integer) 0
</span><span class="line">redis 127.0.0.1:6379&gt; sql "insert into test values (1, 'hello')"
</span><span class="line">(integer) 1
</span><span class="line">redis 127.0.0.1:6379&gt; sql "select * from test"
</span><span class="line">1) 1) 1) "a"
</span><span class="line">      2) "int"
</span><span class="line">   2) 1) "b"
</span><span class="line">      2) "text"
</span><span class="line">2) 1) (integer) 1
</span><span class="line">   2) "hello"
</span><span class="line">redis 127.0.0.1:6379&gt; 
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Now let’s start a slave on a different port and fire up another
redis-client to connect to it. (This means <code>slaveof</code> is set to
localhost:6379 and <code>slave-read-only</code> is set to false, I won’t bore you
with a paste of the config here).</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class=""><span class="line">$ redis-cli -p 6380
</span><span class="line">redis 127.0.0.1:6380&gt; sql "select * from test"
</span><span class="line">1) 1) 1) "a"
</span><span class="line">      2) "int"
</span><span class="line">   2) 1) "b"
</span><span class="line">      2) "text"
</span><span class="line">2) 1) (integer) 1
</span><span class="line">   2) "hello"
</span><span class="line">redis 127.0.0.1:6380&gt; </span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Here you go - the DB’s replicated!</p>

<p>You can also see what SQLite data looks like in Redis (not terribly exciting):</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class=""><span class="line">redis 127.0.0.1:6379&gt; hlen _sql:redis_db
</span><span class="line">(integer) 2
</span><span class="line">redis 127.0.0.1:6379&gt; hget _sql:redis_db 0
</span><span class="line">"SQLite format 3\x00 \x00\x01\x01\x00@  \x00\x00\x00\x02\x00\x00\x00\x02\x00\x00 ...</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Another potential benefit to this approach is that with not too much
more tinkering the database could be backed by 
<a href="http://redis.io/topics/cluster-spec">Redis Cluster</a>, which would give you a
fully-functional horizontally-scalable clustered in-memory SQL
database.  Of course, only the <em>store</em> would be distributed, not the
query <em>processing</em>. So this would be no match to Impala and the like
which can process queries in a distributed fasion, but still, it’s
pretty cool for some 300 lines of code, n’est-ce pas?</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/05/23/checking-out-cloudera-impala/">Checking Out Cloudera Impala</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-05-23T12:43:00-04:00" pubdate data-updated="true">May 23<span>rd</span>, 2013</time>
        
         | <a href="/blog/2013/05/23/checking-out-cloudera-impala/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I’ve decided to check out
<a href="http://blog.cloudera.com/blog/2012/10/cloudera-impala-real-time-queries-in-apache-hadoop-for-real/">Impala</a>
last week and here’s some notes on how that went.</p>

<h2 id="first-thoughts">First thoughts</h2>

<p>I was very impressed with how easy it was to install, even considering
our unusual set up (see below). In my simple ad-hoc tests Impala
performed orders of magnitude faster than Hive. So far it seems solid
down to the little details, like the shell prompt with a fully
functional libreadline and column headers nicely formatted.</p>

<h2 id="installing">Installing</h2>

<p>The first problem I encountered was that we use Cloudera
<a href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDHTarballs/3.25.2013/CDH4-Downloadable-Tarballs/CDH4-Downloadable-Tarballs.html">tarballs</a>
in our set up, but Impala is only available as a package (RPM in our
case). I tried compiling it from
<a href="https://github.com/cloudera/impala">source</a>, but it’s not a trivial
compile - it requires <a href="http://llvm.org/">LLVM</a> (which is way cool,
BTW) and has a bunch of dependencies, it didn’t work out-of-the-box
for me so I’ve decided to take an alternative route (I will definitely get it compiled some weekend soon). </p>

<p>Retreiving contents of an RPM is trivial (because it’s really a cpio
archive), and then I’d just have to “make it work”.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class=""><span class="line">$ curl -O http://archive.cloudera.com/impala/redhat/6/x86_64/impala/1.0/RPMS/x86_64/impala-server-1.0-1.p0.819.el6.x86_64.rpm
</span><span class="line">$ mkdir impala
</span><span class="line">$ cd impala
</span><span class="line">$ rpm2cpio ../impala-server-1.0-1.p0.819.el6.x86_64.rpm | cpio -idmv</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>I noticed that <code>usr/bin/impalad</code> is a shell script, and it appears to
rely on a few environment vars for configuration, so I created a shell
script that sets them which looks approximately like this:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nb">export </span><span class="nv">JAVA_HOME</span><span class="o">=</span>/usr/java/default
</span><span class="line"><span class="nb">export </span><span class="nv">IMPALA_LOG_DIR</span><span class="o">=</span> <span class="c"># your log dir</span>
</span><span class="line"><span class="nb">export </span><span class="nv">IMPALA_STATE_STORE_PORT</span><span class="o">=</span>24000
</span><span class="line"><span class="nb">export </span><span class="nv">IMPALA_STATE_STORE_HOST</span><span class="o">=</span> <span class="c"># probably namenode host or whatever</span>
</span><span class="line"><span class="nb">export </span><span class="nv">IMPALA_BACKEND_PORT</span><span class="o">=</span>22000
</span><span class="line">
</span><span class="line"><span class="nb">export </span><span class="nv">IMPALA_HOME</span><span class="o">=</span> <span class="c"># full path to usr/lib/impala from the RPM, e.g. /home/grisha/impala/usr/lib/impala</span>
</span><span class="line"><span class="nb">export </span><span class="nv">IMPALA_CONF_DIR</span><span class="o">=</span> <span class="c"># config dir, e.g. /home/grisha/impala/etc/impala&quot;</span>
</span><span class="line"><span class="nb">export </span><span class="nv">IMPALA_BIN</span><span class="o">=</span><span class="k">${</span><span class="nv">IMPALA_HOME</span><span class="k">}</span>/sbin-retail
</span><span class="line"><span class="nb">export </span><span class="nv">LIBHDFS_OPTS</span><span class="o">=</span>-Djava.library.path<span class="o">=</span><span class="k">${</span><span class="nv">IMPALA_HOME</span><span class="k">}</span>/lib
</span><span class="line"><span class="nb">export </span><span class="nv">MYSQL_CONNECTOR_JAR</span><span class="o">=</span> <span class="c"># full path a mysql-connect jar</span>
</span><span class="line">
</span><span class="line"><span class="nb">export </span><span class="nv">HIVE_HOME</span><span class="o">=</span> <span class="c"># your hive home - note: every impala nodes needs it, just config, not the whole Hive install</span>
</span><span class="line"><span class="nb">export </span><span class="nv">HIVE_CONF_DIR</span><span class="o">=</span> <span class="c"># this seems redundant, my guess HIVE_HOME is enough, but whatever</span>
</span><span class="line"><span class="nb">export </span><span class="nv">HADOOP_CONF_DIR</span><span class="o">=</span> <span class="c"># path the hadoop config, the dir that has hdfs-site.xml, etc.</span>
</span><span class="line">
</span><span class="line"><span class="nb">export </span><span class="nv">IMPALA_STATE_STORE_ARGS</span><span class="o">=</span><span class="s2">&quot; -log_dir=${IMPALA_LOG_DIR} -state_store_port=${IMPALA_STATE_STORE_PORT}&quot;</span>
</span><span class="line"><span class="nb">export </span><span class="nv">IMPALA_SERVER_ARGS</span><span class="o">=</span><span class="s2">&quot; \                                                                                                                                                                                  -log_dir=${IMPALA_LOG_DIR} \                                                                                                                                                                              -state_store_port=${IMPALA_STATE_STORE_PORT} \                                                                                                                                                            -use_statestore \                                                                                                                                                                                         -state_store_host=${IMPALA_STATE_STORE_HOST} \                                                                                                                                                            -be_port=${IMPALA_BACKEND_PORT}&quot;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>With the above environment vars set, starting Impala should amount to
the following (you probably want to run those in separate windows, also note that
the state store needs to be started first):</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">$ </span>./usr/bin/statestored <span class="k">${</span><span class="nv">IMPALA_STATE_STORE_ARGS</span><span class="k">}</span> <span class="c"># do this on IMPALA_STATE_STORE_HOST only</span>
</span><span class="line"><span class="nv">$ </span>./usr/bin/impalad <span class="k">${</span><span class="nv">IMPALA_SERVER_ARGS</span><span class="k">}</span> <span class="c"># do this on every node</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The only problem that I encountered was that Impala needed
short-circuit access enabled, so I had to add the following to the hdfs-site.xml:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
</pre></td><td class="code"><pre><code class="xml"><span class="line"> <span class="nt">&lt;property&gt;</span>
</span><span class="line">   <span class="nt">&lt;name&gt;</span>dfs.client.read.shortcircuit<span class="nt">&lt;/name&gt;</span>
</span><span class="line">   <span class="nt">&lt;value&gt;</span>true<span class="nt">&lt;/value&gt;</span>
</span><span class="line"> <span class="nt">&lt;/property&gt;</span>
</span><span class="line"> <span class="nt">&lt;property&gt;</span>
</span><span class="line">   <span class="nt">&lt;name&gt;</span>dfs.domain.socket.path<span class="nt">&lt;/name&gt;</span>
</span><span class="line"><span class="c">&lt;!-- adjust this to your set up: --&gt;</span>
</span><span class="line">   <span class="nt">&lt;value&gt;</span>/var/run/dfs_domain_socket_PORT.sock<span class="nt">&lt;/value&gt;</span>
</span><span class="line"> <span class="nt">&lt;/property&gt;</span>
</span><span class="line"> <span class="nt">&lt;property&gt;</span>
</span><span class="line">   <span class="nt">&lt;name&gt;</span>dfs.client.file-block-storage-locations.timeout<span class="nt">&lt;/name&gt;</span>
</span><span class="line">   <span class="nt">&lt;value&gt;</span>3000<span class="nt">&lt;/value&gt;</span>
</span><span class="line"> <span class="nt">&lt;/property&gt;</span>
</span><span class="line"> <span class="nt">&lt;property&gt;</span>
</span><span class="line"><span class="c">&lt;!-- adjust this too: --&gt;</span>
</span><span class="line">   <span class="nt">&lt;name&gt;</span>dfs.block.local-path-access.user<span class="nt">&lt;/name&gt;</span>
</span><span class="line">   <span class="nt">&lt;value&gt;</span><span class="c">&lt;!-- user name --&gt;</span><span class="nt">&lt;/value&gt;</span>
</span><span class="line"> <span class="nt">&lt;/property&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Once the above works, we need <code>impala-shell</code> to test it. Again, I pulled it out of the RPM:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="xml"><span class="line">$ curl -O http://archive.cloudera.com/impala/redhat/6/x86_64/impala/1.0/RPMS/x86_64/impala-shell-1.0-1.p0.819.el6.x86_64.rpm
</span><span class="line">$ mkdir shell ; cd shell
</span><span class="line">$ rpm2cpio ../impala-shell-1.0-1.p0.819.el6.x86_64.rpm | cpio -idmv
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>I was then able to start the shell and connect. You can connect to any Impala node (read the docs):</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
</pre></td><td class="code"><pre><code class="xml"><span class="line">$ ./usr/bin/impala-shell
</span><span class="line">[localhost:21000] &gt; connect some_node;
</span><span class="line">Connected to some_node:21000
</span><span class="line">Server version: impalad version 1.0 RELEASE (build d1bf0d1dac339af3692ffa17a5e3fdae0aed751f)
</span><span class="line">[some_node:21000] &gt; select count(*) from your_favorite_table;
</span><span class="line">Query: select count(*) from your_favorite_table
</span><span class="line">Query finished, fetching results ...
</span><span class="line">+-----------+
</span><span class="line">| count(*)  |
</span><span class="line">+-----------+
</span><span class="line">| 302052158 |
</span><span class="line">+-----------+
</span><span class="line">Returned 1 row(s) in 2.35s
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Ta-da! The above query takes a good few minutes in Hive, BTW.</p>

<h2 id="other-notes">Other Notes</h2>

<ul>
  <li>Impala does not support custom SerDe’s so it won’t work if you’re relying on JSON. It does support Avro.</li>
  <li>There is no support for UDF’s, so our <a href="https://github.com/livingsocial/HiveSwarm">HiveSwarm</a> is of no use.</li>
  <li>INSERT OVERWRITE works, which is good.</li>
  <li>LZO support works too.</li>
  <li><em>Security Warning</em>: Everything Impala does will appear in HDFS as
the user under which Impala is running. Be careful with this if
you’re relying on HDFS permissions to prevent an accidental “INSERT
OVERWRITE”, as you might inadvertently give your users superuser
privs on HDFS via Hue, for example. (Oh did I mention Hue completely
supports Impala too?). From what I can tell there is no way to set a
username, this is a bit of a show-stopper for us, actually.</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/05/11/relational-database-on-top-of-key-value-store-explained/">Relational Database on Top of Key-value Store Explained (or Why B-trees Are Cool)</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-05-11T11:36:00-04:00" pubdate data-updated="true">May 11<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/05/11/relational-database-on-top-of-key-value-store-explained/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>This post attempts to explain how a relational database can be
implemented atop a key/value store, a subject that I’ve long found
rather mysterious.</p>

<p>Every once in a while I would come across a mention that a relational
database can be implemented using a key/value store (aka dictionary,
hash table or hash map - for brevity I’ll be using <em>map</em> from here on).</p>

<p>Whenever I thought about it, it just didn’t make sense. A relational
database needs to store rows <em>in order</em>, and that’s one feature that
maps do not provide. Imagine we have a table keyed by employee id
stored in a map and we need to traverse it by id in ascending order. A
hypothetical keys() method would return us a list of ids ordered
randomly. It’s impossible to iterate over a hash map <em>in
order</em>. So how would a relational database work then?</p>

<p>It took a while for me to realize the root of my misunderstanding. I
naively was trying to picture how tables, rows and values can be
represented as key/value pairs, and that was the wrong path to take. I
was focusing on the wrong layer of abstraction. </p>

<p>As it turns out the
key [NPI] to this problem is the clever data structure commonly used
to store data in a relational DB known as
<em><a href="http://en.wikipedia.org/wiki/B-tree">B-Tree</a></em> (or a variation
thereof, <em><a href="http://en.wikipedia.org/wiki/B+tree">B+Tree</a></em>). 
Okay, B-trees are nothing new and I’m sure we’ve all heard of them. In fact B-trees were 
desgined in the 1970’s as a generalization of the
<a href="http://en.wikipedia.org/wiki/Binary_search_tree">Binary Search Tree</a> that was 
more suited for block storage. </p>

<p>But there is something about B-trees that I did not know, and which
now that I do know, seems absolutely essential as well as simply brilliant. In his 1979 paper “The
Ubiquitous B-Tree” <a href="http://www.cs.purdue.edu/people/comer">Douglas Comer</a> writes: </p>

<blockquote> The availability of demand paging hardware suggests an
interesting implementation of B-trees.  Through careful allocation,
each node of the B-tree can be mapped into one page of the virtual
address space.  Then the user treats the B-tree as if it were in
memory.  Accesses to nodes (pages) which are not in memory cause the
system to &#8220;page-in&#8221; the node from secondary storage. </blockquote>

<p>The above paragraph implies that the B-Tree and all its data can be
stored in <em>pages</em>. In fact, if you look at the file 
<a href="http://www.sqlite.org/src/artifact/eecc84f02375b2bb7a44abbcbbe3747dde73edb2">format of a SQLite 3 database</a>
(who says source code comments are bad?) you’ll see it states quite plainly  that the <em>file
is divided into pages</em>. (You will also see a fantastic description of exactly
how a B+tree works, but that’s way outside the scope of this post.)</p>

<p>The important point is that the entire file consists of pages and
nothing else. Inside those pages live the B-tree structure, as well as
the data. Each table is a B-tree and to access it we need to know the
starting page number, which in turn is stored in the sqlite_master
table whose root page is always the first page of the file. The root
page of a table is the head of the B-tree strucutre, and it may refer
to other pages, which in turn may be additional nodes of the tree or
pure data.</p>

<p>All pages are of the same size and are numbered
sequentially, thus we can easily retreive any page by its number
because its offset into the file is the page number multiplied by the
page size. (By default a SQLite3 page is 1K and will hold 4 keys,
i.e. the order of the tree is 4).</p>

<p>And bingo, there is our key/value pair: the page number is the key,
and the page itself is the value! All you need to do is stick those
pages into your favorite key/value store keyed by page number and
you’ve got a relational database atop a key/value store. It’s that
simple.</p>

<p>P.S. An astute reader may point out that there is such a thing as a
<em>sorted map</em>. But a sorted map is very different from a “pure” hash
map. The miracle of hashing is that not only does it let you find
elements in O(1) time, but more importantly that it is very suitable
for distributed processing, where the map may be spread across
multiple servers. And if you start thinking about how a <em>sorted</em> map
might be implemented in a distributed fashion, you will ultimately
loop back to B-trees, because that’s typically how it’s actually done.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/04/19/mapjoin-a-simple-way-to-speed-up-your-hive-queries/">MapJoin: A Simple Way to Speed Up Your Hive Queries</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-04-19T11:15:00-04:00" pubdate data-updated="true">Apr 19<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/04/19/mapjoin-a-simple-way-to-speed-up-your-hive-queries/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Mapjoin is a little-known feature of Hive. It allows a table to be
loaded into memory so that a (very fast) join could be performed
entirely within a mapper without having to use a Map/Reduce step. If
your queries frequently rely on small table joins (e.g. cities or
countries, etc.)  you might see a very substantial speed-up from using
mapjoins.</p>

<p>There are two ways to enable it. First is by using a hint, which looks
like <code>/*+ MAPJOIN(aliasname), MAPJOIN(anothertable) */</code>. This C-style comment
should be placed immediately following the <code>SELECT</code>. It directs Hive
to load <code>aliasname</code> (which is a table or alias of the query) into
memory.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="k">SELECT</span> <span class="cm">/*+ MAPJOIN(c) */</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">orders</span> <span class="n">o</span> <span class="k">JOIN</span> <span class="n">cities</span> <span class="k">c</span> <span class="k">ON</span> <span class="p">(</span><span class="n">o</span><span class="p">.</span><span class="n">city_id</span> <span class="o">=</span> <span class="k">c</span><span class="p">.</span><span class="n">id</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Another (better, in my opinion) way to turn on mapjoins is to let Hive
do it automatically. Simply set <code>hive.auto.convert.join</code> to true in
your config, and Hive will automatically use mapjoins for any tables
smaller than <code>hive.mapjoin.smalltable.filesize</code> (default is 25MB).</p>

<p>Mapjoins have a limitation in that the same table or alias cannot be
used to join on different columns in the same query. (This makes sense
because presumably Hive uses a HashMap keyed on the column(s) used in
the join, and such a HashMap would be of no use for a join on
different keys).</p>

<p>The workaround is very simple - do not use the same aliases in your
query.</p>

<p>I also found that when the Hive documentation states that such queries
are “<a href="https://cwiki.apache.org/Hive/languagemanual-joins.html#LanguageManualJoins-Mapjoinrestrictions">not supported</a>”
 they mean that the query will fail in unexpected
ways, sometimes with a Java traceback.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/04/02/linus-on-understanding-pointers/">Linus on Understanding Pointers</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-04-02T10:52:00-04:00" pubdate data-updated="true">Apr 2<span>nd</span>, 2013</time>
        
         | <a href="/blog/2013/04/02/linus-on-understanding-pointers/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>A while back <a href="http://en.wikipedia.org/wiki/Linus_Torvalds">Linus Torvalds</a> <a href="http://meta.slashdot.org/story/12/10/11/0030249/linus-torvalds-answers-your-questions">answered questions on Slashdot</a>.</p>

<p>One of the answers was on the subject of understanding of pointers:</p>

<blockquote>
  <p><small>At the opposite end of the spectrum, I actually wish more people
understood the really core low-level kind of coding. Not big, complex
stuff like the lockless name lookup, but simply good use of
pointers-to-pointers etc. For example, I’ve seen too many people who
delete a singly-linked list entry by keeping track of the “prev”
entry, and then to delete the entry, doing something like</small></p>
</blockquote>

<blockquote>
  <p><small>if (prev)<br />
  prev-&gt;next = entry-&gt;next;<br />
else<br />
  list_head = entry-&gt;next;<br />
</small></p>
</blockquote>

<blockquote>
  <p><small>and whenever I see code like that, I just go “This person doesn’t
understand pointers”. And it’s sadly quite common.</small></p>
</blockquote>

<blockquote>
  <p><small>People who understand pointers just use a “pointer to the entry
pointer”, and initialize that with the address of the list_head. And
then as they traverse the list, they can remove the entry without
using any conditionals, by just doing a “*pp = entry-&gt;next”</small></p>
</blockquote>

<p>There were a few comments, but none explained what he really
meant. So here it is.</p>

<p>Imagine you have a linked list defined as:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="c"><span class="line"><span class="k">typedef</span> <span class="k">struct</span> <span class="n">list_entry</span> <span class="p">{</span>
</span><span class="line">    <span class="kt">int</span> <span class="n">val</span><span class="p">;</span>
</span><span class="line">    <span class="k">struct</span> <span class="n">list_entry</span> <span class="o">*</span><span class="n">next</span><span class="p">;</span>
</span><span class="line"><span class="p">}</span> <span class="n">list_entry</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>You need to iterate over it from the begining to end and remove a
specific element whose value equals the value of <code>to_remove</code>. The more
obvious way to do this would be:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
</pre></td><td class="code"><pre><code class="c"><span class="line"><span class="n">list_entry</span> <span class="o">*</span><span class="n">entry</span> <span class="o">=</span> <span class="n">head</span><span class="p">;</span> <span class="cm">/* assuming head exists and is the first entry of the list */</span>
</span><span class="line"><span class="n">list_entry</span> <span class="o">*</span><span class="n">prev</span> <span class="o">=</span> <span class="nb">NULL</span><span class="p">;</span>
</span><span class="line">
</span><span class="line"><span class="k">while</span> <span class="p">(</span><span class="n">entry</span><span class="p">)</span> <span class="p">{</span>
</span><span class="line">    <span class="k">if</span> <span class="p">(</span><span class="n">entry</span><span class="o">-&gt;</span><span class="n">val</span> <span class="o">==</span> <span class="n">to_remove</span><span class="p">)</span>     <span class="cm">/* this is the one to remove */</span>
</span><span class="line">        <span class="k">if</span> <span class="p">(</span><span class="n">prev</span><span class="p">)</span>
</span><span class="line">           <span class="n">prev</span><span class="o">-&gt;</span><span class="n">next</span> <span class="o">=</span> <span class="n">entry</span><span class="o">-&gt;</span><span class="n">next</span><span class="p">;</span> <span class="cm">/* remove the entry */</span>
</span><span class="line">        <span class="k">else</span>
</span><span class="line">            <span class="n">head</span> <span class="o">=</span> <span class="n">entry</span><span class="o">-&gt;</span><span class="n">next</span><span class="p">;</span>      <span class="cm">/* special case - first entry */</span>
</span><span class="line">
</span><span class="line">    <span class="cm">/* move on to the next entry */</span>
</span><span class="line">    <span class="n">prev</span> <span class="o">=</span> <span class="n">entry</span><span class="p">;</span>
</span><span class="line">    <span class="n">entry</span> <span class="o">=</span> <span class="n">entry</span><span class="o">-&gt;</span><span class="n">next</span><span class="p">;</span>
</span><span class="line"><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>What we are doing above is iterating over the list until <code>entry</code> is
NULL, which means we’ve reached the end of the list (line 4). When we
come across an entry we want removed (line 5), we assign the value of
current <code>next</code> pointer to the previous one, thus eliminating the
current element (line 7).</p>

<p>There is a special case above - at the beginning of the iteration
there is no previous entry (<code>prev</code> is NULL), and so to remove the
first entry in the list you have to modify <code>head</code> itself (line 9).</p>

<p>What Linus was saying is that the above code could be simplified by
making the previous element a <em>pointer to a pointer</em> rather than just a
pointer. The code then looks like this:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="c"><span class="line"><span class="n">list_entry</span> <span class="o">**</span><span class="n">pp</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">head</span><span class="p">;</span> <span class="cm">/* pointer to a pointer */</span>
</span><span class="line"><span class="n">list_entry</span> <span class="o">*</span><span class="n">entry</span> <span class="o">=</span> <span class="n">head</span><span class="p">;</span>
</span><span class="line">
</span><span class="line"><span class="k">while</span> <span class="p">(</span><span class="n">entry</span><span class="p">)</span> <span class="p">{</span>
</span><span class="line">    <span class="k">if</span> <span class="p">(</span><span class="n">entry</span><span class="o">-&gt;</span><span class="n">val</span> <span class="o">==</span> <span class="n">to_remove</span><span class="p">)</span>
</span><span class="line">        <span class="o">*</span><span class="n">pp</span> <span class="o">=</span> <span class="n">entry</span><span class="o">-&gt;</span><span class="n">next</span><span class="p">;</span>
</span><span class="line">
</span><span class="line">    <span class="n">pp</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">entry</span><span class="o">-&gt;</span><span class="n">next</span><span class="p">;</span>
</span><span class="line">    <span class="n">entry</span> <span class="o">=</span> <span class="n">entry</span><span class="o">-&gt;</span><span class="n">next</span><span class="p">;</span>
</span><span class="line"><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The above code is very similar to the previous variant, but notice how
we no longer need to watch for the special case of the first element
of the list, since <code>pp</code> is not NULL at the beginning. Simple and
clever.</p>

<p>Also, someone in that thread commented that the reason this is better
is because <code>*pp = entry-&gt;next</code> is <em>atomic</em>.  It is most certainly NOT
atomic. The above expression contains two dereference operators (<code>*</code>
and <code>-&gt;</code>) and one assignment, and neither of those three things is
atomic. This is a common misconception, but alas pretty much <em>nothing</em>
in C should ever be assumed to be atomic (including the <code>++</code> and <code>--</code>
operators)!</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/04/01/storm-notes/">Storm Notes</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-04-01T17:05:00-04:00" pubdate data-updated="true">Apr 1<span>st</span>, 2013</time>
        
         | <a href="/blog/2013/04/01/storm-notes/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Some random thoughts on having tinkered with
<a href="http://storm-project.net/">Storm</a> over the past few weeks.</p>

<p>It took me some time to understand what Storm is, and I am still not
clear I have found a perfect use for it. (This is not
a criticism of Storm, the point is that the concepts it introduces are
new, somewhat diffuclt and will need some time so sync in). The best way to get the basic
understanding of Storm concepts is to watch Nathan Marz’s <a href="https://www.youtube.com/watch?v=bdps8tE0gYo">excellent presentation</a>. </p>

<p>In simple terms, Storm is a tool that lets you run code in parallel
across a cluster of servers. It differs from Map/Reduce in that the
actual algorithm is entirely up to you, and in essence all that Storm
provides is the framework that supervises all the moving pieces of your
application (known as a <em>topology</em>) and provides a uniform way of
creating, testing locally, sumbitting to a cluster, logging,
monitoring, as well as primitives for sending data between components
such as grouping data by using hashing, etc.</p>

<p>Storm is mainly meant for stream processing. A stream could be
anything, some of the most obvious examples may be your web logs,
tables containing user actions such as clicks, transactions,
purchases, trades, etc. If the data is coming in at a rate where it’s
challenging to process it on one server, Storm provides a way to scale
it across a cluster of servers and can handle ridiculous amounts of
incoming data. The result is a real-time view of summary data that is
always up to date.</p>

<p>Storm is written in Java and Clojure, which makes the JVM the common
denominator, so any JVM language should work as “native”. Storm also provides a
primitive for using pipes to a process which means that you can write
a component in anything - from a Bash script to C, all it needs to do
is read stdin and write stdout.</p>

<p>For those who would prefer to try it out using a higher-level
language, there is an excellent project called
<a href="https://github.com/colinsurprenant/redstorm">Redstorm</a> which lets you
write your topology in JRuby. While a Redstorm topology may not be as
fast as something written in pure Java, the reduced development
time is well worth any trade offs, and you always have the option of
perfecting it later by porting your code to something JVM-native when
your understanding of how it ought to work is solidified in your mind.</p>

<p>If you’re going to go the Redstorm route, a couple of gotchas that I
came across were:</p>

<ul>
  <li>
    <p>Storm 0.8.2 and JRuby 1.7.2 disagree on the version of Yaml parsing
jar (snakeyaml). Don’t know what the solution is if you absolutely must parse
Yaml other than downgrading to JRuby 1.6.8, otherwise you can just
use something other than Yaml: JSON or just plain eval().</p>
  </li>
  <li>
    <p>If you’re going to use ActiveRecord (which does work fine), watch
out for how to properly use it in a multi-threaded environment. You
might need to wrap some code in synchronize (see <a href="https://github.com/jruby/jruby/wiki/Concurrency-in-jruby">Concurrency in JRuby</a>.
You will also need make sure your ActiveRecord connections are not
shared by concurrent threads by using
<a href="http://api.rubyonrails.org/classes/ActiveRecord/ConnectionAdapters/ConnectionPool.html#method-i-with_connection">connection_pool.with_connection</a></p>
  </li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/03/27/on-prioritization/">On Prioritization - Important vs Urgent</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-03-27T10:13:00-04:00" pubdate data-updated="true">Mar 27<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/03/27/on-prioritization/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Every item on a TODO list can be classified as <em>urgent</em>, <em>important</em>
or <em>neither</em>. We should act on important items first, urgent second and
ignore the rest.</p>

<p>Sometimes an item lands on our TODO list described as extremely urgent
without any explanation of importance. In this case the important item
(and thus to be done <em>first</em>) becomes <em>determining the importance of the
extremely urgent item in question</em>, even if it means delaying it.</p>

<p>The reason I so strongly believe that understanding the importance of
every thing we do is essential is quite simple: understanding
the importance implies understanding of the ultimate objective. And
inversely, not understanding the importance implies not understanding
the objective.</p>

<p>And if after some discussion and thinking one still cannot assess the
importance of a task, and nobody can explain it, then it
is simply not important, however urgent it may seem.</p>

<p>There are exceptions, however. Sometimes importance can be difficult
to verbalize. We should always be attuned to that. In my personal
experience reiterated urgency in response to “why it is important” is
a bad sign, whereas an emotional reaction of the “you just don’t get
it, how can I explain this to you?” is a very good sign.</p>

<p>And sometimes, when you trust that the person requesting something of
you truly believes it is both important and urgent but is unable to
verbalize the importance sufficiently well, you may have to take their
word for it and just do it, without fully understanding the
importance.</p>

<p>It is also important to remember to always take the time to explain
importance of things we request of others. We naturally enjoy working
on important things and resent “urgent” and unimportant tasks.</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/5/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/3/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    

<section>
<script type="text/javascript"><!--
google_ad_client = "pub-9718360309690383";
google_ad_width = 200;
google_ad_height = 200;
google_ad_format = "200x200_as";
google_ad_type = "image";
//-->
</script>
<div style="text-align: center;">
  <div style="text-align: left; width: 200px; display: block; margin-left: auto; margin-right: auto;">
    <script type="text/javascript"
            src="https://pagead2.googlesyndication.com/pagead/show_ads.js">
    </script>
  </div>
</div>
</section>

<section>
  <h1>About Me</h1>

  <p>
  <div style="width: 50%; margin: 0 auto;">
  <a href="https://twitter.com/humblehack" class="twitter-follow-button"
    data-show-count="">Follow @humblehack</a>
  </div>
  </p>

  <p>I am currently a (Data) Hacker at <a href="http://voxmedia.com">Vox Media</a>.</p>
  <p>Grisha is a common Russian short name for Gregory. It is pronounced more like Greesha.</p>
  <p>Years ago I wrote <a href="http://modpython.org">mod_python</a>, which became a hugely succesful OSS Project and is still in use by millions of sites.</p>
  <p>I am a former VP and member emeritus of the <a href="http://apache.org">Apache Software Foundation</a>.</p>
  <p>I started programming professionally back when I was a teenager.
  I&#8217;ve spent most of my early career working at large ISP&#8217;s solving industrial-scale hosting challenges. Since around 2009 I&#8217;ve become more intersted in and now work exclusively on data infrastuctre, both big and small, but mostly big.</p>
  <p>I was born and grew up in Moscow, Russia, though I&#8217;ve lived in the Washington, DC (USA) area for more than half of my life now. Our kids were born and go to school here, it&#8217;s gradually become home for us.</p>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2017/01/21/storing-time-seris-in-postgresql-optimize-for-write/">Storing Time Seris in PostgreSQL - Optimize for Write</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/12/28/simple-tgres-part-ii-a-high-rate-counter/">Simple Tgres Part II - A High Rate Counter</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/12/23/time-series-what-is-it/">Why is there no Formal Definition of Time Series?</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/12/21/simple-time-series-app-with-tgres/">Simple Time Series App with Tgres</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/12/16/storing-time-series-in-postgresql-part-ii/">Storing Time Series in PostgreSQL (Continued)</a>
      </li>
    
  </ul>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  <img src="https://www.ispol.com/grisha_org.gif" height="1" width="1">
  Copyright &copy; 2017 - Gregory Trubetskoy -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'grisha';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'https://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'https://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
