<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Grisha Trubetskoy]]></title>
  <link href="http://grisha.org/atom.xml" rel="self"/>
  <link href="http://grisha.org/"/>
  <updated>2017-04-09T19:40:45-04:00</updated>
  <id>http://grisha.org/</id>
  <author>
    <name><![CDATA[Gregory Trubetskoy]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Tgres 0.10.0b - Time Series with Go and PostgreSQL]]></title>
    <link href="http://grisha.org/blog/2017/03/22/tgres-0-dot-10-dot-0b-time-series-with-go-and-postgresql/"/>
    <updated>2017-03-22T13:52:00-04:00</updated>
    <id>http://grisha.org/blog/2017/03/22/tgres-0-dot-10-dot-0b-time-series-with-go-and-postgresql</id>
    <content type="html"><![CDATA[<p>After nearly two years of hacking, I am tagging this version of
<a href="https://github.com/tgres/tgres">Tgres</a>
as beta. It is functional and stable enough for people to try out and
not feel like they are wasting their time. There is still a lot that
could and should be improved, but at this point the most
important thing is to get more people to check it out.</p>

<h3 id="what-is-tgres">What is Tgres?</h3>

<p>Tgres is a <a href="https://golang.org">Go</a> program which can receive time
series data via <a href="https://graphiteapp.org/">Graphite</a>, <a href="https://github.com/etsy/statsd/wiki">Statsd</a>
protocols or an http <a href="https://godoc.org/github.com/tgres/tgres/http#PixelHandler">pixel</a>, store it
in <a href="https://www.postgresql.org/">PostgreSQL</a>, and provide Graphite-like access to the data
in a way that is compatible with tools such as <a href="https://grafana.com/">Grafana</a>. You could think of it as a
drop-in Graphite/Statsd replacement, though I’d rather avoid direct
comparison, because the key feature of Tgres is that data is stored in
PostgreSQL.</p>

<p><a href="http://grisha.org/blog/2017/02/28/tgres-load-testing-follow-up/"><img src="http://grisha.org/images/tgres_load_head_01.png" /></a></p>

<h3 id="why-postgresql">Why PostgreSQL?</h3>

<p>The “grand vision” for Tgres begins with the database. Relational
databases have the most man-decades of any storage type invested into
them, and PostgreSQL is probably the most advanced implementation
presently in existence.</p>

<p>If you search for “relational databases and time series” (or
some variation thereupon), you will come across the whole gamut of
opinions (if not convictions) varying so widely it is but
discouraging. This is because time series storage, while simple at
first glance, is actually fraught with subtleties and ambiguities that
can drive even the most patient of us up the wall.</p>

<h3 id="avoid-solving-the-storage-problem">Avoid Solving the Storage Problem.</h3>

<p>Someone once said that “anything is possible when you don’t know what
you’re talking about”, and nowhere is it more evident than in data
storage. File systems and relational databases trace their origin back
to the late 1960s and over half a century later I doubt that
any field experts would say “the storage problem is solved”. And so it seems
almost foolish to suppose that by throwing together a key-value store and a
concensus algorithm or some such it is possible to come up with
something <em>better</em>? Instead of re-inventing storage, why not focus on
how to structure the data in a way that is compatible with a
storage implementation that we know works and scales reliably?</p>

<p>As part of the Tgres project, I thought it’d be interesting to get to
the bottom of this. If not bottom, then at least deeper than most
people dare to dive. I am not a mathematician or a statistician, nor
am I a data scientist, whatever that means, but I think I understand
enough about the various subjects involved, including programming,
that I can come up with something more than just another off-the-cuff
opinion.</p>

<p>And so now I think I can conclude definitively that time
series data can be stored in a relational database very efficently, PostgreSQL in
particular for its support for
<a href="https://www.postgresql.org/docs/current/static/arrays.html">arrays</a>.
The general approach I described in a series of blogs starting with
<a href="http://grisha.org/blog/2015/09/23/storing-time-series-in-postgresql-efficiently/">this one</a>,
Tgres uses the technique described in the
<a href="http://grisha.org/blog/2017/01/21/storing-time-seris-in-postgresql-optimize-for-write/">last one</a>.
In my <a href="http://grisha.org/blog/2017/02/28/tgres-load-testing-follow-up/">performance tests</a>
the Tgres/Postgres combination was so efficient it was possibly
outperforming its time-series <a href="http://obfuscurity.com/2016/09/Benchmarking-Graphite-master-on-AWS">siblings</a>.</p>

<p>The good news is that as a user you don’t need to think about the
complexities of the data layout, Tgres takes care of it. Still I very
much wish people would take more time to think about how to organize
data in a tried and true solution like PostgreSQL before jumping ship
into the murky waters of the “noSQL” ocean, lured by alternative
storage sirens, big on promise but shy on delivery, only to drown
where no one could come to the rescue.</p>

<h3 id="how-else-is-tgres-different">How else is Tgres different?</h3>

<p>Tgres is a single program, a single binary which does everything
(one of my favorite things about Go). It supports all of Graphite
and Statsd protocols without having to run separate
processes, there are no dependencies of any kind other than a PostgreSQL
database. No need for Python, Node or a JVM, just the binary, the
<a href="https://github.com/tgres/tgres/blob/v0.10.0b/etc/tgres.conf.sample">config file</a>
and access to a database.</p>

<p>And since the data is stored in Postgres, virtually all of the
features of Postgres are available: from being able to query
the data using real SQL with all the latest features, to replication,
security, performance, back-ups and whatever else Postgres
offers.</p>

<p>Another benefit of data being in a database is that it can be
accessible to any application frameworks in Python, Ruby or whatever
other language as just another database table. For example in Rails it
might be as trivial as <code>class Tv &lt; ActiveRecord::Base; end</code> et voilà,
you have the data points as a model.</p>

<p>It should also be mentioned that Tgres requires no PostgreSQL
extensions. This is because optimizing by implementing a custom
extension which circumvents the PostgreSQL natural way of handling
data means we are solving the storage problem again. PostgreSQL
storage is not broken to begin with, no customization is necessary to
handle time series.</p>

<p>In addition to being a standalone program, Tgres packages aim to be useful on their own
as part of any other Go program. For example it is very easy to equip a Go application with Graphite
capabilities by providing it access to a database and using the
provided http
<a href="https://godoc.org/github.com/tgres/tgres/http#GraphiteRenderHandler">handler</a>. This
also means that you can use a separate Tgres instance dedicated to querying data
(perhaps from a downstream Potgres slave).</p>

<h3 id="some-internals-overview">Some Internals Overview</h3>

<p>Internally, Tgres series identification is tag-based. The series are
identified by a <a href="https://www.postgresql.org/docs/current/static/datatype-json.html">JSONB</a>
field which is a set of key/value pairs indexed using a
<a href="https://www.postgresql.org/docs/current/static/gin-intro.html">GIN index</a>.
In Go, the JSONB field becomes a
<a href="https://godoc.org/github.com/tgres/tgres/serde#Ident">serde.Ident</a>.
Since the “outside” interface Tgres is presently mimicking is Graphite,
which uses dot-separated series identifiers, all idents are made of just one tag
“name”, but this will change as we expand the DSL.</p>

<p>Tgres stores data in evenly-spaced series. The conversion from the
data as it comes in to its evenly-spaced form happens on-the-fly,
using a <a href="http://grisha.org/blog/2016/08/04/data-points/">weighted mean</a> method, and
the resulting stored rate is actually correct. This is similar to how
<a href="http://oss.oetiker.ch/rrdtool/">RRDTool</a> does it, but different from
many other tools which simply discard all points except for last in the same
series slot as I explained in <a href="http://grisha.org/blog/2015/05/04/recording-time-series/">this post</a>.</p>

<p>Tgres maintains a (configurable) number of Round-Robin Archives (RRAs)
of varying length and resolution for each series, this is an approach
similar to RRDTool and Graphite Whisper as well. The conversion to
evenly-spaced series happens in the
<a href="https://godoc.org/github.com/tgres/tgres/rrd">rrd</a> package.</p>

<p>Tgres does not store the original (unevenly spaced) data points. The
rationale behind this is that for analytical value you always
inevitably have to convert an uneven series to a regular one. The
problem of storing the original data points is not a time-seires
problem, the main challenge there is the ability to keep up with a
massive influx of data, and this is what Hadoop, Cassandra, S3,
BigQuery, etc are excellent at.</p>

<p>While Tgres code implements most of the <a href="http://graphite.readthedocs.io/en/latest/functions.html">Graphite functions</a>,
complete compatibility with the Graphite DSL is not a goal, and some
functions will probably left uniplemented. In my opinion the Graphite
DSL has a number of shortcomings by design. For example, the series names are not
strings but are syntactically identifiers, i.e. there is no
difference between <code>scale(foo.bar, 10)</code> and <code>scale("foo.bar", 10)</code>,
which is problematic in more than one way. The dot-names are
ingrained into the DSL, and lots of functions take arguments denoting
position within the dot-names, but they seem unnecessary. For
example there is <code>averageSeriesWithWildcards</code> and
<code>sumSeriesWithWildcards</code>, while it would be cleaner to have some kind
of a <code>wildcard()</code> function which can be passed into <code>average()</code> or
<code>sum()</code>. Another example is that Graphite does not support chaining (but Tgres already
does), e.g. <code>scale(average("foo.*"), 10)</code> might be better as
<code>average("foo.*").scale(10)</code>. There are many more similar small
grievances I have with the DSL, and in the end I think that the DSL ought to be
revamped to be more like a real language (or perhaps just be a
language, e.g. Go itself), exactly how hasn’t been crystalized just
yet.</p>

<p>Tgres also aims to be a useful time-series processing Golang package
(or a set of packages). This means that in Go the code also needs to
be clean and readable, and that there ought to be a conceptual
correspondence between the DSL and how one might to something at the
lower level in Go. Again, the vision here is still blurry, and more
thinking is required.</p>

<p>For Statsd functionality, the network protocol is supported by the
<a href="https://godoc.org/github.com/tgres/tgres/statsd">tgres/statsd</a>
package while the aggregation is done by the
<a href="https://godoc.org/github.com/tgres/tgres/aggregator">tgres/aggregator</a>. In
addition, there is also support for “paced metrics” which let you
aggregate data <em>before</em> it is passed on to the Tgres receiver and
becomes a data point, which is useful in situations where you have
some kind of an iteration that would otherwise generate millions of
measurements per second.</p>

<p>The finest resolution for Tgres is a millisecond. Nanoseconds seems
too small to be practical, though it shouldn’t be too hard to change
it, as internally Tgres uses native Go types for time and duration -
the milliseconds are the integers in the database.</p>

<p>When the Data points are received via the network, the job of parsing the
network stuff is done by the code in the <a href="https://godoc.org/github.com/tgres/tgres/daemon">tgres/daemon</a>
package with some help from <a href="https://godoc.org/github.com/tgres/tgres/http">tgres/http</a>
and <a href="https://godoc.org/github.com/tgres/tgres/statsd">tgres/statsd</a>, as well as
potentially others (e.g. Python pickle decoding).</p>

<p>Once received and correctly parsed, they are passed on to the
<a href="https://godoc.org/github.com/tgres/tgres/receiver">tgres/receiver</a>. The
receiver’s job is to check whether this series ident is known to us
by checking the cache or that it needs to be loaded from the
database or created. Once the appropriate series is found, the
receiver updates the in-memory cache of the
<a href="https://godoc.org/github.com/tgres/tgres/rrd#RoundRobinArchive">RRAs</a>
for the series (which causes the data points to be evenly spaced) as well as
periodically flushes data points to the data base. The
receiver also controls the <a href="https://godoc.org/github.com/tgres/tgres/aggregator">aggregator</a>
of statsd metrics.</p>

<p>The database interface code is in the <a href="https://godoc.org/github.com/tgres/tgres/serde">tgres/serde</a>
package which supports PostgreSQL or an in-memory database (useful
in situations where persistence is not required or during testing).</p>

<p>When Tgres is queried for data, it loads it from the database
into a variety of implementations of the Series interface in the
<a href="https://godoc.org/github.com/tgres/tgres/series">tgres/series</a> package
as controlled by the <a href="https://godoc.org/github.com/tgres/tgres/dsl">tgres/dsl</a>
responsible for figuring out what is asked of it in the query.</p>

<p>In addition to all of the above, Tgres supports clustering, though this is
highly experimental at this point. The idea
is that a cluster of Tgres instances (all backed by the same database,
at least for now) would split the series amongst themselves and
forward data points to the node which is responsible for a particular
series. The nodes are placed behind a load-balancer of some kind, and
with this set up nodes can go in and out of the cluster without any
overall downtime for maximum availability. The clustering logic lives in
<a href="https://godoc.org/github.com/tgres/tgres/cluster">tgres/cluster</a>.</p>

<p>This is an overly simplistic overview which hopefully conveys that
there are a lot of pieces to Tgres.</p>

<h2 id="future">Future</h2>

<p>In addition to a new/better DSL, there are lots of interesting ideas,
and if you have any please chime in on Github.</p>

<p>One thing that is missing in the telemetry world is encryption,
authentication and access control so that tools like Tgres could be
used to store health data securely.</p>

<p>A useful feature might be interoperability with big data tools to
store the original data points and perhaps provide means for pulling
them out of BigQuery or whatever and replay them into series - this
way we could change the resolution to anything at will.</p>

<p>Or little details like a series alias - so that a series could be
renamed. The way this would work is you rename a series while keeping
its old ident as an alias, then take your time to make sure all the
agents send data under the new name, at which point the alias can go
away.</p>

<p>Lots can also be done on the scalability front with improved
clustering, sharding, etc.</p>

<h2 id="we-could-use-your-help">We Could Use Your Help</h2>

<p>Last but not least, this is an Open Source project. It works best when
people who share the vision also contribute to the project, and this
is where you come in. If you’re interested in learning more about time
series and databases, please check it out and feel free to contribute
in any way you can!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tgres Load Testing Follow Up]]></title>
    <link href="http://grisha.org/blog/2017/02/28/tgres-load-testing-follow-up/"/>
    <updated>2017-02-28T21:40:00-05:00</updated>
    <id>http://grisha.org/blog/2017/02/28/tgres-load-testing-follow-up</id>
    <content type="html"><![CDATA[<p>To follow up on the <a href="http://grisha.org/blog/2017/02/23/can-tgres-outperform-graphite/">previous post</a>,
after a bunch
of tweaking, here is Tgres (<a href="https://github.com/tgres/tgres/commit/90924e4afa4ac8bef61caf46c3439794983660ec">commit</a>) receiving over 150,000 data points per
second across 500,000 time series without any signs of the queue size
or any other resource blowing up.</p>

<p>This is both Tgres and Postgres running on the same i2.2xlarge EC2 instance (8 cores, 64GB, SSD).</p>

<p><img src="http://grisha.org/images/tgres_aws1_150k.png" /></p>

<p>At this point I think there’s been enough load testing and optimization, and I am
going to get back to crossing the t’s and dotting the i’s so that we can release
the first version of Tgres.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PostgreSQL vs Whisper, which is Faster?]]></title>
    <link href="http://grisha.org/blog/2017/02/23/can-tgres-outperform-graphite/"/>
    <updated>2017-02-23T09:49:00-05:00</updated>
    <id>http://grisha.org/blog/2017/02/23/can-tgres-outperform-graphite</id>
    <content type="html"><![CDATA[<p>Note: there is an <a href="http://grisha.org/blog/2017/02/28/tgres-load-testing-follow-up/">update</a> to this post.</p>

<h2 id="tldr">TL;DR</h2>

<p>On a 8 CPU / 16 GB EC2 instance,
<a href="https://github.com/tgres/tgres">Tgres</a> can process 150,000 data
points per second across 300,000 series (Postgres running on the same
machine). With some tweaks we were able to get the number of series to
half a million, flushing ~60K data points per second.</p>

<h2 id="now-the-long-version">Now the long version…</h2>

<p>If you were to ask me whether Tgres could outperform Graphite, just a
couple of months ago my answer would have been “No”. Tgres uses
Postgres to store time series data, while Graphite stores data by
writing to files directly, the overhead of the relational database
just seemed too great.</p>

<p>Well, I think I’ve managed to prove myself wrong. After re-working
Tgres to use the
<a href="http://grisha.org/blog/2017/01/21/storing-time-seris-in-postgresql-optimize-for-write/">write-optimized layout</a>,
I’ve run some tests on AWS yielding unexpectedly promising results.</p>

<p>As a benchmark I targeted the excellent <a href="http://obfuscurity.com/2016/08/Benchmarking-Carbon-and-Whisper-on-AWS">blog post</a>
by Jason Dixon describing his AWS Graphite test. My goal was to get to at least half the
level of performance described therein. But it appears the combination of Go, Postgres and some
clever data structuring has been able to beat it, not without breaking
a little sweat, but it has.</p>

<p>My test was conducted on a
<a href="https://aws.amazon.com/ec2/instance-types/">c4.2xlarge</a> instance,
which has 8 cores and 16 GB, using 100GB EBS (which, if I understood it
correctly, comes with 300 IOPS, please comment if I’m wrong). The “c4”
instances are supposed to be some of the highest speed CPU AWS has to
offer, but compare this with the instance used in the Graphite test,
an i2.4xlarge (16 CPU/ 122GB), it had half the CPU cores and nearly
one tenth of the RAM.</p>

<p>Before I go any further, here is the obligatory screenshot, then my
observations and lessons learned in the process, as well as a
screenshot depicting even better performance.</p>

<p><img src="http://grisha.org/images/tgres_aws1.png" /></p>

<p>The Tgres version running was <a href="https://github.com/tgres/tgres/tree/1c57cba3fe4cdb0b96bf5054cfd01cb2a41e2bba">this one</a>,
with the config detailed at the bottom of the post.</p>

<p>Postgres was whatever <code>yum install postgresql95-server</code> brings your
way, with the <code>data</code> directory moved to the EBS volume formatted using
ext4 (not that I think it matters). The Postgres config was modified to
allow a 100ms commit delay and to make autovacuum extra aggressive. I
did not increase any memory buffers and left everything else as
is. Specifically, these were the changes:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class=""><span class="line">autovacuum_work_mem = -1
</span><span class="line">synchronous_commit = off
</span><span class="line">commit_delay = 100000
</span><span class="line">autovacuum_max_workers = 10
</span><span class="line">autovacuum_naptime = 1s
</span><span class="line">autovacuum_vacuum_threshold = 2000
</span><span class="line">autovacuum_vacuum_scale_factor = 0.0
</span><span class="line">autovacuum_vacuum_cost_delay = 0</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The data points for the test were generated by a [goroutine](https://github.com/tgres/tgres/blob/06a9f5805a934c304b11f44a32792414ceafe6f0/blaster/blaster.go#L55
in the Tgres process itself. In the past I’ve found that blasting a server
with this many UDP packets can be tricky and hardware/network
intensive. It’s also hard to tell when/if they get dropped and why,
etc. Since Go is not known for having problems in its network stack, I
was not too worried about it, I just wanted a reliable and
configurable source of incoming packets, and in Go world writing a
simple goroutine seemed like the right answer.</p>

<h2 id="somewhat-random-notes-and-making-tgres-even-faster">Somewhat Random Notes and Making Tgres Even Faster</h2>

<h3 id="determining-failure">Determining failure</h3>

<p>Determining when we are “at capacity” is tricky. I’ve mostly looked at
two factors (aside from the obvious - running out of memory/disk,
becoming unresponsive, etc): receiver queue size
and Postgres <a href="https://www.keithf4.com/checking-for-postgresql-bloat/">table bloat</a>.</p>

<h4 id="queue-size">Queue size</h4>

<p>Tgres uses “elastic channels” (so eloquently
<a href="https://github.com/npat-efault/musings/wiki/Elastic-channels">described here</a> by Nick Patavalis)
for incoming data points and to load series from Postgres.  These are
channel-like structures that can grow to arbitrary length only limited
by the memory available. This is done so as to be able to take maximum
advantage of the hardware at hand. If any of those queues starts
growing out of control, we are failing. You can see in the picture
that at about 140K data points per second the receiver queue started
growing, though it did stay steady at this size and never spun out of
control (the actual test was left overnight at this rate just to make
sure).</p>

<h4 id="pg-table-bloat">PG Table Bloat</h4>

<p>Table bloat is a phenomenon affecting Postgres in write-intensive
situations because of its adherence to the <a href="https://en.wikipedia.org/wiki/Multiversion_concurrency_control">MVCC</a>.
It basically means that pages on disk are being updated faster than the autovacuum
process can keep up with them and the table starts growing out of
control.</p>

<p>To monitor for table bloat, I used a simple formula which determined
the approximate size of the table based on the row count (our data is
all floats, which makes it very predictable) and compared it with the
actual size. If the actual size exceeded the estimated size, that’s
considered bloat. Bloat is reported in the “TS Table Size” chart. A
little bloat is fine, and you can see that it stayed in fairly low
percent throughout the test.</p>

<p>In the end, though more research is warranted, it may just turn out
that contrary to every expectation PostgreSQL was <em>not</em> the limiting
factor here. The <code>postmaster</code> processes stayed below 170MB RSS, which
is absolutely remarkable, and Grafana refreshes were very quick even
at peak loads.</p>

<h4 id="memory-consumption">Memory consumption</h4>

<p>Tgres has a slight limitation in that creating a series is
expensive. It needs to check with Postgres and for reasons I don’t
want to bore you with it’s always a SELECT, optionally followed by an
“UPSERT”. This takes time, and during the ramp-up period when the
number of series is growing fast and lots of them need to be created,
the Go runtime ends up consuming a lot of memory. You can see that
screenshot image reports 4.69GB. If I were to restart Tgres (which
would cause all existing DS names to be pre-cached) its memory
footprint stayed at about 1.7GB. More work needs to be done to figure
out what accounts for the difference.</p>

<h4 id="data-point-rate-and-number-of-series">Data Point Rate and Number of Series</h4>

<p>The rate of data points that need to be saved to disk is a function of
the number of series and the resolution of the RRAs. To illustrate, if
I have one series at 1 point per second, even if I blast a million
data points per second, still only 1 data point per second needs to be
saved.</p>

<p>There is an important difference between Graphite and Tgres in that
Tgres actually adjusts the final value considering the every data
point value using weighted mean, while Graphite just ignores all
points but the last. So Tgres does a bit more work, which adds up
quickly at 6-figure rates per second.</p>

<p>The Graphite test if I read the chart correctly was able to process
~70K data points per second across 300K series. My test had 300K
series and data points were coming in at over 150K/s. But just out of
curiosity, I tried to push it to its limit.</p>

<p>At 400 series, you can see clear signs of deterioration. You can see
how vcache isn’t flushed fast enough leaving gaps at the end of
series. If we stop the data blast, it does eventually catch up,
so long as there is memory for the cache.</p>

<p><img src="http://grisha.org/images/tgres_aws1_det.png" /></p>

<p>If you don’t catch this condition in time, Tgres will die with:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">fatal error: runtime: out of memory
</span><span class="line">
</span><span class="line">runtime stack:
</span><span class="line">runtime.throw<span class="o">(</span>0xa33e5a, 0x16<span class="o">)</span>
</span><span class="line">        /home/grisha/.gvm/gos/go1.8/src/runtime/panic.go:596 +0x95
</span><span class="line">...
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="segment-width">Segment Width</h3>

<p>There is still one easy performance card we can play here. Segment
width is how many data points are stored in one row, it is also the
limit on how many points we can transfer in a single SQL operation.
Segment width by default is 200, because a width higher than that
causes rows to exceed a page and trigger
<a href="https://www.postgresql.org/docs/current/static/storage-toast.html">TOAST</a>.
TOAST can be good or bad because it means data is stored in a separate table
(not so good), but it also means it’s compressed, which may be an I/O
win.</p>

<h4 id="so-what-would-happen-if-we-set-the-segment-width-to-1000">So what would happen if we set the segment width to 1000?</h4>

<p>The picture changes significantly (see below). I was able to get the
number of series to 500K, note the whopping 52,602 data points being
written to the database per second! You can see we’re pushing it to
the limit because the receiver queue is beginning to grow. I <em>really</em>
wanted to get the rate up to 150K/sec, but it just didn’t want to go
there.</p>

<p><img src="http://grisha.org/images/tgres_aws1_1k.png" /></p>

<h4 id="and-what-would-happen-if-we-set-the-segment-width-to-4096">And what would happen if we set the segment width to 4096?</h4>

<p>Interestingly, the memory footprint is a tad larger while the vcache
is leaner, the number of data points flushed per second is about same,
though in fewer SQL statements, and the overall picture is about the
same and the incoming queue still skyrockets at just about 100K/sec
over 500K series.</p>

<p><img src="http://grisha.org/images/tgres_aws1_4k.png" /></p>

<h2 id="conclusion">Conclusion</h2>

<p>There is plenty of places in Tgres code that could still be
optimized.</p>

<p>One issue that would be worth looking into is exposing Tgres to the
firehose on an empty database. The current code runs out of memory in
under a minute when suddenly exposed to 300K new series at
150K/s. Probably the simplest solution to this would be to somehow
detect that we’ve unable to keep up and start dropping data
points. Eventually, when all the series are created and cached,
performance should even out after the initial spike and all should be
well.</p>

<p>In any event, it’s nice to be able to do something like this and know
that it is performant as well:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="n">tgres</span><span class="o">=&gt;</span> <span class="k">select</span> <span class="n">t</span><span class="p">,</span> <span class="n">r</span> <span class="k">from</span> <span class="n">ds</span>
</span><span class="line"> <span class="k">join</span> <span class="n">tv</span>  <span class="k">on</span> <span class="n">tv</span><span class="p">.</span><span class="n">ds_id</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="n">id</span>
</span><span class="line"><span class="k">where</span> <span class="n">ident</span> <span class="o">@&gt;</span> <span class="s1">&#39;{&quot;name&quot;:&quot;tgres.0_0_0_0.runtime.load.five&quot;}&#39;</span>
</span><span class="line">  <span class="k">and</span> <span class="n">tv</span><span class="p">.</span><span class="n">step_ms</span> <span class="o">=</span> <span class="mi">10000</span>
</span><span class="line"><span class="k">order</span> <span class="k">by</span> <span class="n">t</span> <span class="k">desc</span>
</span><span class="line"><span class="k">limit</span> <span class="mi">5</span><span class="p">;</span>
</span><span class="line">           <span class="n">t</span>            <span class="o">|</span>       <span class="n">r</span>
</span><span class="line"><span class="c1">------------------------+----------------</span>
</span><span class="line"> <span class="mi">2017</span><span class="o">-</span><span class="mi">02</span><span class="o">-</span><span class="mi">23</span> <span class="mi">22</span><span class="p">:</span><span class="mi">31</span><span class="p">:</span><span class="mi">50</span><span class="o">+</span><span class="mi">00</span> <span class="o">|</span> <span class="mi">1</span><span class="p">.</span><span class="mi">256833462648</span>
</span><span class="line"> <span class="mi">2017</span><span class="o">-</span><span class="mi">02</span><span class="o">-</span><span class="mi">23</span> <span class="mi">22</span><span class="p">:</span><span class="mi">26</span><span class="p">:</span><span class="mi">30</span><span class="o">+</span><span class="mi">00</span> <span class="o">|</span> <span class="mi">1</span><span class="p">.</span><span class="mi">305209492142</span>
</span><span class="line"> <span class="mi">2017</span><span class="o">-</span><span class="mi">02</span><span class="o">-</span><span class="mi">23</span> <span class="mi">22</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mi">10</span><span class="o">+</span><span class="mi">00</span> <span class="o">|</span> <span class="mi">1</span><span class="p">.</span><span class="mi">554056287975</span>
</span><span class="line"> <span class="mi">2017</span><span class="o">-</span><span class="mi">02</span><span class="o">-</span><span class="mi">23</span> <span class="mi">22</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mi">00</span><span class="o">+</span><span class="mi">00</span> <span class="o">|</span> <span class="mi">1</span><span class="p">.</span><span class="mi">453365774931</span>
</span><span class="line"> <span class="mi">2017</span><span class="o">-</span><span class="mi">02</span><span class="o">-</span><span class="mi">23</span> <span class="mi">22</span><span class="p">:</span><span class="mi">23</span><span class="p">:</span><span class="mi">50</span><span class="o">+</span><span class="mi">00</span> <span class="o">|</span> <span class="mi">1</span><span class="p">.</span><span class="mi">380504724386</span>
</span><span class="line"><span class="p">(</span><span class="mi">5</span> <span class="k">rows</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="reference">Reference</h2>

<p>For completness sake, the instance was created using Terraform config
approximately like this:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
</pre></td><td class="code"><pre><code class="go"><span class="line"><span class="nx">variable</span> <span class="s">&quot;aws_region&quot;</span> <span class="p">{</span> <span class="k">default</span> <span class="p">=</span> <span class="s">&quot;us-east-1&quot;</span> <span class="p">}</span>
</span><span class="line"><span class="nx">variable</span> <span class="s">&quot;aws_zone&quot;</span> <span class="p">{</span> <span class="k">default</span> <span class="p">=</span> <span class="s">&quot;us-east-1a&quot;</span> <span class="p">}</span>
</span><span class="line"><span class="nx">variable</span> <span class="s">&quot;key_name&quot;</span> <span class="p">{</span> <span class="k">default</span> <span class="p">=</span> <span class="s">&quot;REDACTED&quot;</span>
</span><span class="line">
</span><span class="line"><span class="nx">provider</span> <span class="s">&quot;aws&quot;</span> <span class="p">{</span>
</span><span class="line">  <span class="nx">region</span> <span class="p">=</span> <span class="s">&quot;${var.aws_region}&quot;</span>
</span><span class="line"><span class="p">}</span>
</span><span class="line">
</span><span class="line"><span class="nx">resource</span> <span class="s">&quot;aws_ebs_volume&quot;</span> <span class="s">&quot;ebs_volume&quot;</span> <span class="p">{</span>
</span><span class="line">  <span class="nx">availability_zone</span> <span class="p">=</span> <span class="s">&quot;${var.aws_zone}&quot;</span>
</span><span class="line">  <span class="nx">size</span> <span class="p">=</span> <span class="mi">100</span>
</span><span class="line"><span class="p">}</span>
</span><span class="line">
</span><span class="line"><span class="nx">resource</span> <span class="s">&quot;aws_volume_attachment&quot;</span> <span class="s">&quot;ebs_att&quot;</span> <span class="p">{</span>
</span><span class="line">  <span class="nx">device_name</span> <span class="p">=</span> <span class="s">&quot;/dev/sdh&quot;</span>
</span><span class="line">  <span class="nx">volume_id</span> <span class="p">=</span> <span class="s">&quot;${aws_ebs_volume.ebs_volume.id}&quot;</span>
</span><span class="line">  <span class="nx">instance_id</span> <span class="p">=</span> <span class="s">&quot;${aws_instance.tgres-test-tmp.id}&quot;</span>
</span><span class="line"><span class="p">}</span>
</span><span class="line">
</span><span class="line"><span class="nx">resource</span> <span class="s">&quot;aws_instance&quot;</span> <span class="s">&quot;tgres-test-tmp&quot;</span> <span class="p">{</span>
</span><span class="line">  <span class="nx">ami</span> <span class="p">=</span> <span class="s">&quot;ami-0b33d91d&quot;</span>
</span><span class="line">  <span class="nx">instance_type</span> <span class="p">=</span> <span class="s">&quot;c4.2xlarge&quot;</span>
</span><span class="line">  <span class="nx">subnet_id</span> <span class="p">=</span> <span class="s">&quot;REDACTED&quot;</span>
</span><span class="line">  <span class="nx">vpc_security_group_ids</span> <span class="p">=</span> <span class="p">[</span>
</span><span class="line">    <span class="s">&quot;REDACTED&quot;</span>
</span><span class="line">  <span class="p">]</span>
</span><span class="line">  <span class="nx">associate_public_ip_address</span> <span class="p">=</span> <span class="kc">true</span>
</span><span class="line">  <span class="nx">key_name</span> <span class="p">=</span> <span class="s">&quot;${var.key_name}&quot;</span>
</span><span class="line"><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>And then the following commands were used to prime everyting:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
<span class="line-number">35</span>
<span class="line-number">36</span>
<span class="line-number">37</span>
<span class="line-number">38</span>
<span class="line-number">39</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">sudo mke2fs /dev/sdh
</span><span class="line">sudo mkdir /ebs
</span><span class="line">sudo mount /dev/sdh /ebs
</span><span class="line">
</span><span class="line">sudo yum install -y postgresql95-server
</span><span class="line">sudo service postgresql95 initdb
</span><span class="line">sudo mkdir /ebs/pg
</span><span class="line">sudo mv /var/lib/pgsql95/data /ebs/pg/data
</span><span class="line">sudo ln -s /ebs/pg/data /var/lib/pgsql95/data
</span><span class="line">
</span><span class="line">sudo vi /var/lib/pgsql95/data/postgresql.conf
</span><span class="line"><span class="c"># BEGIN postgres config - paste this somewhere in the file</span>
</span><span class="line"><span class="nv">autovacuum_work_mem</span> <span class="o">=</span> -1
</span><span class="line"><span class="nv">synchronous_commit</span> <span class="o">=</span> off
</span><span class="line"><span class="nv">commit_delay</span> <span class="o">=</span> 100000
</span><span class="line"><span class="nv">autovacuum_max_workers</span> <span class="o">=</span> 10
</span><span class="line"><span class="nv">autovacuum_naptime</span> <span class="o">=</span> 1s
</span><span class="line"><span class="nv">autovacuum_vacuum_threshold</span> <span class="o">=</span> 2000
</span><span class="line"><span class="nv">autovacuum_vacuum_scale_factor</span> <span class="o">=</span> 0.0
</span><span class="line"><span class="nv">autovacuum_vacuum_cost_delay</span> <span class="o">=</span> 0
</span><span class="line"><span class="c"># END postgres config</span>
</span><span class="line">
</span><span class="line">sudo service postgresql95 restart
</span><span class="line">
</span><span class="line"><span class="c"># create PG database</span>
</span><span class="line">
</span><span class="line">sudo su - postgres
</span><span class="line">createuser -s ec2-user   <span class="c"># note -s is superuser - not necessary for tgres but just in case</span>
</span><span class="line">createdb tgres
</span><span class="line"><span class="nb">exit</span>
</span><span class="line">
</span><span class="line"><span class="c"># Tgres (requires Go - I used 1.8)</span>
</span><span class="line"><span class="c"># (or you can just scp it from some machine where you already have go environment)</span>
</span><span class="line">mkdir golang
</span><span class="line"><span class="nb">export </span><span class="nv">GOPATH</span><span class="o">=</span>~/golang/
</span><span class="line">go get github.com/tgres/tgres
</span><span class="line"><span class="nb">cd</span> /home/ec2-user/golang/src/github.com/tgres/tgres
</span><span class="line">go build
</span><span class="line">cp etc/tgres.conf.sample etc/tgres.conf
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The <code>tgres.conf</code> file looked like this:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">min-step                <span class="o">=</span> <span class="s2">&quot;10s&quot;</span>
</span><span class="line">
</span><span class="line">pid-file <span class="o">=</span>                 <span class="s2">&quot;tgres.pid&quot;</span>
</span><span class="line">log-file <span class="o">=</span>                 <span class="s2">&quot;log/tgres.log&quot;</span>
</span><span class="line">log-cycle-interval <span class="o">=</span>       <span class="s2">&quot;24h&quot;</span>
</span><span class="line">
</span><span class="line">max-flushes-per-second      <span class="o">=</span> 1000000 <span class="c"># NB - Deprecated setting</span>
</span><span class="line"><span class="nv">workers</span>                     <span class="o">=</span> 4       <span class="c"># NB - Deprecated setting</span>
</span><span class="line">
</span><span class="line">http-listen-spec            <span class="o">=</span> <span class="s2">&quot;0.0.0.0:8888&quot;</span>
</span><span class="line">graphite-line-listen-spec   <span class="o">=</span> <span class="s2">&quot;0.0.0.0:2003&quot;</span>
</span><span class="line">graphite-text-listen-spec   <span class="o">=</span> <span class="s2">&quot;0.0.0.0:2003&quot;</span>
</span><span class="line">graphite-udp-listen-spec    <span class="o">=</span> <span class="s2">&quot;0.0.0.0:2003&quot;</span>
</span><span class="line">graphite-pickle-listen-spec <span class="o">=</span> <span class="s2">&quot;0.0.0.0:2004&quot;</span>
</span><span class="line">
</span><span class="line">statsd-text-listen-spec     <span class="o">=</span> <span class="s2">&quot;0.0.0.0:8125&quot;</span>
</span><span class="line">statsd-udp-listen-spec      <span class="o">=</span> <span class="s2">&quot;0.0.0.0:8125&quot;</span>
</span><span class="line">stat-flush-interval         <span class="o">=</span> <span class="s2">&quot;10s&quot;</span>
</span><span class="line">stats-name-prefix           <span class="o">=</span> <span class="s2">&quot;stats&quot;</span>
</span><span class="line">
</span><span class="line">db-connect-string <span class="o">=</span> <span class="s2">&quot;host=/tmp dbname=tgres sslmode=disable&quot;</span>
</span><span class="line">
</span><span class="line"><span class="o">[[</span>ds<span class="o">]]</span>
</span><span class="line"><span class="nv">regexp</span> <span class="o">=</span> <span class="s2">&quot;.*&quot;</span>
</span><span class="line"><span class="nv">step</span> <span class="o">=</span> <span class="s2">&quot;10s&quot;</span>
</span><span class="line"><span class="c">#heartbeat = &quot;2h&quot;</span>
</span><span class="line"><span class="nv">rras</span> <span class="o">=</span> <span class="o">[</span><span class="s2">&quot;10s:6h&quot;</span>, <span class="s2">&quot;1m:7d&quot;</span>, <span class="s2">&quot;1h:1y&quot;</span><span class="o">]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Tgres was running with the following. The <code>TGRES_BLASTER</code> starts the
blaster goroutine.</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line"><span class="nv">TGRES_BIND</span><span class="o">=</span>0.0.0.0 <span class="nv">TGRES_BLASTER</span><span class="o">=</span>1 ./tgres
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Once you have Tgres with the blaster running, you can control it via
HTTP, e.g. the following would set it to 50K/s data points across 100K
series. Setting rate to 0 pauses it.</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sh"><span class="line">curl -v <span class="s2">&quot;http://127.0.0.1:8888/blaster/set?rate=50000&amp;n=100000&quot;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Storing Time Series in PostgreSQL - Optimize for Write]]></title>
    <link href="http://grisha.org/blog/2017/01/21/storing-time-seris-in-postgresql-optimize-for-write/"/>
    <updated>2017-01-21T09:33:00-05:00</updated>
    <id>http://grisha.org/blog/2017/01/21/storing-time-seris-in-postgresql-optimize-for-write</id>
    <content type="html"><![CDATA[<p>Continuing on the
<a href="http://grisha.org/blog/2016/12/16/storing-time-series-in-postgresql-part-ii/">previous</a>
write up on how time series data can be stored in Postgres
efficiently, here is another approach, this time providing for extreme
write performance.</p>

<p>The “horizontal” data structure in the last article requires an SQL
statement for every data point update. If you cache data points long
enough, you might be able to collect a bunch for a series and write
them out at once for a slight performance advantage. But there is no
way to update multiple series with a single statement, it’s always
at least one update per series. With a large number of series, this
can become a performance bottleneck. Can we do better?</p>

<p>One observation we can make about incoming time series data is that
commonly the data points are roughly from the same time period, the
current time, give or take. If we’re storing data at regularly-spaced
intervals, then it is extremely likely that many if not all of the
most current data points from various time series are going to belong
to the exact same time slot. Considering this observation, what if we
organized data points in rows of arrays, only now we would have a row
per timestamp while the position within the array would determine the
series?</p>

<p>Lets create the tables:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">rra_bundle</span> <span class="p">(</span>
</span><span class="line">  <span class="n">id</span> <span class="nb">SERIAL</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="k">PRIMARY</span> <span class="k">KEY</span><span class="p">,</span>
</span><span class="line">  <span class="n">step_ms</span> <span class="nb">INT</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span>
</span><span class="line">  <span class="n">steps_per_row</span> <span class="nb">INT</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span>
</span><span class="line">  <span class="k">size</span> <span class="nb">INT</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span>
</span><span class="line">  <span class="n">latest</span> <span class="n">TIMESTAMPTZ</span> <span class="k">DEFAULT</span> <span class="k">NULL</span><span class="p">);</span>
</span><span class="line">
</span><span class="line"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">rra</span> <span class="p">(</span>
</span><span class="line">  <span class="n">id</span> <span class="nb">SERIAL</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="k">PRIMARY</span> <span class="k">KEY</span><span class="p">,</span>
</span><span class="line">  <span class="n">ds_id</span> <span class="nb">INT</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span>
</span><span class="line">  <span class="n">rra_bundle_id</span> <span class="nb">INT</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span>
</span><span class="line">  <span class="n">pos</span> <span class="nb">INT</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">);</span>
</span><span class="line">
</span><span class="line"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">ts</span> <span class="p">(</span>
</span><span class="line">  <span class="n">rra_bundle_id</span> <span class="nb">INT</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span>
</span><span class="line">  <span class="n">i</span> <span class="nb">INT</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span>
</span><span class="line">  <span class="n">dp</span> <span class="n">DOUBLE</span> <span class="k">PRECISION</span><span class="p">[]</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="k">DEFAULT</span> <span class="s1">&#39;{}&#39;</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Notice how the step and size now become properties of the bundle
rather than the rra which now refers to a bundle. In the <code>ts</code> table,
<code>i</code> is the index in the round-robin archive (which in the previous
“horizontal” layout would be the array index).</p>

<p>The data we used before was a bunch of temperatures, lets add two more
series, one where temperature is 1 degree higher, and one where it’s 1
degree lower. (Not that it really matters).</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">rra_bundle</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">60000</span><span class="p">,</span> <span class="mi">1440</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="s1">&#39;2008-04-02 00:00:00-00&#39;</span><span class="p">);</span>
</span><span class="line">
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">rra</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">rra</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">rra</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">);</span>
</span><span class="line">
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;{64,65,63}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;{67,68,66}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;{70,71,69}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;{71,72,70}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;{72,73,71}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;{69,70,68}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="s1">&#39;{67,68,66}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="s1">&#39;{65,66,64}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="s1">&#39;{60,61,59}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="s1">&#39;{58,59,57}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;{59,60,58}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="s1">&#39;{62,63,61}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="s1">&#39;{68,69,67}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="s1">&#39;{70,71,69}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="s1">&#39;{71,72,70}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="s1">&#39;{72,73,71}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="s1">&#39;{77,78,76}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="s1">&#39;{70,71,69}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="s1">&#39;{71,72,70}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="s1">&#39;{73,74,72}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="s1">&#39;{75,76,74}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="s1">&#39;{79,80,78}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="s1">&#39;{82,83,81}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">23</span><span class="p">,</span> <span class="s1">&#39;{90,91,89}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="s1">&#39;{69,70,68}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="s1">&#39;{75,76,74}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">26</span><span class="p">,</span> <span class="s1">&#39;{80,81,79}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">27</span><span class="p">,</span> <span class="s1">&#39;{81,82,80}&#39;</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Notice that every INSERT adds data for all three of our series in a
single database operation!</p>

<p>Finally, let us create the view. (How it works is described in detail in the
<a href="http://grisha.org/blog/2016/12/16/storing-time-series-in-postgresql-part-ii/">previous article</a>)</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="k">CREATE</span> <span class="k">VIEW</span> <span class="n">tv</span> <span class="k">AS</span>
</span><span class="line">  <span class="k">SELECT</span> <span class="n">rra</span><span class="p">.</span><span class="n">id</span> <span class="k">as</span> <span class="n">rra_id</span><span class="p">,</span>
</span><span class="line">     <span class="n">rra_bundle</span><span class="p">.</span><span class="n">latest</span> <span class="o">-</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;1 MILLISECOND&#39;</span> <span class="o">*</span> <span class="n">rra_bundle</span><span class="p">.</span><span class="n">step_ms</span> <span class="o">*</span> <span class="n">rra_bundle</span><span class="p">.</span><span class="n">steps_per_row</span> <span class="o">*</span>
</span><span class="line">       <span class="k">MOD</span><span class="p">(</span><span class="n">rra_bundle</span><span class="p">.</span><span class="k">size</span> <span class="o">+</span> <span class="k">MOD</span><span class="p">(</span><span class="k">EXTRACT</span><span class="p">(</span><span class="n">EPOCH</span> <span class="k">FROM</span> <span class="n">rra_bundle</span><span class="p">.</span><span class="n">latest</span><span class="p">)::</span><span class="nb">BIGINT</span><span class="o">*</span><span class="mi">1000</span><span class="o">/</span><span class="p">(</span><span class="n">rra_bundle</span><span class="p">.</span><span class="n">step_ms</span> <span class="o">*</span> <span class="n">rra_bundle</span><span class="p">.</span><span class="n">steps_per_row</span><span class="p">),</span>
</span><span class="line">       <span class="n">rra_bundle</span><span class="p">.</span><span class="k">size</span><span class="p">)</span> <span class="o">-</span> <span class="n">i</span><span class="p">,</span> <span class="n">rra_bundle</span><span class="p">.</span><span class="k">size</span><span class="p">)</span> <span class="k">AS</span> <span class="n">t</span><span class="p">,</span>
</span><span class="line">     <span class="n">dp</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="k">AS</span> <span class="n">r</span>
</span><span class="line">  <span class="k">FROM</span> <span class="n">rra</span> <span class="k">AS</span> <span class="n">rra</span>
</span><span class="line">  <span class="k">JOIN</span> <span class="n">rra_bundle</span> <span class="k">AS</span> <span class="n">rra_bundle</span> <span class="k">ON</span> <span class="n">rra_bundle</span><span class="p">.</span><span class="n">id</span> <span class="o">=</span> <span class="n">rra</span><span class="p">.</span><span class="n">rra_bundle_id</span>
</span><span class="line">  <span class="k">JOIN</span> <span class="n">ts</span> <span class="k">AS</span> <span class="n">ts</span> <span class="k">ON</span> <span class="n">ts</span><span class="p">.</span><span class="n">rra_bundle_id</span> <span class="o">=</span> <span class="n">rra_bundle</span><span class="p">.</span><span class="n">id</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>And now let’s verify that it works:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="o">=&gt;</span> <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">tv</span> <span class="k">where</span> <span class="n">rra_id</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">order</span> <span class="k">by</span> <span class="n">t</span><span class="p">;</span>
</span><span class="line"> <span class="n">rra_id</span> <span class="o">|</span>           <span class="n">t</span>            <span class="o">|</span> <span class="n">r</span>
</span><span class="line"> <span class="c1">--------+------------------------+----</span>
</span><span class="line">       <span class="mi">1</span> <span class="o">|</span> <span class="mi">2008</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">06</span> <span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">-</span><span class="mi">00</span> <span class="o">|</span> <span class="mi">64</span>
</span><span class="line">       <span class="mi">1</span> <span class="o">|</span> <span class="mi">2008</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">07</span> <span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">-</span><span class="mi">00</span> <span class="o">|</span> <span class="mi">67</span>
</span><span class="line">       <span class="mi">1</span> <span class="o">|</span> <span class="mi">2008</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">08</span> <span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">-</span><span class="mi">00</span> <span class="o">|</span> <span class="mi">70</span>
</span><span class="line"> <span class="p">...</span>
</span><span class="line">
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>This approach makes writes blazingly fast though it does have its
drawbacks. For example there is no way to read a single series - even
though the view selects a single array element, under the hood
Postgres reads the whole row. Given that time series is more write
intensive and rarely read, this may not be a bad compromise.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Simple Tgres Part II - A High Rate Counter]]></title>
    <link href="http://grisha.org/blog/2016/12/28/simple-tgres-part-ii-a-high-rate-counter/"/>
    <updated>2016-12-28T17:06:00-05:00</updated>
    <id>http://grisha.org/blog/2016/12/28/simple-tgres-part-ii-a-high-rate-counter</id>
    <content type="html"><![CDATA[<p>Continuing on the <a href="http://grisha.org/blog/2016/12/21/simple-time-series-app-with-tgres/">the previous</a>
post on simple use of <a href="https://github.com/tgres/tgres">Tgres</a> components, let’s
try to count something that goes by really fast.</p>

<p>This time let’s start out with creating a memory-based SerDe. This
means that all our data is in memory and there is no database backing
our series.</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
</pre></td><td class="code"><pre><code class="go"><span class="line"><span class="kn">package</span> <span class="nx">main</span>
</span><span class="line">
</span><span class="line"><span class="kn">import</span> <span class="p">(</span>
</span><span class="line">    <span class="s">&quot;fmt&quot;</span>
</span><span class="line">    <span class="s">&quot;net/http&quot;</span>
</span><span class="line">    <span class="s">&quot;time&quot;</span>
</span><span class="line">
</span><span class="line">    <span class="s">&quot;github.com/tgres/tgres/dsl&quot;</span>
</span><span class="line">    <span class="nx">h</span> <span class="s">&quot;github.com/tgres/tgres/http&quot;</span>
</span><span class="line">    <span class="s">&quot;github.com/tgres/tgres/receiver&quot;</span>
</span><span class="line">    <span class="s">&quot;github.com/tgres/tgres/rrd&quot;</span>
</span><span class="line">    <span class="s">&quot;github.com/tgres/tgres/serde&quot;</span>
</span><span class="line"><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="kd">func</span> <span class="nx">main</span><span class="p">()</span> <span class="p">{</span>
</span><span class="line">
</span><span class="line">    <span class="nx">step</span> <span class="o">:=</span> <span class="mi">1</span> <span class="o">*</span> <span class="nx">time</span><span class="p">.</span><span class="nx">Second</span> <span class="c1">// 1 second resolution</span>
</span><span class="line">    <span class="nx">span</span> <span class="o">:=</span> <span class="mi">600</span> <span class="o">*</span> <span class="nx">step</span>      <span class="c1">// spanning 10 minutes</span>
</span><span class="line">
</span><span class="line">    <span class="c1">// In-memory SerDe</span>
</span><span class="line">    <span class="nx">ms</span> <span class="o">:=</span> <span class="nx">serde</span><span class="p">.</span><span class="nx">NewMemSerDe</span><span class="p">()</span>
</span><span class="line">
</span><span class="line">    <span class="c1">// Create a receiver of our data points backed by the above</span>
</span><span class="line">    <span class="c1">// memory SerDe</span>
</span><span class="line">    <span class="nx">rcvr</span> <span class="o">:=</span> <span class="nx">receiver</span><span class="p">.</span><span class="nx">New</span><span class="p">(</span><span class="nx">ms</span><span class="p">,</span> <span class="o">&amp;</span><span class="nx">receiver</span><span class="p">.</span><span class="nx">SimpleDSFinder</span><span class="p">{</span><span class="o">&amp;</span><span class="nx">rrd</span><span class="p">.</span><span class="nx">DSSpec</span><span class="p">{</span>
</span><span class="line">        <span class="nx">Step</span><span class="p">:</span> <span class="nx">step</span><span class="p">,</span>
</span><span class="line">        <span class="nx">RRAs</span><span class="p">:</span> <span class="p">[]</span><span class="nx">rrd</span><span class="p">.</span><span class="nx">RRASpec</span><span class="p">{</span>
</span><span class="line">            <span class="nx">rrd</span><span class="p">.</span><span class="nx">RRASpec</span><span class="p">{</span><span class="nx">Function</span><span class="p">:</span> <span class="nx">rrd</span><span class="p">.</span><span class="nx">WMEAN</span><span class="p">,</span>
</span><span class="line">                <span class="nx">Step</span><span class="p">:</span> <span class="nx">step</span><span class="p">,</span>
</span><span class="line">                <span class="nx">Span</span><span class="p">:</span> <span class="nx">span</span><span class="p">,</span>
</span><span class="line">            <span class="p">},</span>
</span><span class="line">        <span class="p">}}})</span>
</span><span class="line">    <span class="nx">rcvr</span><span class="p">.</span><span class="nx">Start</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Now let’s create a goroutine which creates data points as fast as it
can, the difference from the previous blog post is that we are using
QueueGauge(), which is a <em>paced metric</em>, meaning that it flushes to the
time series only periodically (once per second by default) so as to
not overwhelm the I/O and or network (even though in this case it doesn’t
really matter since we’re using a memory-based SerDe anyway).</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="go"><span class="line">    <span class="nx">start</span> <span class="o">:=</span> <span class="nx">time</span><span class="p">.</span><span class="nx">Now</span><span class="p">()</span>
</span><span class="line">    <span class="nx">end</span> <span class="o">:=</span> <span class="nx">start</span><span class="p">.</span><span class="nx">Add</span><span class="p">(</span><span class="nx">span</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">    <span class="k">go</span> <span class="kd">func</span><span class="p">()</span> <span class="p">{</span>
</span><span class="line">        <span class="nx">n</span> <span class="o">:=</span> <span class="mi">0</span>
</span><span class="line">        <span class="k">for</span> <span class="nx">t</span> <span class="o">:=</span> <span class="nx">time</span><span class="p">.</span><span class="nx">Now</span><span class="p">();</span> <span class="nx">t</span><span class="p">.</span><span class="nx">Before</span><span class="p">(</span><span class="nx">end</span><span class="p">);</span> <span class="nx">t</span> <span class="p">=</span> <span class="nx">time</span><span class="p">.</span><span class="nx">Now</span><span class="p">()</span> <span class="p">{</span>
</span><span class="line">            <span class="nx">rcvr</span><span class="p">.</span><span class="nx">QueueGauge</span><span class="p">(</span><span class="nx">serde</span><span class="p">.</span><span class="nx">Ident</span><span class="p">{</span><span class="s">&quot;name&quot;</span><span class="p">:</span><span class="s">&quot;foo.bar&quot;</span><span class="p">},</span> <span class="nb">float64</span><span class="p">(</span><span class="nx">n</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="nx">t</span><span class="p">.</span><span class="nx">Sub</span><span class="p">(</span><span class="nx">start</span><span class="p">)).</span><span class="nx">Seconds</span><span class="p">())</span>
</span><span class="line">            <span class="nx">n</span><span class="o">++</span>
</span><span class="line">        <span class="p">}</span>
</span><span class="line">    <span class="p">}()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>And finally, as before, we need to hook up a couple of http handlers:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="go"><span class="line">    <span class="nx">db</span> <span class="o">:=</span> <span class="nx">dsl</span><span class="p">.</span><span class="nx">NewNamedDSFetcher</span><span class="p">(</span><span class="nx">ms</span><span class="p">.</span><span class="nx">Fetcher</span><span class="p">())</span>
</span><span class="line">
</span><span class="line">    <span class="nx">http</span><span class="p">.</span><span class="nx">HandleFunc</span><span class="p">(</span><span class="s">&quot;/metrics/find&quot;</span><span class="p">,</span> <span class="nx">h</span><span class="p">.</span><span class="nx">GraphiteMetricsFindHandler</span><span class="p">(</span><span class="nx">db</span><span class="p">))</span>
</span><span class="line">    <span class="nx">http</span><span class="p">.</span><span class="nx">HandleFunc</span><span class="p">(</span><span class="s">&quot;/render&quot;</span><span class="p">,</span> <span class="nx">h</span><span class="p">.</span><span class="nx">GraphiteRenderHandler</span><span class="p">(</span><span class="nx">db</span><span class="p">))</span>
</span><span class="line">
</span><span class="line">    <span class="nx">listenSpec</span> <span class="o">:=</span> <span class="s">&quot;:8088&quot;</span>
</span><span class="line">    <span class="nx">fmt</span><span class="p">.</span><span class="nx">Printf</span><span class="p">(</span><span class="s">&quot;Waiting for requests on %s\n&quot;</span><span class="p">,</span> <span class="nx">listenSpec</span><span class="p">)</span>
</span><span class="line">    <span class="nx">http</span><span class="p">.</span><span class="nx">ListenAndServe</span><span class="p">(</span><span class="nx">listenSpec</span><span class="p">,</span> <span class="kc">nil</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="p">}</span> <span class="c1">// end of main()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Now if we run the above code with something like
<code>go run simpletgres.go</code>, we’ll notice that unlike with the previous
example, the web server starts right away, and the data points are
being written while the server is running. If we aim Grafana at it,
we should be able to see the chart update in real time.</p>

<p>After a couple of minutes, mine looks like this:</p>

<p><img src="http://grisha.org/images/simple-tgres01.png" /></p>

<p>So my macbook can crank these out at about 2.5 million per second.</p>

<p>In my experience instrumenting my apps with simple counters like this
and having them available directly from the app without having to send
them to a separate statsd server somewhere has been extremely useful in
helping understand performance and other issues.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Why is there no Formal Definition of Time Series?]]></title>
    <link href="http://grisha.org/blog/2016/12/23/time-series-what-is-it/"/>
    <updated>2016-12-23T09:13:00-05:00</updated>
    <id>http://grisha.org/blog/2016/12/23/time-series-what-is-it</id>
    <content type="html"><![CDATA[<p>If you’re reading this, chances are you may have searched for
definition of “Time Series”. And, like me, you were probably
disappointed by what you’ve found.</p>

<p>The most popular “definition” I come across amongst our fellow
programmer folk is that it’s “data points with timestamps”. Or something
like that. And you can make charts from it. And that’s about it, alas.</p>

<p>The word <em>time</em> suggests that is has something to do with time. At
first it seems reasonable, I bite. The word <em>series</em> is a little more
peculiar. A mathematician would argue that a series is a <a href="https://en.wikipedia.org/wiki/Series_(mathematics)"><em>sum</em> of a sequence</a>.
Most people though think “series” and “sequence” are the
same thing, and that’s fine. But it’s a clue that <em>time series</em> is
not a scientific term, because it would have been called
<em>time sequence</em> most likely.</p>

<p>Lets get back to the time aspect of it. Why do data points need
timestamps? Or do they? Isn’t it the time <em>interval</em> between points
that is most essential, rather than the absolute time? And if the data
points are spaced equally (which conforms to the most common definiton
of time series), then what purpose would <em>any</em> time-related
information attached to a data point serve?</p>

<p>To understand this better, picture a time chart. Of anything -
temperature, price of bitcoin over a week, whatever. Now think - does
the absolute time of every point provide any useful information to
you? Does the essential meaning of the chart change depending on
whether it shows the price of bitcoin in the year 2016 or 2098 or
10923?</p>

<p>Doesn’t it seem like “time” in “time series” is a bit of a red
herring?</p>

<p>Here is another example. Let’s say I decide to travel from
San-Francisco to New York taking measurements of elevation above the
sea level at every mile. I then plot that sequence on a chart where
x-axis is distance traveled and y-axis is elevation. You would agree
that this chart is not a “time series” by any stretch, right? But then
if I renamed x-axis to “time traveled” (let’s assume I moved at
constant speed), the chart wouldn’t change at all, but now it’s okay
to call it “time series”?</p>

<p>So it’s no surprise that there is no formal definition of “time
series”.  In the end a “time series” is just a <em>sequence</em>. There are
no timestamps required and there is nothing at all special regarding a
dimension being time as opposed to any other unit, which is why there
is no mathematical definition of “time series”. Time series is a
colloquial term etymological origins of which are not known to me, but
it’s not a thing from a scientific perspective, I’m afraid.</p>

<p>Next time you hear “time series” just substitute it with “sequence” and
see how much sense that makes. For example a “time series database” is
a “sequence database”, i.e. database optimized for sequences. Aren’t
all relational databases optimized for sequences?</p>

<p>Something to think about over the holidays…</p>

<p>Edit: Someone brought up the subject of <a href="https://en.wikipedia.org/wiki/Unevenly_spaced_time_series"><em>unevenly-spaced time series</em></a>.
All series are evenly spaced given proper resolution. An
unevenly-spaced time series with timestamps accurate to 1 millisecond
is a sparse evenly-spaced series with a 1 millisecond resolution.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Simple Time Series App with Tgres]]></title>
    <link href="http://grisha.org/blog/2016/12/21/simple-time-series-app-with-tgres/"/>
    <updated>2016-12-21T19:55:00-05:00</updated>
    <id>http://grisha.org/blog/2016/12/21/simple-time-series-app-with-tgres</id>
    <content type="html"><![CDATA[<p>Did you know you can use <a href="https://github.com/tgres/tgres">Tgres</a> components
in your code without PostgreSQL, and in
just a dozen lines of code instrument your program with a time
series. This example shows a complete server emulating Graphite API
which you can use with <a href="http://grafana.org/">Grafana</a> (or any other tool).</p>

<p>In this example we will be using three Tgres packages like so (in addition to
a few standard ones, I’m skipping them here for brevity - complete source code <a href="https://gist.github.com/grisha/9561e7837cff1340b218054f36430187">gist</a>):</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="go"><span class="line"><span class="kn">import</span> <span class="p">(</span>
</span><span class="line">    <span class="s">&quot;github.com/tgres/tgres/dsl&quot;</span>
</span><span class="line">    <span class="nx">h</span> <span class="s">&quot;github.com/tgres/tgres/http&quot;</span>
</span><span class="line">    <span class="s">&quot;github.com/tgres/tgres/rrd&quot;</span>
</span><span class="line"><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>First we need a <a href="https://godoc.org/github.com/tgres/tgres/rrd#DataSource">Data Source</a>.
This will create a Data Source containing one Round Robin Archive with a 10 second resolution
spanning 1000 seconds.</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="go"><span class="line"><span class="nx">step</span> <span class="o">:=</span> <span class="mi">10</span> <span class="o">*</span> <span class="nx">time</span><span class="p">.</span><span class="nx">Second</span>
</span><span class="line"><span class="nx">span</span> <span class="o">:=</span> <span class="mi">100</span> <span class="o">*</span> <span class="nx">step</span>
</span><span class="line">
</span><span class="line"><span class="nx">ds</span> <span class="o">:=</span> <span class="nx">rrd</span><span class="p">.</span><span class="nx">NewDataSource</span><span class="p">(</span><span class="nx">rrd</span><span class="p">.</span><span class="nx">DSSpec</span><span class="p">{</span>
</span><span class="line">    <span class="nx">Step</span><span class="p">:</span> <span class="mi">1</span> <span class="o">*</span> <span class="nx">time</span><span class="p">.</span><span class="nx">Second</span><span class="p">,</span>
</span><span class="line">    <span class="nx">RRAs</span><span class="p">:</span> <span class="p">[]</span><span class="nx">rrd</span><span class="p">.</span><span class="nx">RRASpec</span><span class="p">{</span>
</span><span class="line">        <span class="nx">rrd</span><span class="p">.</span><span class="nx">RRASpec</span><span class="p">{</span><span class="nx">Step</span><span class="p">:</span> <span class="nx">step</span><span class="p">,</span> <span class="nx">Span</span><span class="p">:</span> <span class="nx">span</span><span class="p">},</span>
</span><span class="line">    <span class="p">},</span>
</span><span class="line"><span class="p">})</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Let’s shove a bunch of data points into it. To make it look extra
nice, we can make these points look like a sinusoid with this little
function:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="go"><span class="line"><span class="kd">func</span> <span class="nx">sinTime</span><span class="p">(</span><span class="nx">t</span> <span class="nx">time</span><span class="p">.</span><span class="nx">Time</span><span class="p">,</span> <span class="nx">span</span> <span class="nx">time</span><span class="p">.</span><span class="nx">Duration</span><span class="p">)</span> <span class="kt">float64</span> <span class="p">{</span>
</span><span class="line">    <span class="nx">x</span> <span class="o">:=</span> <span class="mi">2</span> <span class="o">*</span> <span class="nx">math</span><span class="p">.</span><span class="nx">Pi</span> <span class="o">/</span> <span class="nx">span</span><span class="p">.</span><span class="nx">Seconds</span><span class="p">()</span> <span class="o">*</span> <span class="nb">float64</span><span class="p">(</span><span class="nx">t</span><span class="p">.</span><span class="nx">Unix</span><span class="p">()</span><span class="o">%</span><span class="p">(</span><span class="nx">span</span><span class="p">.</span><span class="nx">Nanoseconds</span><span class="p">()</span><span class="o">/</span><span class="mf">1e9</span><span class="p">))</span>
</span><span class="line">    <span class="k">return</span> <span class="nx">math</span><span class="p">.</span><span class="nx">Sin</span><span class="p">(</span><span class="nx">x</span><span class="p">)</span>
</span><span class="line"><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>And now for the actual population of the series:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="go"><span class="line"><span class="nx">start</span> <span class="o">:=</span> <span class="nx">time</span><span class="p">.</span><span class="nx">Now</span><span class="p">().</span><span class="nx">Add</span><span class="p">(</span><span class="o">-</span><span class="nx">span</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="k">for</span> <span class="nx">i</span> <span class="o">:=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="p">&lt;</span> <span class="nb">int</span><span class="p">(</span><span class="nx">span</span><span class="o">/</span><span class="nx">step</span><span class="p">);</span> <span class="nx">i</span><span class="o">++</span> <span class="p">{</span>
</span><span class="line">    <span class="nx">t</span> <span class="o">:=</span> <span class="nx">start</span><span class="p">.</span><span class="nx">Add</span><span class="p">(</span><span class="nx">time</span><span class="p">.</span><span class="nx">Duration</span><span class="p">(</span><span class="nx">i</span><span class="p">)</span> <span class="o">*</span> <span class="nx">step</span><span class="p">)</span>
</span><span class="line">    <span class="nx">ds</span><span class="p">.</span><span class="nx">ProcessDataPoint</span><span class="p">(</span><span class="nx">sinTime</span><span class="p">(</span><span class="nx">t</span><span class="p">,</span> <span class="nx">span</span><span class="p">),</span> <span class="nx">t</span><span class="p">)</span>
</span><span class="line"><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>We will also need to create a <a href="https://godoc.org/github.com/tgres/tgres/dsl#NamedDSFetcher">NamedDSFetcher</a>,
the structure which knows how to search dot-separated series names a la Graphite.</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="go"><span class="line"><span class="nx">db</span> <span class="o">:=</span> <span class="nx">dsl</span><span class="p">.</span><span class="nx">NewNamedDSFetcherMap</span><span class="p">(</span><span class="kd">map</span><span class="p">[</span><span class="kt">string</span><span class="p">]</span><span class="nx">rrd</span><span class="p">.</span><span class="nx">DataSourcer</span><span class="p">{</span><span class="s">&quot;foo.bar&quot;</span><span class="p">:</span> <span class="nx">ds</span><span class="p">})</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Finally, we need to create two http handlers which will mimic a
Graphite server and start listening for requests:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="go"><span class="line"><span class="nx">http</span><span class="p">.</span><span class="nx">HandleFunc</span><span class="p">(</span><span class="s">&quot;/metrics/find&quot;</span><span class="p">,</span> <span class="nx">h</span><span class="p">.</span><span class="nx">GraphiteMetricsFindHandler</span><span class="p">(</span><span class="nx">db</span><span class="p">))</span>
</span><span class="line"><span class="nx">http</span><span class="p">.</span><span class="nx">HandleFunc</span><span class="p">(</span><span class="s">&quot;/render&quot;</span><span class="p">,</span> <span class="nx">h</span><span class="p">.</span><span class="nx">GraphiteRenderHandler</span><span class="p">(</span><span class="nx">db</span><span class="p">))</span>
</span><span class="line">
</span><span class="line"><span class="nx">listenSpec</span> <span class="o">:=</span> <span class="s">&quot;:8088&quot;</span>
</span><span class="line"><span class="nx">fmt</span><span class="p">.</span><span class="nx">Printf</span><span class="p">(</span><span class="s">&quot;Waiting for requests on %s\n&quot;</span><span class="p">,</span> <span class="nx">listenSpec</span><span class="p">)</span>
</span><span class="line"><span class="nx">http</span><span class="p">.</span><span class="nx">ListenAndServe</span><span class="p">(</span><span class="nx">listenSpec</span><span class="p">,</span> <span class="kc">nil</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Now if you point Grafana at it, it will happily think it’s Graphite
and should show you a chart like this:</p>

<p><img src="http://grisha.org/images/simple-tgres00.png" /></p>

<p>Note that you can use all kinds of Graphite functions at this point -
it all “just works”.</p>

<p>Enjoy!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Storing Time Series in PostgreSQL (Continued)]]></title>
    <link href="http://grisha.org/blog/2016/12/16/storing-time-series-in-postgresql-part-ii/"/>
    <updated>2016-12-16T19:35:00-05:00</updated>
    <id>http://grisha.org/blog/2016/12/16/storing-time-series-in-postgresql-part-ii</id>
    <content type="html"><![CDATA[<p>Edit: there is now a <a href="http://grisha.org/blog/2017/01/21/storing-time-seris-in-postgresql-optimize-for-write">part iii</a> in this series of articles.</p>

<p>I have <a href="http://grisha.org/blog/2015/09/23/storing-time-series-in-postgresql-efficiently/">previously written</a> how
time series can be stored in PostgreSQL efficiently using <a href="https://www.postgresql.org/docs/current/static/arrays.html">arrays</a>.</p>

<p>As a continuation of that article, I shall attempt to describe in detail the inner workings of an
<a href="https://en.wikipedia.org/wiki/View_(SQL)">SQL view</a> that <a href="https://github.com/tgres/tgres">Tgres</a> uses to
make an array of numbers appear as a regular table
(<a href="https://github.com/tgres/tgres/blob/bc718e3999650b7aab934517179ea47632530d28/serde/postgres.go#L235-L242">link to code</a>).</p>

<p>In short, I will explain how incomprehensible data like this:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="o">=&gt;</span> <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">ts</span><span class="p">;</span>
</span><span class="line"> <span class="n">rra_id</span> <span class="o">|</span> <span class="n">n</span> <span class="o">|</span>           <span class="n">dp</span>
</span><span class="line"><span class="c1">--------+---+------------------------</span>
</span><span class="line">      <span class="mi">1</span> <span class="o">|</span> <span class="mi">0</span> <span class="o">|</span> <span class="err">{</span><span class="mi">64</span><span class="p">,</span><span class="mi">67</span><span class="p">,</span><span class="mi">70</span><span class="p">,</span><span class="mi">71</span><span class="p">,</span><span class="mi">72</span><span class="p">,</span><span class="mi">69</span><span class="p">,</span><span class="mi">67</span><span class="err">}</span>
</span><span class="line">      <span class="mi">1</span> <span class="o">|</span> <span class="mi">1</span> <span class="o">|</span> <span class="err">{</span><span class="mi">65</span><span class="p">,</span><span class="mi">60</span><span class="p">,</span><span class="mi">58</span><span class="p">,</span><span class="mi">59</span><span class="p">,</span><span class="mi">62</span><span class="p">,</span><span class="mi">68</span><span class="p">,</span><span class="mi">70</span><span class="err">}</span>
</span><span class="line">      <span class="mi">1</span> <span class="o">|</span> <span class="mi">2</span> <span class="o">|</span> <span class="err">{</span><span class="mi">71</span><span class="p">,</span><span class="mi">72</span><span class="p">,</span><span class="mi">77</span><span class="p">,</span><span class="mi">70</span><span class="p">,</span><span class="mi">71</span><span class="p">,</span><span class="mi">73</span><span class="p">,</span><span class="mi">75</span><span class="err">}</span>
</span><span class="line">      <span class="mi">1</span> <span class="o">|</span> <span class="mi">3</span> <span class="o">|</span> <span class="err">{</span><span class="mi">79</span><span class="p">,</span><span class="mi">82</span><span class="p">,</span><span class="mi">90</span><span class="p">,</span><span class="mi">69</span><span class="p">,</span><span class="mi">75</span><span class="p">,</span><span class="mi">80</span><span class="p">,</span><span class="mi">81</span><span class="err">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>… can be transformed in an SQL view to appear as so:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="o">=&gt;</span> <span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">tv</span> <span class="k">order</span> <span class="k">by</span> <span class="n">t</span><span class="p">;</span>
</span><span class="line"> <span class="n">rra_id</span> <span class="o">|</span>           <span class="n">t</span>            <span class="o">|</span> <span class="n">r</span>
</span><span class="line"><span class="c1">--------+------------------------+----</span>
</span><span class="line">      <span class="mi">1</span> <span class="o">|</span> <span class="mi">2008</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">06</span> <span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">+</span><span class="mi">00</span> <span class="o">|</span> <span class="mi">64</span>
</span><span class="line">      <span class="mi">1</span> <span class="o">|</span> <span class="mi">2008</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">07</span> <span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">+</span><span class="mi">00</span> <span class="o">|</span> <span class="mi">67</span>
</span><span class="line">      <span class="mi">1</span> <span class="o">|</span> <span class="mi">2008</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">08</span> <span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">+</span><span class="mi">00</span> <span class="o">|</span> <span class="mi">70</span>
</span><span class="line">      <span class="mi">1</span> <span class="o">|</span> <span class="mi">2008</span><span class="o">-</span><span class="mi">03</span><span class="o">-</span><span class="mi">09</span> <span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="o">+</span><span class="mi">00</span> <span class="o">|</span> <span class="mi">71</span>
</span><span class="line"><span class="p">...</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>This write up will make a lot more sense if you read the
<a href="http://grisha.org/blog/2015/09/23/storing-time-series-in-postgresql-efficiently/">previous post</a> first.
To recap, Tgres stores series in an array broken up over multiple
table rows each containing an array representing a segment of the
series. The series array is a round-robin structure, which means
that it occupies a fixed amount of space and we do not need to worry
about expiring data points: the round-robin nature of the array
takes care of it by overwriting old data with new on assignment.</p>

<p>An additional benefit of such a fixed interval round-robin structure
is that we do not need to store timestamps for every data point. If we
know the timestamp of the latest entry along with the series step and size,
we can extrapolate the timestamp of any point in the series.</p>

<p>Tgres creates an SQL view which takes care of this extrapolation and
makes this data easy to query. Tgres actually uses this view as its
only source of time series information when reading from the database
thus delegating all the processing to the database server, where it is
close to the data and most efficient.</p>

<p>If you would like to follow along on the Postgres command line, feel
free to create and populate the tables with the following SQL, which
is nearly identical to the schema used by Tgres:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">rra</span> <span class="p">(</span>
</span><span class="line">  <span class="n">id</span> <span class="nb">SERIAL</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="k">PRIMARY</span> <span class="k">KEY</span><span class="p">,</span>
</span><span class="line">  <span class="n">step_s</span> <span class="nb">INT</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span>
</span><span class="line">  <span class="n">steps_per_row</span> <span class="nb">INT</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span>
</span><span class="line">  <span class="k">size</span> <span class="nb">INT</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span>
</span><span class="line">  <span class="n">width</span> <span class="nb">INT</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span>
</span><span class="line">  <span class="n">latest</span> <span class="n">TIMESTAMPTZ</span> <span class="k">DEFAULT</span> <span class="k">NULL</span><span class="p">);</span>
</span><span class="line">
</span><span class="line"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">ts</span> <span class="p">(</span>
</span><span class="line">  <span class="n">rra_id</span> <span class="nb">INT</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span>
</span><span class="line">  <span class="n">n</span> <span class="nb">INT</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span>
</span><span class="line">  <span class="n">dp</span> <span class="n">DOUBLE</span> <span class="k">PRECISION</span><span class="p">[]</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="k">DEFAULT</span> <span class="s1">&#39;{}&#39;</span><span class="p">);</span>
</span><span class="line">
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">rra</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">1440</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="s1">&#39;2008-04-02 00:00:00-00&#39;</span><span class="p">);</span>
</span><span class="line">
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;{64,67,70,71,72,69,67}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;{65,60,58,59,62,68,70}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;{71,72,77,70,71,73,75}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;{79,82,90,69,75,80,81}&#39;</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>And finally create the view:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="k">CREATE</span> <span class="k">VIEW</span> <span class="n">tv</span> <span class="k">AS</span>
</span><span class="line">  <span class="k">SELECT</span> <span class="n">rra</span><span class="p">.</span><span class="n">id</span> <span class="n">rra_id</span><span class="p">,</span>
</span><span class="line">         <span class="n">latest</span> <span class="o">-</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;1 SECOND&#39;</span> <span class="o">*</span> <span class="n">rra</span><span class="p">.</span><span class="n">step_s</span> <span class="o">*</span> <span class="n">rra</span><span class="p">.</span><span class="n">steps_per_row</span> <span class="o">*</span>
</span><span class="line">           <span class="k">MOD</span><span class="p">(</span><span class="n">rra</span><span class="p">.</span><span class="k">size</span> <span class="o">+</span> <span class="k">MOD</span><span class="p">(</span><span class="k">EXTRACT</span><span class="p">(</span><span class="n">EPOCH</span> <span class="k">FROM</span> <span class="n">rra</span><span class="p">.</span><span class="n">latest</span><span class="p">)::</span><span class="nb">BIGINT</span><span class="o">/</span><span class="p">(</span><span class="n">rra</span><span class="p">.</span><span class="n">step_s</span> <span class="o">*</span> <span class="n">rra</span><span class="p">.</span><span class="n">steps_per_row</span><span class="p">),</span> <span class="k">size</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
</span><span class="line">           <span class="o">-</span> <span class="p">(</span><span class="n">generate_subscripts</span><span class="p">(</span><span class="n">dp</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">n</span> <span class="o">*</span> <span class="n">width</span><span class="p">),</span> <span class="n">rra</span><span class="p">.</span><span class="k">size</span><span class="p">)</span> <span class="k">AS</span> <span class="n">t</span><span class="p">,</span>
</span><span class="line">         <span class="k">UNNEST</span><span class="p">(</span><span class="n">dp</span><span class="p">)</span> <span class="k">AS</span> <span class="n">r</span>
</span><span class="line">    <span class="k">FROM</span> <span class="n">rra</span>
</span><span class="line">   <span class="k">INNER</span> <span class="k">JOIN</span> <span class="n">ts</span> <span class="n">ts</span> <span class="k">ON</span> <span class="n">ts</span><span class="p">.</span><span class="n">rra_id</span> <span class="o">=</span> <span class="n">rra</span><span class="p">.</span><span class="n">id</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Now give it a whirl with a <code>SELECT * FROM tv ORDER BY t</code>. Impressive? So how does it work?</p>

<p>First let’s go over the columns of the rra table.</p>

<ul>
  <li><code>step_s</code>: the minimal unit of time expressed in seconds (60 or 1 minute in the above data).</li>
  <li><code>steps_per_row</code>: the number of the <code>step_s</code> intervals in one slot of our time series.
 In our example it is 1440, which is the number of minutes in a day, thus making our time series
 resolution <em>one day</em>.</li>
  <li><code>size</code>: number of slots in the series. Ours is 28, i.e. four weeks.</li>
  <li><code>width</code>: size of a segment which will be stored in a single row, which in our case
 is 7 (one week).</li>
  <li><code>latest</code>: the timestamp of the last data point in the series.</li>
</ul>

<p>Next, let’s look at the <code>UNNEST</code> keyword in the SQL of the view. <code>UNNEST</code> takes an array and turns it into row, e.g.:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="o">=&gt;</span> <span class="k">SELECT</span> <span class="k">UNNEST</span><span class="p">(</span><span class="n">dp</span><span class="p">)</span> <span class="k">AS</span> <span class="n">r</span> <span class="k">FROM</span> <span class="n">ts</span><span class="p">;</span>
</span><span class="line"> <span class="n">r</span>
</span><span class="line"><span class="c1">----</span>
</span><span class="line"> <span class="mi">64</span>
</span><span class="line"> <span class="mi">67</span>
</span><span class="line"><span class="p">...</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><code>UNNEST</code> works in conjunction with the <code>generate_subscripts</code>
PostgreSQL function which generates index values:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="o">=&gt;</span> <span class="k">SELECT</span> <span class="n">generate_subscripts</span><span class="p">(</span><span class="n">dp</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="k">AS</span> <span class="n">i</span><span class="p">,</span> <span class="k">UNNEST</span><span class="p">(</span><span class="n">dp</span><span class="p">)</span> <span class="k">AS</span> <span class="n">r</span> <span class="k">FROM</span> <span class="n">ts</span><span class="p">;</span>
</span><span class="line"> <span class="n">i</span> <span class="o">|</span> <span class="n">r</span>
</span><span class="line"><span class="c1">---+----</span>
</span><span class="line"> <span class="mi">1</span> <span class="o">|</span> <span class="mi">64</span>
</span><span class="line"> <span class="mi">2</span> <span class="o">|</span> <span class="mi">67</span>
</span><span class="line"><span class="p">...</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Let us now zoom in on the very long expression in the view, here it is again:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="n">latest</span> <span class="o">-</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;1 SECOND&#39;</span> <span class="o">*</span> <span class="n">rra</span><span class="p">.</span><span class="n">step_s</span> <span class="o">*</span> <span class="n">rra</span><span class="p">.</span><span class="n">steps_per_row</span> <span class="o">*</span>
</span><span class="line">  <span class="k">MOD</span><span class="p">(</span><span class="n">rra</span><span class="p">.</span><span class="k">size</span> <span class="o">+</span> <span class="k">MOD</span><span class="p">(</span><span class="k">EXTRACT</span><span class="p">(</span><span class="n">EPOCH</span> <span class="k">FROM</span> <span class="n">rra</span><span class="p">.</span><span class="n">latest</span><span class="p">)::</span><span class="nb">BIGINT</span><span class="o">/</span><span class="p">(</span><span class="n">rra</span><span class="p">.</span><span class="n">step_s</span> <span class="o">*</span> <span class="n">rra</span><span class="p">.</span><span class="n">steps_per_row</span><span class="p">),</span> <span class="k">size</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
</span><span class="line">  <span class="o">-</span> <span class="p">(</span><span class="n">generate_subscripts</span><span class="p">(</span><span class="n">dp</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">n</span> <span class="o">*</span> <span class="n">width</span><span class="p">),</span> <span class="n">rra</span><span class="p">.</span><span class="k">size</span><span class="p">)</span> <span class="k">AS</span> <span class="n">t</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>A perhaps not immediately apparent trick to how all this works is that all
our series are aligned
on the <a href="https://en.wikipedia.org/wiki/Unix_time">beginning of the epoch</a>.
This means that at UNIX time 0, any series’ slot index is 0. From then on it
increments sequentially until the series size is reached, at which point
it wraps-around to 0 (thus “round-robin”). Armed with this information we
can calculate the index for any point in time.</p>

<p>The formula for calculating the index <code>i</code> for a given time <code>t</code> is:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">i</span> <span class="o">=</span> <span class="n">t</span><span class="o">/</span><span class="n">step</span> <span class="o">%</span> <span class="n">size</span><span class="o">.</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>We need time to be expressed as a UNIX time which is done
with <code>EXTRACT(EPOCH FROM rra.latest)::BIGINT</code>. Now you should recognize
the above formula in the more verbose expression</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="k">MOD</span><span class="p">(</span><span class="k">EXTRACT</span><span class="p">(</span><span class="n">EPOCH</span> <span class="k">FROM</span> <span class="n">rra</span><span class="p">.</span><span class="n">latest</span><span class="p">)::</span><span class="nb">BIGINT</span><span class="o">/</span><span class="p">(</span><span class="n">rra</span><span class="p">.</span><span class="n">step_s</span> <span class="o">*</span> <span class="n">rra</span><span class="p">.</span><span class="n">steps_per_row</span><span class="p">),</span> <span class="k">size</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>where <code>rra.step_s * rra.steps_per_row</code> is the size of our series in seconds.</p>

<p>Next, we need to compute the <em>distance</em> between the current slot and the
last slot (for which we know the timestamp). I.e. if the last slot is <code>i</code> and the slot we need the
timestamp for is <code>j</code>, the distance between them is <code>i-j</code>, but with a
caveat: it is possible for <code>j</code> to be greater than <code>i</code> if the series
wraps around, in which case the distance is the sum of the distance from
<code>j</code> to the end of the series and the distance from the beginning to
<code>i</code>. If you ponder over it with a pencil and paper long enough, you
will arrive at the following formula for distance between two slots
<code>i</code> and <code>j</code> in a wrap-around array:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">distance</span> <span class="o">=</span> <span class="p">(</span><span class="n">size</span> <span class="o">+</span> <span class="n">j</span> <span class="o">-</span> <span class="n">i</span><span class="p">)</span> <span class="o">%</span> <span class="n">size</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Another thing to consider is that we’re splitting our series across
multiple rows, thus the actual index of any point is the subscript
into the current segment plus the index of the segment itself (the <code>n</code>
column) multiplied by the <code>wdith</code> of the segment: <code>generate_subscripts(dp,1) + n * width</code>.</p>

<p>Which pieced together in SQL now looks like this:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="k">MOD</span><span class="p">(</span><span class="n">rra</span><span class="p">.</span><span class="k">size</span> <span class="o">+</span> <span class="k">MOD</span><span class="p">(</span><span class="k">EXTRACT</span><span class="p">(</span><span class="n">EPOCH</span> <span class="k">FROM</span> <span class="n">rra</span><span class="p">.</span><span class="n">latest</span><span class="p">)::</span><span class="nb">BIGINT</span><span class="o">/</span><span class="p">(</span><span class="n">rra</span><span class="p">.</span><span class="n">step_s</span> <span class="o">*</span> <span class="n">rra</span><span class="p">.</span><span class="n">steps_per_row</span><span class="p">),</span> <span class="k">size</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
</span><span class="line">  <span class="o">-</span> <span class="p">(</span><span class="n">generate_subscripts</span><span class="p">(</span><span class="n">dp</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">n</span> <span class="o">*</span> <span class="n">width</span><span class="p">),</span> <span class="n">rra</span><span class="p">.</span><span class="k">size</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Astute readers should notice an unexplained <code>+ 1</code>. This is because
PostgreSQL arrays are 1-based.</p>

<p>Now we need to convert the distance expressed in array slots into
a time interval, which we do by multiplying it by
<code>INTERVAL '1 SECOND' * rra.step_s * rra.steps_per_row</code>.</p>

<p>And finally, we need to subtract the above time interval from the
latest stamp which yields (ta-da!) the timestamp of the current slot:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="n">latest</span> <span class="o">-</span> <span class="nb">INTERVAL</span> <span class="s1">&#39;1 SECOND&#39;</span> <span class="o">*</span> <span class="n">rra</span><span class="p">.</span><span class="n">step_s</span> <span class="o">*</span> <span class="n">rra</span><span class="p">.</span><span class="n">steps_per_row</span> <span class="o">*</span>
</span><span class="line">  <span class="k">MOD</span><span class="p">(</span><span class="n">rra</span><span class="p">.</span><span class="k">size</span> <span class="o">+</span> <span class="k">MOD</span><span class="p">(</span><span class="k">EXTRACT</span><span class="p">(</span><span class="n">EPOCH</span> <span class="k">FROM</span> <span class="n">rra</span><span class="p">.</span><span class="n">latest</span><span class="p">)::</span><span class="nb">BIGINT</span><span class="o">/</span><span class="p">(</span><span class="n">rra</span><span class="p">.</span><span class="n">step_s</span> <span class="o">*</span> <span class="n">rra</span><span class="p">.</span><span class="n">steps_per_row</span><span class="p">),</span> <span class="k">size</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
</span><span class="line">  <span class="o">-</span> <span class="p">(</span><span class="n">generate_subscripts</span><span class="p">(</span><span class="n">dp</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">n</span> <span class="o">*</span> <span class="n">width</span><span class="p">),</span> <span class="n">rra</span><span class="p">.</span><span class="k">size</span><span class="p">)</span> <span class="k">AS</span> <span class="n">t</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>That’s it! And even though this may look complicated, from the
computational view point it is very efficient, and PostgreSQL can
handle it easily.</p>

<p>As an exercise, try setting <code>latest</code> to various timestamps and observe
how it affects the output of the view and see if you can explain how
and why it happens.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Parsing Table Names from SQL]]></title>
    <link href="http://grisha.org/blog/2016/11/14/table-names-from-sql/"/>
    <updated>2016-11-14T14:40:00-05:00</updated>
    <id>http://grisha.org/blog/2016/11/14/table-names-from-sql</id>
    <content type="html"><![CDATA[<p>Sometimes it is useful to extract table names from an SQL statement,
for example if you are trying to figure out dependencies for your Hive
or BigQuery (or whatever) tables.</p>

<p>It is actually a lot simpler than it seems and you don’t need to write
your own SQL parser or find one out there. In SQL table names always
follow the FROM and JOIN keywords. So all you have to do is split the
statemement into tokens, and scan the list for any mention of FROM or
JOIN and grab the next token.</p>

<p>Here is a very simplistic Python function that does this using regular
expressions:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">tables_in_query</span><span class="p">(</span><span class="n">sql_str</span><span class="p">):</span>
</span><span class="line">
</span><span class="line">    <span class="c"># remove the /* */ comments</span>
</span><span class="line">    <span class="n">q</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s">r&quot;/\*[^*]*\*+(?:[^*/][^*]*\*+)*/&quot;</span><span class="p">,</span> <span class="s">&quot;&quot;</span><span class="p">,</span> <span class="n">sql_str</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">    <span class="c"># remove whole line -- and # comments</span>
</span><span class="line">    <span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">q</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="s">&quot;^\s*(--|#)&quot;</span><span class="p">,</span> <span class="n">line</span><span class="p">)]</span>
</span><span class="line">
</span><span class="line">    <span class="c"># remove trailing -- and # comments</span>
</span><span class="line">    <span class="n">q</span> <span class="o">=</span> <span class="s">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&quot;--|#&quot;</span><span class="p">,</span> <span class="n">line</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">])</span>
</span><span class="line">
</span><span class="line">    <span class="c"># split on blanks, parens and semicolons</span>
</span><span class="line">    <span class="n">tokens</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">r&quot;[\s)(;]+&quot;</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">    <span class="c"># scan the tokens. if we see a FROM or JOIN, we set the get_next</span>
</span><span class="line">    <span class="c"># flag, and grab the next one (unless it&#39;s SELECT).</span>
</span><span class="line">
</span><span class="line">    <span class="n">result</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
</span><span class="line">    <span class="n">get_next</span> <span class="o">=</span> <span class="bp">False</span>
</span><span class="line">    <span class="k">for</span> <span class="n">tok</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
</span><span class="line">        <span class="k">if</span> <span class="n">get_next</span><span class="p">:</span>
</span><span class="line">            <span class="k">if</span> <span class="n">tok</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s">&quot;&quot;</span><span class="p">,</span> <span class="s">&quot;select&quot;</span><span class="p">]:</span>
</span><span class="line">                <span class="n">result</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tok</span><span class="p">)</span>
</span><span class="line">            <span class="n">get_next</span> <span class="o">=</span> <span class="bp">False</span>
</span><span class="line">        <span class="n">get_next</span> <span class="o">=</span> <span class="n">tok</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="s">&quot;from&quot;</span><span class="p">,</span> <span class="s">&quot;join&quot;</span><span class="p">]</span>
</span><span class="line">
</span><span class="line">    <span class="k">return</span> <span class="n">result</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>This is obviously not perfect, for example in BigQuery there is a
possibility that what follows <code>SELECT</code> is a UDF name, but I’ll leave
working around that as an exercise for the reader.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Load testing Tgres]]></title>
    <link href="http://grisha.org/blog/2016/11/08/load-testing-tgres/"/>
    <updated>2016-11-08T14:41:00-05:00</updated>
    <id>http://grisha.org/blog/2016/11/08/load-testing-tgres</id>
    <content type="html"><![CDATA[<p>Edit: There is an <a href="http://grisha.org/blog/2017/02/23/can-tgres-outperform-graphite/">update</a> to this story.</p>

<p>So I finally got around to some load testing of <a href="https://github.com/tgres/tgres">Tgres</a>. Load testing is
mysterious, it never goes the way you think it would, and what you
learn is completely unexpcted.</p>

<p>Given that I presently don’t have any spare big iron at my disposal
and my “servers” are my macbook and an old thinkpad, all I really was
after is making sure that Tgres is “good enough” whatever that
means. And I think it is.</p>

<p>I was hoping to gather some concrete numbers and may be even make a
chart or two, but in the end it all turned out to be so tedious and
time consuming, running the tests with various setting for hours on,
that I just gave up for now - after all, “premature optimization is
the root of all evil”.</p>

<p>I also wanted to see how it stacks up against Graphite
carbon-cache.py. As in, is it on par, or much better or much worse. My
expectation was that Graphite could outperform it, because what it
does is so much simpler (and I was right). First thing I tried to do
is overwhelm Graphite. I never succeeded in that - I probably could
have tried harder, but I quickly learned that I don’t know what
symptoms I’m looking for. I wronte a Go program that blasted UDP data
points at 10K/sec across 10K different series, and taking it to over
20K/sec saturated my network before Graphite showed any signs of
deterioration. There was also no reliable way for me to audit the data
points - may be some of them got lost, but at 600K+ per minute, I
don’t know of any practical way of doing it. Not without a lot of
work, at least.</p>

<p>With Tgres things were much easier. The weakest link is, not
surpisingly, PostgreSQL. What I learned was that there are two kinds of
deterioration when it comes to PostgreSQL though. The first one is
outright, and that one manifests in database requests getting
progressively slower until Tgres gets stuck with all its channels
full.</p>

<p>You can make PostgreSQL very significantly faster with a few simple
tricks. For example the following settings can make it much faster:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">synchronous_commit = off
</span><span class="line">commit_delay = 100000</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>This post isn’t about PostgreSQL, and so I’m not going to get into the
details of what this does, there is plenty of documentation and blog
posts on the subject. If you plan on hosting a busy Tgres set up, you
should probably have the above settings.</p>

<p>The second way PostgreSQL deteriorates is not immediately apparent - it
is the infamous table bloat. Getting autovacuum to keep up with the ts
table (which stores all the time series) is tricky, and once you’ve
ran out of options to tweak, this is probably it - the maximum load
the database can handle, even if it may seem relatively calm.</p>

<p>Autovacuum has a lot of knobs, but ultimately they all exist to take
advantage of the variability of load in a database, i.e. you can let
it get behind during the day and catch up at night when the database
is not as busy. It doesn’t really work with time series, which are not
variable by nature - if you’re receiving 5 thousand data points per
second at noon, you can expect the same rate at 4am. I think the
setting that worked best for me were:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class=""><span class="line">autovacuum_max_workers = 10
</span><span class="line">autovacuum_naptime = 1s
</span><span class="line">autovacuum_vacuum_threshold = 2000
</span><span class="line">autovacuum_vacuum_scale_factor = 0.0
</span><span class="line">autovacuum_vacuum_cost_delay = 0 # disable cost based
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>To the best of my undestanding the above setting disables cost-based
autovacuum (meaning it doesn’t pause periodically to yield resources
to the normal db tasks), makes autovacuum kick in after 2K updates
(which happens in no time), and sleeps 1s in between runs, which means
it’s running pretty much continuosly.</p>

<p>I was able to sustain a load of ~6K datapoints per second across 6K
series - anything higher caused my “database server” (which is a 2010
i7 Thinkpad) autovacuum to get behind.</p>

<p>I also did some testing of how TOAST affects performance. There is no
setting for turning TOAST on or off, but it can easily be done in
Tgres by changing the number of data points per row. The default is
768 which is about 75% of a page. If you for example double it, then
each row becomes larger than a page and TOAST kicks in. TOAST is
compressed, which is an advantage, but it is a separate table, which
is a disadvantage. In the end it seemed like the database detirorated
quicker with TOAST, but it was rather inconclusive.</p>

<p>In the end the key factor, or the weakest link, was the rate of
queries per second. I now added a special rate limiting setting
feature to Tgres (max-flushes-per-second) which trumps all other
settings and will keep your database happy at the expense of Tgres
possibly caching a little more points in memory than expected.</p>

<p>I will probably get back to some more load testing in a while, but for
now this is it.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Golang receiver vs function argument]]></title>
    <link href="http://grisha.org/blog/2016/09/22/golang-receiver-vs-function/"/>
    <updated>2016-09-22T08:15:00-04:00</updated>
    <id>http://grisha.org/blog/2016/09/22/golang-receiver-vs-function</id>
    <content type="html"><![CDATA[<p>What is the difference between a Go <em>receiver</em> (as in “method receiver”)
and a function <em>argument</em>? Consider these two bits of code:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="go"><span class="line"><span class="kd">func</span> <span class="p">(</span><span class="nx">d</span> <span class="o">*</span><span class="nx">duck</span><span class="p">)</span> <span class="nx">quack</span><span class="p">()</span> <span class="p">{</span> <span class="c1">// receiver</span>
</span><span class="line">     <span class="c1">// do something</span>
</span><span class="line"><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>versus</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="go"><span class="line"><span class="kd">func</span> <span class="nx">quack</span><span class="p">(</span><span class="nx">d</span> <span class="o">*</span><span class="nx">duck</span><span class="p">)</span> <span class="p">{</span> <span class="c1">// funciton argument</span>
</span><span class="line">    <span class="c1">// do something</span>
</span><span class="line"><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The “do something” part above would work exactly the same regardless of
how you declare the function. Which begs the question, which should
you use?</p>

<p>In the object-oriented world we were used to objects doing things, and
in that context <code>d.quack()</code> may seem more intuitive or familiar than
<code>quack(d)</code> because it “reads better”. After all, one could argue that
the former is a duck quacking, but the latter reads like you’re
quacking a duck, and what does that even mean? I have learned that you
should not think this way in the Go universe, and here is why.</p>

<p>First, what is the essential difference? It is that at the time of the
call, the receiver is an <em>interface</em> and the function to be called is
determined <em>dynamically</em>. If you are not using interfaces, then this
doesn’t matter whatsoever and the only benefit you are getting from
using a method is syntactic sweetness.</p>

<p>But what if you need to write a test where you want to stub out
<code>quack()</code>. If your code looks like this, then it is not possible,
because methods are attached to their types inflexibly, you cannot
change them, and there is no such thing as a “method variable”:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="go"><span class="line"><span class="kd">type</span> <span class="nx">duck</span> <span class="kd">struct</span><span class="p">{}</span>
</span><span class="line">
</span><span class="line"><span class="kd">func</span> <span class="p">(</span><span class="nx">d</span> <span class="o">*</span><span class="nx">duck</span><span class="p">)</span> <span class="nx">quack</span><span class="p">()</span> <span class="p">{</span>
</span><span class="line">     <span class="c1">// do something</span>
</span><span class="line"><span class="p">}</span>
</span><span class="line">
</span><span class="line"><span class="c1">// the function we are testing:</span>
</span><span class="line"><span class="kd">func</span> <span class="nx">testme</span><span class="p">(</span><span class="nx">d</span> <span class="o">*</span><span class="nx">duck</span><span class="p">)</span> <span class="p">{</span>
</span><span class="line">    <span class="nx">d</span><span class="p">.</span><span class="nx">quack</span><span class="p">()</span> <span class="c1">// cannot be stubbed</span>
</span><span class="line"><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>However, if you used a function argument, it would be easy:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="go"><span class="line"><span class="kd">type</span> <span class="nx">duck</span> <span class="kd">struct</span><span class="p">{}</span>
</span><span class="line">
</span><span class="line"><span class="kd">var</span> <span class="nx">quack</span> <span class="p">=</span> <span class="kd">func</span><span class="p">(</span><span class="nx">d</span> <span class="o">*</span><span class="nx">duck</span><span class="p">)</span> <span class="p">{</span>
</span><span class="line">     <span class="c1">// do something</span>
</span><span class="line"><span class="p">}</span>
</span><span class="line">
</span><span class="line"><span class="c1">// the function we are testing:</span>
</span><span class="line"><span class="kd">func</span> <span class="nx">foo</span><span class="p">(</span><span class="nx">d</span> <span class="o">*</span><span class="nx">duck</span><span class="p">)</span> <span class="p">{</span>
</span><span class="line">    <span class="nx">quack</span><span class="p">(</span><span class="nx">d</span><span class="p">)</span>
</span><span class="line"><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Now you can assign another function to quack at test time, e.g. <code>quack = func(d *duck) { // do something else }</code>  and all is
well.</p>

<p>Alternatively, you can use an interface:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
</pre></td><td class="code"><pre><code class="go"><span class="line"><span class="kd">type</span> <span class="nx">quacker</span> <span class="kd">interface</span> <span class="p">{</span>
</span><span class="line">    <span class="nx">quack</span><span class="p">()</span>
</span><span class="line"><span class="p">}</span>
</span><span class="line">
</span><span class="line"><span class="kd">type</span> <span class="nx">duck</span> <span class="kd">struct</span><span class="p">{}</span>
</span><span class="line">
</span><span class="line"><span class="kd">var</span> <span class="kd">func</span> <span class="p">(</span><span class="nx">d</span> <span class="o">*</span><span class="nx">duck</span><span class="p">)</span> <span class="nx">quack</span><span class="p">()</span> <span class="p">{</span> <span class="c1">// satisfies quacker</span>
</span><span class="line">     <span class="c1">// do something</span>
</span><span class="line"><span class="p">}</span>
</span><span class="line">
</span><span class="line"><span class="c1">// the function we are testing:</span>
</span><span class="line"><span class="kd">func</span> <span class="nx">foo</span><span class="p">(</span><span class="nx">d</span> <span class="nx">quacker</span><span class="p">)</span> <span class="p">{</span>
</span><span class="line">    <span class="nx">d</span><span class="p">.</span><span class="nx">quack</span><span class="p">()</span>
</span><span class="line"><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Here, if we need to test <code>foo()</code> we can provide a different
<code>quacker</code>.</p>

<p>Bottom line is that it only makes sense to use a receiver if this
function is part of an interface implementation, OR if you never ever
need to augment (stub) that function for testing or some other
reason. As a practical matter, it seems like (contrary to how it’s
done in the OO world) it is better to always start out with <code>quack(d)</code>
rather than <code>d.quack()</code>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How Data Points Build Up]]></title>
    <link href="http://grisha.org/blog/2016/08/04/data-points/"/>
    <updated>2016-08-04T10:35:00-04:00</updated>
    <id>http://grisha.org/blog/2016/08/04/data-points</id>
    <content type="html"><![CDATA[<p>This silly SVG animation (animation not my strong suit) demonstrates
what happens when multiple Tgres data points arrive within the same
step (i.e. smallest time interval for this series, also known as PDP,
primary data point).</p>

<object data="/images/data_point.svg" type="image/svg+xml">
  You browser does not support SVG objects?
</object>

<h3 id="explanation">Explanation</h3>

<p>Let’s say we have a series with a step of 100 seconds. We receive the
following data points, all within the 100 second interval of a
single step:</p>

<table>
  <thead>
    <tr>
      <th>Time</th>
      <th>Value</th>
      <th>Recorded</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>25s</td>
      <td>2.0</td>
      <td>0.5</td>
    </tr>
    <tr>
      <td>75s</td>
      <td>3.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <td>100s</td>
      <td>1.0</td>
      <td>2.25</td>
    </tr>
  </tbody>
  <tbody>
    <tr>
      <td> </td>
      <td>Final:</td>
      <td>2.25</td>
    </tr>
  </tbody>
</table>

<p />
<p>Tgres will store 2.25 as the final value for this step. So how
does 1, 2 and 3 add up to <em>2.25</em>?</p>

<p>One way to think about it is that the incomplete step is an empty
swimming pool as wide as 1 step, into which we dump blocks of
water. The first data point dumps a 2.0 × 0.25 block of water, which
fills the pool to 0.5. The second data point dumps a 3.0 × 0.50 block,
which raises the water another 1.5 to 2.0. The last data point dumps a
1.0 × 0.25 block which raises it to the final value of 2.25.  Compare
this with Graphite which would simply discard the first two data
points and we are left with 1.0 as the final value.</p>

<p>Why is it done this way? Because this is how rates add up. If this was
speed of a car in meters per second (more like a bycicle, I guess),
its weighted average speed for the duration of this step of 2.25
meters per second would mean that in the 100s it would have traveled
exactly 225 meters.</p>

<h3 id="nans-or-unknowns">NaNs or “Unknowns”</h3>

<p>What if instead of the first data point, the first 25s were “unknown”
(recorded as NaN)? This would happen, for example, if the series
heartbeat (maximum duration without any data) was exceeded. Even
though the data point has a value of 2.0, it gets recorded as NaN.</p>

<table>
  <thead>
    <tr>
      <th>Time</th>
      <th>Value</th>
      <th>Recorded</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>25s</td>
      <td>2.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>75s</td>
      <td>3.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <td>100s</td>
      <td>1.0</td>
      <td>2.33</td>
    </tr>
  </tbody>
  <tbody>
    <tr>
      <td> </td>
      <td>Final:</td>
      <td>2.33</td>
    </tr>
  </tbody>
</table>

<p />

<p>But wait a second… 0.50 × 3 + 0.25 × 1 = 1.75 ? Where did
the value of 2.33 come from?</p>

<p>The reason for this is that NaN ought not be influencing the
value. The above calculation would only be correct if we assumed that NaN is
synonymous with zero, but that would be a false assumption, as NaN
means “we do not know”.</p>

<p>Therefore, we must only consider the known part of the data point,
which is 75s. We can think of it that the data point (the “swimming
pool”) just got smaller.  Thus the correct calculation for the 3.0
point would be 3.0 × 50 ÷ 75 = 2.0 and for the 1.0 point
2.0 + 1.0 × 25 ÷ 75 = 2.33.</p>

<p>Here it is in SVG:</p>

<object data="/images/data_point_unk.svg" type="image/svg+xml">
  You browser does not support SVG objects?
</object>

<p>Also note how the value of the data point which was recorded as NaN
(2.0 in our example) is essentially irrelevant. This is because any
calculation with a NaN always results in a NaN. The only thing we know
about this data point is that it was not NaN and that it marked the
end of period recorded as NaN. The next data point after this (3.0 in
our example) is not affected by the NaN, however, this is because it
in effect starts its own data point afresh, not considering anything
in the past.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introducing Tgres - A Time Series DB on top of PostgreSQL]]></title>
    <link href="http://grisha.org/blog/2016/07/29/state-of-tgres-2016/"/>
    <updated>2016-07-29T10:12:00-04:00</updated>
    <id>http://grisha.org/blog/2016/07/29/state-of-tgres-2016</id>
    <content type="html"><![CDATA[<p><a href="http://github.com/tgres/tgres">Tgres</a> is a metrics collection and storage server, aka a time series
database. I’m not very comfortable with referring to it as a
<em>database</em>, because at least in case of Tgres, the database is
actually PostgreSQL. But also “database” to me is in the same category
as “operating system” or “compiler”, a thing so advanced that only few
can claim to be it without appearing pretentious. But for the sake of
tautology avoidance, I might occasionally refer to Tgres as a TS
database.</p>

<p>Ulike <a href="https://graphiteapp.org/">Graphite</a> or
<a href="http://oss.oetiker.ch/rrdtool/">RRDTool</a>, Tgres produces no charts,
it assumes you’re using something like
<a href="http://grafana.org/">Grafana</a>. Currently Tgres supports most of the
Graphite functionality (including vast majority of the functions) as
well as Statsd functionality. Tgres supports clustering, albeit
whereby all nodes must share the PostgreSQL instance. Tgres can be
used as a standalone server or as a Go package compiled into your app.</p>

<h3 id="current-status">Current status</h3>

<p>It’s been over a year since I began hacking on it in this incarnation,
though the idea and a couple of scrapped implementations thereof go
back more than two years. Tgres is still not quite production quality,
though it’s probably stable enough for someone who knows their way
around Go to give it a whirl. At this point I have proven the concept,
and believe the architecture is sound, but the magnitude of the
project turned out to be much grater than I originally pictured, and
so it still needs lots and lots of proofreading, t’s crossed and i’s
dotted.</p>

<h2 id="raisons-detre">Raisons d’etre</h2>

<h3 id="with-go-new-things-are-possible">With Go, new things are possible</h3>

<p>The idea of a TS database came about when I first decided to dive into
<a href="https://golang.org/">Golang</a>. Go can do great stuff, but I didn’t see
how it applied to anything I was working on at
the time. I needed a project that was a better match for the domain of
applications that Go made possible, something where performance and scale
matter, something with concurrent moving pieces, something
challenging. A “time series database” seemed like it had potential. It
has all kinds of curious requirements that could be great fun to
implement in Go.</p>

<h3 id="present-state-of-time-series-databases-is-dismal">Present state of “time series databases” is dismal</h3>

<p>I was (and still am) frustrated with the state of TS in our
industry. Since the appearance of
<a href="http://oss.oetiker.ch/mrtg/doc/mrtg.en.html">MRTG</a> back in 1995 when
the network admins of the then burgeoning Internet realized that TS is
essential to device monitoring, not much has happened.</p>

<p><a href="http://oss.oetiker.ch/rrdtool/">RRDTool</a> was definitely a major step
forward from MRTG which was merely a Perl script. RRDTool to this day
is the best implementation of a round-robin database for time series
data (in C to boot). Similarly to MRTG, RRDTool was designed as a command-line tool,
the server component was left as an exercise for the user. And even
though linking RRDTool into your app was not too difficult (I
<a href="https://github.com/grisha/openvps-common/blob/master/py-rrd/_RRD.c">did it</a>
in 2004), somehow an “RRD server” never appeared.</p>

<p>Then there was <a href="https://graphiteapp.org/">Graphite</a>. (I think Graphite
is a reflection of the Python-can-do-anything era.) Graphite borrowed
a lot of ideas from RRDTool, though its re-implementation of
round-robin on-disk files in pure Python while <a href="http://graphite.wikidot.com/whisper">claiming superiority</a> is not that much
better, if at all, IMHO when compared to RRDTool in both accuracy and
performance. In general though, I think storing data directly in files
is the wrong approach to begin with.</p>

<p>Graphite’s appeal is that it’s an easy-to-start server that does
everything, and it became especially popular alongside
<a href="https://github.com/etsy/statsd/wiki">Statsd</a> a tool with umpteen
different implementation designed to sit in front of
Graphite. Eventually people stopped using Graphite to make charts
favoring instead the most excellent Grafana,
while Graphite (or its nephew <a href="https://github.com/brutasse/graphite-api">Graphite-API</a>)
became a UI-less server-only component to store and retrieve data.</p>

<p>Graphite and RRDTool didn’t scale very well, so for “Big Time Series”
(as in very large networks, or specialized fields like finance,
weather, etc.) people used solutions backed by
<a href="http://cassandra.apache.org/">Cassandra</a>, <a href="https://hbase.apache.org/">HBase</a>,
or <a href="http://lucene.apache.org/solr/">Solr</a> such as
<a href="http://opentsdb.net/">OpenTSDB</a>.</p>

<p>There are also new kids on the block such as
<a href="https://influxdata.com/">InfluxDB</a> or
<a href="https://prometheus.io/">Prometheus</a>, which are a little too flashy
and commercial by my taste, each trying to solve problems that I don’t
think I have.</p>

<p>Bottom line is that some 20 years after MRTG, time series remains
mostly a system monitoring aid and has never crossed over to the
mainstream application development.</p>

<h3 id="data-isolation">Data isolation</h3>

<p>Virtually all of the aforementioned tools contribute to a problem I
dub <em>data isolation</em>. Data isolation is when a part of our data is
stored using a separate tool in a different format and is therefore
not as easily accessible.  For example if our metrics are in Graphite,
we probably don’t even know how to get them out of it, nor does it
occur to us that it might be useful.  All we’ve been able to do is get
a Grafana chart and are quite satisfied with it. We do not question
why it isn’t a first-class citizen right in the database as a table,
where we could use it in SQL joins, for example. Or export it to our
big data rig and query it with Hive or Spark, etc.</p>

<p>Why is getting a quick chart of customer sign-ups per second next to
all my customer data such a big deal these days? Why can’t it be as
simple as a model in my Rails or Django app?</p>

<h3 id="postgresql---avoid-the-storage-mire">PostgreSQL - Avoid the storage mire</h3>

<p>I believe that there is nothing about time series that makes it unfit
for a relational database. Many projects out there are spinning
their wheels solving the wrong problem, that of data storage. Storage
is one of the hardest problems in computers, time series databases
should focus on time series and delegate the storage to tried-and-true
tools which are good at it.</p>

<p>Time series data does carry certain special requirements, and I’ve
researched extensively all different ways TS can be stored in a
relational database. It does require taking advantage of some newer
features that in the open source database world seem most available in
PostgreSQL. I am guessing that with time these capabilities will
become more available in other databases, and some of them already
are, but for the time being I’ve decided that Tgres is
PostgreSQL-only.</p>

<h2 id="a-bit-of-detail">A bit of detail</h2>

<h3 id="emulating-graphite-as-a-starting-point">Emulating Graphite as a starting point</h3>

<p>I would like Tgres to be useful. The simplest way I could think of
achieving usefulness is by emulating an existing tool so that it can
become a drop-in replacement. This makes adoption easy and it also
proves that the underlying architecture is capable. It also lets us
compare performance.</p>

<p>It doesn’t mean that I am a fan of how Graphite does things, but I
think that if Tgres is architected in such a way that there is a lower
level which does the heavy lifting and then a layer on top of it that
makes it behave like Graphite, that’s a great start, and it leaves
options open for potential improvement and a different/better
interface.</p>

<h3 id="general-terminology">General terminology</h3>

<p>I always liked how RRDTool documentation broke down the problem of
time series into concise and clear terms. Tgres tries to leverage the
RRDTool terminology. Tgres also adopts the same techniques to the
extent that is possible given a considerably different
architecuture. Unlike RRDTool, Tgres uses a millisecond as the
smallest unit of time measure.</p>

<h4 id="data-point-dp">Data Point (DP)</h4>

<p>A <em>data point</em> is a <em>value</em> (a floating point number) a <em>time stamp</em>
and a string <em>name</em> identifying the series. (For a while I
contemplated allowing a data point to have multiple values, but it
made things too complicated, so I reverted to a single value per data
point).</p>

<h4 id="round-robin-archive-rra">Round-Robin Archive (RRA)</h4>

<p>Tgres stores data points in <em>round-robin archives</em>.  While
“round-robin” is an implementation detail, it is part of the name
because the only way it can be round-robin is the number of data
points in the archive is constant. The time-span of the RRA is determined
by the <em>step</em> (resolution) and the <em>size</em> of the archive (in steps). Thus RRA’s are
defined by step and size, e.g. 10s for 24 hours (a data point every
10s for 24 hours, or 8,640 points).</p>

<p>A series is usually is stored in multiple RRA’s. The RRA’s typically
have varying resolutions, e.g. we want a 10s step for the past 24h,
but also a 1h step for a week and a 6h step for 3 years. In this
example we have 3 RRA’s. Tgres takes care of maintaining the RRA’s and
selecting the right resultion for a given query so that there is no
need to deal with individual RRA’s directly.</p>

<h4 id="data-source-ds">Data Source (DS)</h4>

<p>A group of RRA’s under the same identifier (aka series name) is
referred to as a data source (DS). I suppose “DS” can be used
interchangeably with “series”. Depending on how Tgres is configured,
DS’s are either predefined or are created on the fly based on DS name
matching rules.</p>

<p>Note that Tgres does not store the original data points, but only the
weighted averages of the received data points in each RRA. This is how
RRDTool does it. Graphite doesn’t bother averaging the points but
simply discards previous data points within the same step. At first it
may seem not ideal that the original data is discarded, but experience
shows that just about any time series operation results in a
conversion to a fixed interval form as the first step, so it might as
well just be done upfront.</p>

<h4 id="heartbeat-hb">Heartbeat (HB)</h4>

<p>Every DS has a <em>heartbeat</em>, a time duration which defines the longest
possible period of inactivity before the DS becomes considered
dysfunctional. If the heartbeat is exceeded, the data since the last
update will be recorded as NaNs.</p>

<h4 id="xfiles-factor-xff">Xfiles factor (XFF)</h4>

<p>When data is consolidated from smaller to larger step RRAs, the XFF
determines how much of the data is allowed to be NaN before the
consolidated value becomes NaN. For example if we are consolidating
per-minute values into a per-hour value, if one of the minutes happens
to be NaN, strictly speaking the whole hour ought ot be NaN, but that
wouldn’t be very useful. Default XFF is .5, i.e. more than half of the
per-minute values should be NaN before the per-hour value is
considered NaN.</p>

<h3 id="postgres-storage-format">Postgres storage format</h3>

<p>A time series is a series of floats. Note that when it’s stored in
RRA’s, there is no need for timestamps - each position in an RRA has
its timestamp defined by the current state of the RRA. If we know the
timestamp of the tip, we know the timestamp of every element going
back to the beginning of the RRA.</p>

<p>To store data points Tgres takes advantage of PostgreSQL arrays. A
single row stores many data points. Tgres further splits series into
multiple rows to optimize the IO.</p>

<p>To make the data easy to use, Tgres also creates a view which makes
the data points structured as a regular table with a row per data
point.</p>

<p>There are only 3 tables and 1 view required for Tgres operation. You
can use the same database you use for any other web app you have. This
means you can access the time series by simply just adding a model
pointing at the Tgres time series view to your Rails/Django/whatever
to get access to the data.</p>

<h2 id="tgres-components">Tgres components</h2>

<p>Tgres is organized as a set of Go packages.</p>

<h3 id="tgresdaemon">tgres/daemon</h3>

<p>The <a href="https://github.com/tgres/tgres/tree/master/daemon">daemon</a> is the
main process that runs everything. It includes the config parser, and
the listeners that receive and parse incoming data points using both
UDP and TCP Graphite formats, as well as Python Pickle format (though
I’m not sure who out there really uses it). It’s not too hard to add
more formats, for example I think it’d be neat if Tgres could receive
data points via an HTTP pixel that could be embedded in web pages.</p>

<p>The daemon also takes care of graceful restarts, logging and other
typical long-running service stuff.</p>

<h3 id="trgesreceiver">trges/receiver</h3>

<p>The <a href="https://github.com/tgres/tgres/tree/master/receiver">receiver</a>
(formerly known as transceiver) is the data point router and cache. It
maintains a set of workers responsible for writing the data points to
their respective RRA’s, as well as caching and periodic flushing of
the cache. Flushing is done once a certian number of points has
accumulated or a period of time has passed, but not more often than
the minimal flush frequency (all configurable).</p>

<h3 id="tgresrrd">tgres/rrd</h3>

<p>The responsibility of <a href="https://github.com/tgres/tgres/tree/master/rrd">rrd</a> is to add data
points to RRA’s. This is not as simple as it sounds, a good
description of the concepts behind it is available <a href="http://rrdtool.vandenbogaerdt.nl/process.php#Rate">here</a>.</p>

<h3 id="tgreshttp">tgres/http</h3>

<p><a href="https://github.com/tgres/tgres/tree/master/http">http</a> is the place
for all things related to HTTP, which currently is just the Graphite
API. The API requests are passed down to the DSL level for processing.</p>

<h3 id="tgresdsl">tgres/dsl</h3>

<p><a href="https://github.com/tgres/tgres/tree/master/dsl">dsl</a> is an
implementation of the Graphite
<a href="http://graphite.readthedocs.io/en/latest/functions.html">functions</a>. There
are a few differences because I used the Go parser which is nearly
syntactically identical. (For example a series name cannot begin with
a digit because that is not a proper Go identifier).</p>

<p>Graphite has a lot number of functions available in its DSL, and I
spent a lot of time during our beach vacation last summer trying to
implement them all, but I think a few are still left undone. Some were
harder than others, and some led me on side adventures such as
figuring out the Holt-Winters triple exponential smoothing and how to
do it correctly. (ZZZ - link)</p>

<h3 id="tgresserde">tgres/serde</h3>

<p>The interface to the database is reduced to a fairly compact
<a href="https://github.com/tgres/tgres/tree/master/serde">SerDe</a>
(Serialize-Deserializer) interface. While the SerDe itself is utterly
simplistic (e.g. “get me this series”), the SQL behind it anything
but, still, it should be possible to throw together an alternative
SerDe for a different relational database (or not a database at all?).</p>

<h3 id="tgresstatsd">tgres/statsd</h3>

<p><a href="https://github.com/tgres/tgres/tree/master/statsd">Statsd</a> is currently
in a separate Go package, but I might integrate with the RRD because
it is not very clear that it needs to be a separate thing. Somehow it
so happened that Graphite and Statd are two separate projects, but the
reasons for this are probably more cultural than by design.</p>

<h3 id="tgrescluster">tgres/cluster</h3>

<p><a href="https://github.com/tgres/tgres/tree/master/cluster">Cluster</a> supports
very basic clustering. At this point it’s “good enough” given that
it’s OK to occasionally lose data points during cluster transitions
and all that we want to make sure of is that nodes can come and go
without disruptions.</p>

<p>The principle behind cluster is that each node is responsible for one
or more series and other nodes will forward data points to the
responsible node. There is nearly zero configuration, and any node can
act as the point of contact, i.e. there is no leader.</p>

<p>The way clustering is done is in flux at the moment, we might change
it to something more robust in the near future, but for the time being
it addresses the horizontal scaling problem.</p>

<h2 id="theres-still-lots-to-do">There’s still lots to do…</h2>

<p>There’s still a lot of work to be done on Tgres. For one thing, I
don’t have any tests. This is mainly because I don’t believe in
testing that which hasn’t “gelled”, and I wouldn’t be surprised if the
above organization of packages and how they interface changes as I
understand the problem better. We also need documentation. And some
real-life use/testing/feedback would be great as well.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deploying a Golang app to AWS ECS with Terraform]]></title>
    <link href="http://grisha.org/blog/2016/04/19/deploying-a-golang-app-to-aws-ecs-with-terraform/"/>
    <updated>2016-04-19T10:53:00-04:00</updated>
    <id>http://grisha.org/blog/2016/04/19/deploying-a-golang-app-to-aws-ecs-with-terraform</id>
    <content type="html"><![CDATA[<p>I’ve put together a basic example of a “Hello World” Go program which
runs in Amazon AWS Elastic Compute Service (ECS), which allows running
applications in Docker containers and has the ability to scale on
demand.</p>

<p>I initially wanted to write about the components of this system and
the tools you use to deploy your application, but soon realized that
this would make for an extremely long post, as the number of
components required for a simple “Hello World” is mind
boggling. However problematic it may seem, it’s par for the course,
this is what takes to run an application in our cloudy times.</p>

<p>I used <a href="https://github.com/hashicorp/terraform">Terraform</a> to build
all the AWS infrastructure. Initially I was skeptical on how well it
could accomplish such a tedious task, but I have say my confidence in
Terraform grew the more I used it.</p>

<p>The main top level tool for everything is the good old
<a href="https://en.wikipedia.org/wiki/Make_%28software%29">make</a>, a tool that
stood the test of time.</p>

<p>Here is the code of the example, read the README, I hope you find it
useful:</p>

<p><a href="https://github.com/grisha/hello-go-ecs-terraform">https://github.com/grisha/hello-go-ecs-terraform</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Holt-Winters Forecasting for Dummies - Part III]]></title>
    <link href="http://grisha.org/blog/2016/02/17/triple-exponential-smoothing-forecasting-part-iii/"/>
    <updated>2016-02-17T10:39:00-05:00</updated>
    <id>http://grisha.org/blog/2016/02/17/triple-exponential-smoothing-forecasting-part-iii</id>
    <content type="html"><![CDATA[<p>If you haven’t read <a href="http://grisha.org/blog/2016/01/29/triple-exponential-smoothing-forecasting/">Part I</a> and
<a href="http://grisha.org/blog/2016/02/16/triple-exponential-smoothing-forecasting-part-ii/">Part II</a>
you probably should, or the following will be hard to make sense of.</p>

<p>In Part I we’ve learned how to forceast one point, in Part II we’ve
learned how to forecast two points. In this part we’ll learn how to
forecast <em>many</em> points.</p>

<h2 id="more-terminology">More Terminology</h2>

<h3 id="season"><em>Season</em></h3>

<p>If a series appears to be repetitive at regular intervals, such an
interval is referred to as a <em>season</em>, and the series is said to be
<em>seasonal</em>. <a href="https://en.wikipedia.org/wiki/Seasonality">Seasonality</a>
is required for the Holt-Winters method to work, non-seasonal series
(e.g. stock prices) cannot be forecasted using this method (would be
nice though if they could be).</p>

<h3 id="season-length"><em>Season Length</em></h3>

<p><em>Season length</em> is the number of data points after which a new season
begins. We will use $L$ to denote season length.</p>

<h3 id="seasonal-component"><em>Seasonal Component</em></h3>

<p>The <em>seasonal component</em> is an additional deviation from level + trend
that repeats itself at the same offset into the season. There is a
seasonal component for every point in a season, i.e. if your season
length is 12, there are 12 seasonal components. We will use $s$ to
denote the seasonal component.</p>

<h2 id="triple-exponential-smoothing-aka-holt-winters-method">Triple Exponential Smoothing a.k.a Holt-Winters Method</h2>

<p>The idea behind triple exponential smoothing is to apply exponential
smoothing to the seasonal components in addition to level and
trend. The smoothing is applied across seasons, e.g. the seasonal
component of the 3rd point into the season would be exponentially
smoothed with the the one from the 3rd point of last season, 3rd point
two seasons ago, etc. In math notation we now have four equations (see footnote):</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align}
& \ell_x = \alpha(y_x - s_{x-L}) + (1-\alpha)(\ell_{x-1} + b_{x-1})& \mbox{level} \\
& b_x = \beta(\ell_x - \ell_{x-1}) + (1-\beta)b_{x-1} & \mbox{trend} \\
& s_x = \gamma(y_x - \ell_x) + (1-\gamma)s_{x-L} & \mbox{seasonal} \\
& \hat{y}_{x+m} = \ell_x + mb_x + s_{x-L+1+(m-1)modL}& \mbox{forecast}\\
\end{align}
 %]]&gt;</script>

<ul>
  <li>What’s new:
    <ul>
      <li>We now have a third greek letter, $\gamma$ (gamma) which is the smoothing
factor for the seasonal component.</li>
      <li>The expected value index is $x+m$ where $m$ can be any integer meaning
we can forecast any number of points into the future (woo-hoo!)</li>
      <li>The forecast equation now consists of level, trend and the seasonal
component.</li>
    </ul>
  </li>
</ul>

<p>The index of the seasonal component of the forecast
$s_{x-L+1+(m-1)modL}$ may appear a little mind boggling, but it’s
just the offset into the list of seasonal components from the last set
from observed data. (I.e. if we are forecasting the 3rd point into the
season 45 seasons into the future, we cannot use seasonal components
from the 44th season in the future since that season is also
forecasted, we must use the last set of seasonal components from
observed points, or from “the past” if you will.) It looks much
simpler in Python as you’ll see shortly.</p>

<h3 id="initial-values">Initial Values</h3>

<p>Before we can discuss initial values, let me introduce to you a new
tiny series (okay, not as tiny):</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">series</span> <span class="o">=</span> <span class="p">[</span><span class="mi">30</span><span class="p">,</span><span class="mi">21</span><span class="p">,</span><span class="mi">29</span><span class="p">,</span><span class="mi">31</span><span class="p">,</span><span class="mi">40</span><span class="p">,</span><span class="mi">48</span><span class="p">,</span><span class="mi">53</span><span class="p">,</span><span class="mi">47</span><span class="p">,</span><span class="mi">37</span><span class="p">,</span><span class="mi">39</span><span class="p">,</span><span class="mi">31</span><span class="p">,</span><span class="mi">29</span><span class="p">,</span><span class="mi">17</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="mi">27</span><span class="p">,</span><span class="mi">35</span><span class="p">,</span><span class="mi">41</span><span class="p">,</span><span class="mi">38</span><span class="p">,</span>
</span><span class="line">          <span class="mi">27</span><span class="p">,</span><span class="mi">31</span><span class="p">,</span><span class="mi">27</span><span class="p">,</span><span class="mi">26</span><span class="p">,</span><span class="mi">21</span><span class="p">,</span><span class="mi">13</span><span class="p">,</span><span class="mi">21</span><span class="p">,</span><span class="mi">18</span><span class="p">,</span><span class="mi">33</span><span class="p">,</span><span class="mi">35</span><span class="p">,</span><span class="mi">40</span><span class="p">,</span><span class="mi">36</span><span class="p">,</span><span class="mi">22</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="mi">21</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">17</span><span class="p">,</span><span class="mi">14</span><span class="p">,</span><span class="mi">17</span><span class="p">,</span><span class="mi">19</span><span class="p">,</span>
</span><span class="line">          <span class="mi">26</span><span class="p">,</span><span class="mi">29</span><span class="p">,</span><span class="mi">40</span><span class="p">,</span><span class="mi">31</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="mi">18</span><span class="p">,</span><span class="mi">26</span><span class="p">,</span><span class="mi">17</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">17</span><span class="p">,</span><span class="mi">21</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">46</span><span class="p">,</span><span class="mi">33</span><span class="p">,</span><span class="mi">23</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">22</span><span class="p">,</span><span class="mi">27</span><span class="p">,</span>
</span><span class="line">          <span class="mi">18</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">17</span><span class="p">,</span><span class="mi">21</span><span class="p">,</span><span class="mi">31</span><span class="p">,</span><span class="mi">34</span><span class="p">,</span><span class="mi">44</span><span class="p">,</span><span class="mi">38</span><span class="p">,</span><span class="mi">31</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">26</span><span class="p">,</span><span class="mi">32</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>This is what it looks like:</p>

<p><img src="http://grisha.org/images/hw04.png" /></p>

<p>You can see that this series is seasonal, there are clearly visible 6
seasons. Although perhaps not easily apparent from the picture, the
season length for this series is 12, i.e. it “repeats” every 12
points. In order to apply triple exponential smoothing we need to know
what the season length is. (There do exist methods for detecting
seasonality in series, but this is way beyond the scope of this text).</p>

<h4 id="initial-trend">Initial Trend</h4>

<p>For double exponential smoothing we simply used the first two points
for the initial trend. With seasonal data we can do better than that,
since we can observe many seasons and can extrapolate a better
starting trend. The most common practice is to compute the average of
trend averages across seasons.</p>

<script type="math/tex; mode=display">
b_0 = \dfrac{1}{L}\left(\dfrac{y_{L+1}-y_1}{L}+\dfrac{y_{L+2}-y_2}{L}+...+\dfrac{y_{L+L}-y_L}{L}\right)
</script>

<p>Good news - this looks simpler in Python than in math notation:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">initial_trend</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">slen</span><span class="p">):</span>
</span><span class="line">    <span class="nb">sum</span> <span class="o">=</span> <span class="mf">0.0</span>
</span><span class="line">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">slen</span><span class="p">):</span>
</span><span class="line">        <span class="nb">sum</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="n">series</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">slen</span><span class="p">]</span> <span class="o">-</span> <span class="n">series</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="n">slen</span>
</span><span class="line">    <span class="k">return</span> <span class="nb">sum</span> <span class="o">/</span> <span class="n">slen</span>
</span><span class="line">
</span><span class="line"><span class="c"># &gt;&gt;&gt; initial_trend(series, 12)</span>
</span><span class="line"><span class="c"># -0.7847222222222222</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h4 id="initial-seasonal-components">Initial Seasonal Components</h4>

<p>The situation is even more complicated when it comes to initial values
for the seasonal components. Briefly, we need to compute the average
level for every observed season we have, divide every observed value
by the average for the season it’s in and finally average each of
these numbers across our observed seasons. If you want more detail, here is
<a href="http://www.itl.nist.gov/div898/handbook/pmc/section4/pmc435.htm">one thorough description of this process</a>.</p>

<p>I will forgo the math notation for initial seasonal components, but
here it is in Python. The result is a season-length array of seasonal components.</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">initial_seasonal_components</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">slen</span><span class="p">):</span>
</span><span class="line">    <span class="n">seasonals</span> <span class="o">=</span> <span class="p">{}</span>
</span><span class="line">    <span class="n">season_averages</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class="line">    <span class="n">n_seasons</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">series</span><span class="p">)</span><span class="o">/</span><span class="n">slen</span><span class="p">)</span>
</span><span class="line">    <span class="c"># compute season averages</span>
</span><span class="line">    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_seasons</span><span class="p">):</span>
</span><span class="line">        <span class="n">season_averages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">series</span><span class="p">[</span><span class="n">slen</span><span class="o">*</span><span class="n">j</span><span class="p">:</span><span class="n">slen</span><span class="o">*</span><span class="n">j</span><span class="o">+</span><span class="n">slen</span><span class="p">])</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">slen</span><span class="p">))</span>
</span><span class="line">    <span class="c"># compute initial values</span>
</span><span class="line">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">slen</span><span class="p">):</span>
</span><span class="line">        <span class="n">sum_of_vals_over_avg</span> <span class="o">=</span> <span class="mf">0.0</span>
</span><span class="line">        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_seasons</span><span class="p">):</span>
</span><span class="line">            <span class="n">sum_of_vals_over_avg</span> <span class="o">+=</span> <span class="n">series</span><span class="p">[</span><span class="n">slen</span><span class="o">*</span><span class="n">j</span><span class="o">+</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="n">season_averages</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
</span><span class="line">        <span class="n">seasonals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sum_of_vals_over_avg</span><span class="o">/</span><span class="n">n_seasons</span>
</span><span class="line">    <span class="k">return</span> <span class="n">seasonals</span>
</span><span class="line">
</span><span class="line"><span class="c"># &gt;&gt;&gt; initial_seasonal_components(series, 12)</span>
</span><span class="line"><span class="c"># {0: -7.4305555555555545, 1: -15.097222222222221, 2: -7.263888888888888, 3: -5.097222222222222, 4: 3.402777777777778, 5: 8.069444444444445, 6: 16.569444444444446, 7: 9.736111111111112, 8: -0.7638888888888887, 9: 1.902777777777778, 10: -3.263888888888889, 11: -0.7638888888888887}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="the-algorithm">The Algorithm</h3>

<p>And finally, here is the additive Holt-Winters method in Python. The
arguments to the function are the series of observed values, the
season length, alpha, beta, gamma and the number of points we want
forecasted.:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">triple_exponential_smoothing</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">slen</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">n_preds</span><span class="p">):</span>
</span><span class="line">    <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class="line">    <span class="n">seasonals</span> <span class="o">=</span> <span class="n">initial_seasonal_components</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">slen</span><span class="p">)</span>
</span><span class="line">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">series</span><span class="p">)</span><span class="o">+</span><span class="n">n_preds</span><span class="p">):</span>
</span><span class="line">        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c"># initial values</span>
</span><span class="line">            <span class="n">smooth</span> <span class="o">=</span> <span class="n">series</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span class="line">            <span class="n">trend</span> <span class="o">=</span> <span class="n">initial_trend</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">slen</span><span class="p">)</span>
</span><span class="line">            <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">series</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span class="line">            <span class="k">continue</span>
</span><span class="line">        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">series</span><span class="p">):</span> <span class="c"># we are forecasting</span>
</span><span class="line">            <span class="n">m</span> <span class="o">=</span> <span class="n">i</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">series</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
</span><span class="line">            <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">smooth</span> <span class="o">+</span> <span class="n">m</span><span class="o">*</span><span class="n">trend</span><span class="p">)</span> <span class="o">+</span> <span class="n">seasonals</span><span class="p">[</span><span class="n">i</span><span class="o">%</span><span class="n">slen</span><span class="p">])</span>
</span><span class="line">        <span class="k">else</span><span class="p">:</span>
</span><span class="line">            <span class="n">val</span> <span class="o">=</span> <span class="n">series</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span><span class="line">            <span class="n">last_smooth</span><span class="p">,</span> <span class="n">smooth</span> <span class="o">=</span> <span class="n">smooth</span><span class="p">,</span> <span class="n">alpha</span><span class="o">*</span><span class="p">(</span><span class="n">val</span><span class="o">-</span><span class="n">seasonals</span><span class="p">[</span><span class="n">i</span><span class="o">%</span><span class="n">slen</span><span class="p">])</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">smooth</span><span class="o">+</span><span class="n">trend</span><span class="p">)</span>
</span><span class="line">            <span class="n">trend</span> <span class="o">=</span> <span class="n">beta</span> <span class="o">*</span> <span class="p">(</span><span class="n">smooth</span><span class="o">-</span><span class="n">last_smooth</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">beta</span><span class="p">)</span><span class="o">*</span><span class="n">trend</span>
</span><span class="line">            <span class="n">seasonals</span><span class="p">[</span><span class="n">i</span><span class="o">%</span><span class="n">slen</span><span class="p">]</span> <span class="o">=</span> <span class="n">gamma</span><span class="o">*</span><span class="p">(</span><span class="n">val</span><span class="o">-</span><span class="n">smooth</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">gamma</span><span class="p">)</span><span class="o">*</span><span class="n">seasonals</span><span class="p">[</span><span class="n">i</span><span class="o">%</span><span class="n">slen</span><span class="p">]</span>
</span><span class="line">            <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">smooth</span><span class="o">+</span><span class="n">trend</span><span class="o">+</span><span class="n">seasonals</span><span class="p">[</span><span class="n">i</span><span class="o">%</span><span class="n">slen</span><span class="p">])</span>
</span><span class="line">    <span class="k">return</span> <span class="n">result</span>
</span><span class="line">
</span><span class="line"><span class="c"># # forecast 24 points (i.e. two seasons)</span>
</span><span class="line"><span class="c"># &gt;&gt;&gt; triple_exponential_smoothing(series, 12, 0.716, 0.029, 0.993, 24)</span>
</span><span class="line"><span class="c"># [30, 20.34449316666667, 28.410051892109554, 30.438122252647577, 39.466817731253066, ...</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>And here is what this looks like if we were to plot the original
series, followed by the last 24 points from the result of the
<code>triple_exponential_smoothing()</code> call:</p>

<p><img src="http://grisha.org/images/hw05.png" /></p>

<h3 id="a-note-on---and-">A Note on α, β and γ</h3>

<p>You may be wondering how I came up with 0.716, 0.029 and 0.993 for
$\alpha$, $\beta$ and $\gamma$, respectively. To make long story short, it
was done by way of trial and error: simply running the algorithm over and
over again and selecting the values that give you the smallest
<a href="https://en.wikipedia.org/wiki/Residual_sum_of_squares">SSE</a>. As I
mentioned before, this process is known as <em>fitting</em>.</p>

<p>To compute the smothing factors to three decimal points
we may have to run through 1,000,000,000 iterations, but luckily
there are more efficient methods at zooming in on best
values. Unfortunately this would take a whole other very long post to
describe this process. One good algorithm for this is
<a href="https://en.wikipedia.org/wiki/Nelder%E2%80%93Mead_method">Nelder-Mead</a>,
which is what <a href="https://github.com/tgres/tgres">tgres</a> uses.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Well - here you have it, Holt-Winters method explained the way I wish
it would have been explained to me when I needed it. If you think I
missed something, found an error or a suggestion, please do not
hesitate to comment!</p>

<h2 id="footnote">Footnote</h2>

<p>The triple exponential smoothing additive method formula is as it is
described in “Forecasting Method and Applications, Third Edition” by
Makridakis, Wheelwright and Hyndman (1998). <a href="https://en.wikipedia.org/wiki/Exponential_smoothing#Triple_exponential_smoothing">Wikipedia</a> has a different
formula for the seasonal component (I don’t know which is better):</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align}
& s_x = \gamma(y_x - \ell_{x-1} - b_{x-1}) + (1-\gamma)s_{x-L} & \mbox{seasonal} \\
\end{align}
 %]]&gt;</script>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Holt-Winters Forecasting for Dummies - Part II]]></title>
    <link href="http://grisha.org/blog/2016/02/16/triple-exponential-smoothing-forecasting-part-ii/"/>
    <updated>2016-02-16T13:05:00-05:00</updated>
    <id>http://grisha.org/blog/2016/02/16/triple-exponential-smoothing-forecasting-part-ii</id>
    <content type="html"><![CDATA[<p>If you haven’t read <a href="http://grisha.org/blog/2016/01/29/triple-exponential-smoothing-forecasting/">Part I</a>
you probably should, or the following will be hard to make sense of.</p>

<p>All the forecasting methods we covered so far, including single
exponential smoothing, were only good at predicting a single
point. We can do better than that, but first we need to be introduced to
a couple of new terms.</p>

<h2 id="more-terminology">More terminology</h2>

<h3 id="level"><em>Level</em></h3>

<p>Expected value has another name, which, again varies depending on who wrote the
text book: <em>baseline</em>, <em>intercept</em> (as in
<a href="https://en.wikipedia.org/wiki/Y-intercept">Y-intercept</a>) or
<em>level</em>. We will stick with “level” here.</p>

<p>So level is that one predicted point that we learned how to calculate
in Part I. But because now it’s going to be only part of calculation
of the forcast, we can no longer refer to it as $\hat{y}$ and will instead
use $\ell$.</p>

<h3 id="trend-or-slope"><em>Trend</em> or <em>Slope</em></h3>

<p>You should be familiar with
<a href="https://en.wikipedia.org/wiki/Slope">slope</a> from your high school algebra
class. What you might be a little rusty on is how to calculate it,
which is important, because a series slope has an interesting
characteristic. Slope is:</p>

<script type="math/tex; mode=display">
m = \dfrac{\Delta{y}} {\Delta{x}}
</script>

<p>where $\Delta{y}$ is the difference in the $y$ coordinates and
$\Delta{x}$ is the difference in the $x$ coordinates, respectively,
between two points. While in real algebraic problems $\Delta{x}$ could
be anything, in a series, from one point to the next, it is always
1. Which means that for a series, slope between two adjacent points
is simply $\dfrac{\Delta{y}} {1}$ or $\Delta{y}$, or:</p>

<script type="math/tex; mode=display">
b = y_x - y_{x-1}
</script>

<p>Where $b$ is <em>trend</em>. To the best of my understanding terms “trend”
and “slope” are interchangeable. In forecasting parlance “trend” is
more common, and in math notation forecasters refer to it as $b$
rather than $m$.</p>

<h4 id="additive-vs-multiplicative">Additive vs Multiplicative</h4>

<p>Another thing to know about trend is that instead of subtracting
$y_{x-1}$ from $y_x$, we could divide one by the other thereby
getting a ratio. The difference between these two approaches is
similar to how we can say that something costs $20 more or 5%
more. The variant of the method based on subtraction is known as
<em>additive</em>, while the one based on division is known as
<em>multiplicative</em>.</p>

<p>Practice shows that a ratio (i.e. multiplicative) is a more stable
predictor. The additive method, however is simpler to understand, and
going from additive to multiplicative is trivial once you understand
this whole thing. For this reason we will stick with the additive
method here, leaving the multiplicative method an exercise for the
reader.</p>

<h2 id="double-exponential-smoothing">Double Exponential Smoothing</h2>

<p>So now we have two components to a series: level and trend. In Part I
we learned several methods to forecast the level, and it should follow
that every one of these methods can be applied to the trend
just as well. E.g. the naive method would assume that trend between
last two points is going to stay the same, or we could average all
slopes between all points to get an average trend, use a moving trend
average or apply exponential smoothing.</p>

<p>Double exponential smoothing then is nothing more than exponential
smoothing applied to both level and trend. To express this in
mathematical notation we now need three equations: one for level, one
for the trend and one to combine the level and trend to get the
expected $\hat{y}$.</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align}
& \ell_x = \alpha y_x + (1-\alpha)(\ell_{x-1} + b_{x-1})& \mbox{level} \\
& b_x = \beta(\ell_x - \ell_{x-1}) + (1-\beta)b_{x-1} & \mbox{trend} \\
& \hat{y}_{x+1} = \ell_x + b_x & \mbox{forecast}\\
\end{align}
 %]]&gt;</script>

<p>The first equation is from Part I, only now we’re using $\ell$ instead
of $\hat{y}$ and on the right side the expected value becomes the sum
of level end trend.</p>

<p>The second equation introduces $\beta$, the <em>trend factor</em> (or
coefficient). As with $\alpha$, some values of ${\beta}$ work better
than others depending on the series.</p>

<p>Similarly to single exponential smoothing, where we used the first
observed value as the first expected, we can use the first observed
trend as the first expected. Of course we need at least two points to
compute the initial trend.</p>

<p>Because we have a level and a trend, this method can forecast not one,
but two data points. In Python:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="c"># given a series and alpha, return series of smoothed points</span>
</span><span class="line"><span class="k">def</span> <span class="nf">double_exponential_smoothing</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
</span><span class="line">    <span class="n">result</span> <span class="o">=</span> <span class="p">[</span><span class="n">series</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
</span><span class="line">    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">series</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
</span><span class="line">        <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span class="line">            <span class="n">level</span><span class="p">,</span> <span class="n">trend</span> <span class="o">=</span> <span class="n">series</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">series</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">series</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span class="line">        <span class="k">if</span> <span class="n">n</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">series</span><span class="p">):</span> <span class="c"># we are forecasting</span>
</span><span class="line">          <span class="n">value</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span class="line">        <span class="k">else</span><span class="p">:</span>
</span><span class="line">          <span class="n">value</span> <span class="o">=</span> <span class="n">series</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
</span><span class="line">        <span class="n">last_level</span><span class="p">,</span> <span class="n">level</span> <span class="o">=</span> <span class="n">level</span><span class="p">,</span> <span class="n">alpha</span><span class="o">*</span><span class="n">value</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">level</span><span class="o">+</span><span class="n">trend</span><span class="p">)</span>
</span><span class="line">        <span class="n">trend</span> <span class="o">=</span> <span class="n">beta</span><span class="o">*</span><span class="p">(</span><span class="n">level</span><span class="o">-</span><span class="n">last_level</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">beta</span><span class="p">)</span><span class="o">*</span><span class="n">trend</span>
</span><span class="line">        <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">level</span><span class="o">+</span><span class="n">trend</span><span class="p">)</span>
</span><span class="line">    <span class="k">return</span> <span class="n">result</span>
</span><span class="line">
</span><span class="line"><span class="c"># &gt;&gt;&gt; double_exponential_smoothing(series, alpha=0.9, beta=0.9)</span>
</span><span class="line"><span class="c"># [3, 17.0, 15.45, 14.210500000000001, 11.396044999999999, 8.183803049999998, 12.753698384500002, 13.889016464000003]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>And here is a picture of double exponential smoothing in action (the
green dotted line).</p>

<p><img src="http://grisha.org/images/hw03.png" /></p>

<h2 id="quick-review">Quick Review</h2>

<p>We’ve learned that a data point in a series can be represented as a
level and a trend, and we have learned how to appliy exponential
smoothing to each of them to be able to forecast not one, but two
points.</p>

<p>In <a href="http://grisha.org/blog/2016/02/17/triple-exponential-smoothing-forecasting-part-iii/">Part III</a>
we’ll finally talk about triple exponential smoothing.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Holt-Winters Forecasting for Dummies (or Developers) - Part I]]></title>
    <link href="http://grisha.org/blog/2016/01/29/triple-exponential-smoothing-forecasting/"/>
    <updated>2016-01-29T15:36:00-05:00</updated>
    <id>http://grisha.org/blog/2016/01/29/triple-exponential-smoothing-forecasting</id>
    <content type="html"><![CDATA[<p>This three part write up [<a href="http://grisha.org/blog/2016/02/16/triple-exponential-smoothing-forecasting-part-ii/">Part II</a>
<a href="http://grisha.org/blog/2016/02/17/triple-exponential-smoothing-forecasting-part-iii/">Part III</a>]
is my attempt at a down-to-earth explanation (and Python code) of the
Holt-Winters method for those of us who while hypothetically might be
quite good at math, still try to avoid it at every opportunity. I had
to dive into this subject while tinkering on
<a href="https://github.com/tgres/tgres">tgres</a> (which features a Golang implementation). And
having found it somewhat complex (and yet so brilliantly
simple), figured that it’d be good to share this knowledge, and
in the process, to hopefully solidify it in my head as well.</p>

<p><a href="https://en.wikipedia.org/wiki/Exponential_smoothing#Triple_exponential_smoothing">Triple Exponential Smoothing</a>,
also known as the Holt-Winters method, is one of the many methods or
algorithms that can be used to forecast data points in a series,
provided that the series is “seasonal”, i.e. repetitive over some
period.</p>

<p><img src="http://grisha.org/images/hw00.png" /></p>

<h1 id="a-little-history">A little history</h1>

<p>Еxponential smoothing in some form or another dates back to the work
of <a href="https://en.wikipedia.org/wiki/Sim%C3%A9on_Denis_Poisson">Siméon Poisson</a> (1781-1840),
while its application in forecasting appears to have been pioneered over a century later in 1956 by
<a href="https://en.wikipedia.org/wiki/Robert_Goodell_Brown">Robert Brown</a> (1923–2013)
in his publication
<a href="https://industrydocuments.library.ucsf.edu/tobacco/docs/#id=jzlc0130">Exponential Smoothing for Predicting Demand</a>,
(Cambridge, Massachusetts). [Based on the URL it seems Brown was working on forecasting tobacco demand?]</p>

<p>In 1957 an <a href="http://web.mit.edu/">MIT</a> and <a href="http://www.uchicago.edu/">University of Chicago</a>
graduate, professor <a href="https://en.wikipedia.org/wiki/Charles_C._Holt">Charles C Holt</a>
(1921-2010) was working at <a href="http://www.cmu.edu/">CMU</a> (then known as CIT) on forecasting trends in production,
inventories and labor force.
It appears that Holt and Brown worked independently  and knew not of each-other’s work.
Holt published a paper “Forecasting trends
and seasonals by exponentially weighted moving averages” (Office of Naval Research Research
Memorandum No. 52, Carnegie Institute of Technology) describing
double exponential smoothing. Three years later, in 1960, a student of
Holts (?) Peter R. Winters improved the algorithm by adding seasonality and
published
<a href="http://pubsonline.informs.org/doi/abs/10.1287/mnsc.6.3.324">Forecasting sales by exponentially weighted moving averages</a>
(Management Science 6, 324–342), citing Dr. Holt’s 1957 paper as earlier work on the same subject.
This algorithm became known as triple exponential smoothing or the Holt-Winters method,
the latter probably because it was described in a 1960 Prentice-Hall book “Planning Production, Inventories, and Work Force”
by Holt, <a href="https://en.wikipedia.org/wiki/Franco_Modigliani">Modigliani</a>, <a href="https://en.wikipedia.org/wiki/John_Muth">Muth</a>,
<a href="https://en.wikipedia.org/wiki/Herbert_A._Simon">Simon</a>,
<a href="https://www.gsb.stanford.edu/faculty-research/faculty/charles-puis-bonini">Bonini</a> and Winters - good luck finding a copy!</p>

<p>Curiously, I’ve not been able to find any personal information on Peter R. Winters online. If you find anything, please let me
know, I’ll add a reference here.</p>

<p>In 2000 the Holt-Winters method became well known in the <a href="https://en.wikipedia.org/wiki/Internet_service_provider">ISP</a>
circles at the height of the <a href="https://en.wikipedia.org/wiki/Dot-com_bubble">.com boom</a> when Jake D. Brutlag (then of WebTV) published
<a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwiAx9SNoezKAhXCC5oKHZZ4A84QFgghMAA&amp;url=https%3A%2F%2Fwww.usenix.org%2Fevents%2Flisa00%2Ffull_papers%2Fbrutlag%2Fbrutlag.pdf&amp;usg=AFQjCNEg-ynB5Ok0Sf4ATBB77PcGwT4OLw&amp;bvm=bv.113943665,d.bGs">Aberrant Behavior Detection in Time Series for Network Monitoring</a>
(Proceedings of the 14th Systems Administration Conference, LISA
2000). It described how an open source <a href="https://en.wikipedia.org/wiki/C_%28programming_language%29">C</a>
implementation [<a href="https://github.com/oetiker/rrdtool-1.x/commit/cafbbce69d9d1d4a1772299d97138b5a81d343f5">link to the actual commit</a>]
of a variant of the Holt-Winters seasonal method, which he contributed as a feature
to the very popular at ISPs <a href="http://oss.oetiker.ch/rrdtool/">RRDTool</a>, could be used to
monitor network traffic.</p>

<p>In 2003, a remarkable 40+ years since the publication of Winters
paper, professor <a href="http://www.sbs.ox.ac.uk/community/people/james-taylor">James W Taylor</a>
of <a href="http://www.ox.ac.uk/">Oxford University</a> extended the
Holt-Winters method to multiple seasonalities (i.e. $n$-th exponential
smoothing) and published <a href="http://users.ox.ac.uk/~mast0315/ExpSmDoubleSeasonal.pdf">Short-term electricity demand forecasting using double seasonal exponential smoothing</a>
(Journal of Operational
Research Society, vol. 54, pp. 799–805). (But we won’t cover Taylors
method here).</p>

<p>In 2011 the RRDTool implementation contributed by Brutlag was
<a href="https://github.com/graphite-project/graphite-web/commit/4e7a0d664ea2153ea65173138ab8f337716e21fa">ported</a>
to <a href="http://graphite.readthedocs.org/en/latest/">Graphite</a> by Matthew Graham thus making it even more popular in the
devops community.</p>

<p>So… how does it work?</p>

<h1 id="forecasting-baby-steps">Forecasting, Baby Steps</h1>

<p>The best way to explain triple exponential smoothing is to gradually
build up to it starting with the simplest forecasting methods. Lest
this text gets too long, we will stop at triple exponential smoothing,
though there are quite a few other methods known.</p>

<p>I used mathematical notation only where I thought it made best sense, sometimes
accompanied by an “English translation”, and where appropriate
supplemented with a bit of <a href="http://www.python.org">Python</a> code.
In Python I refrain from using any non-standard packages, keeping the
examples plain. I chose not to use <a href="https://wiki.python.org/moin/Generators">generators</a>
for clarity. The objective here is to explain
the inner working of the algorithm so that you can implement it
yourself in whatever language you prefer.</p>

<p>I also hope to demonstrate that this is simple enough that you do not
need to resort to <a href="http://www.scipy.org/">SciPy</a> or <a href="https://en.wikipedia.org/wiki/R_%28programming_language%29">whatever</a>
(not that there is anything wrong with that).</p>

<h2 id="but-first-some-terminology">But First, Some Terminology</h2>

<h3 id="series"><em>Series</em></h3>

<p>The main subject here is a <em>series</em>. In the real world we are most
likely to be applying this to a <em>time series</em>, but for this discussion
the time aspect is irrelevant. A series is merely an ordered sequence
of numbers. We might be using words that are chronological in nature
(past, future, yet, already, <em>time</em> even!), but only because it makes it easer to
understand. So forget about time, timestamps, intervals,
<a href="http://www.preposterousuniverse.com/blog/2013/10/18/is-time-real/">time does not exist</a>,
the only property each data point has (other than the value) is its order: first,
next, previous, last, etc.</p>

<p>It is useful to think of a series as a list of two-dimensional $x,y$
coordinates, where $x$ is order (always going up by 1), and $y$ is
value. For this reason in our math formulas we will be sticking to $y$
for value and $x$ for order.</p>

<h3 id="observed-vs-expected"><em>Observed</em> vs <em>Expected</em></h3>

<p>Forecasting is estimating values that we do not yet know based on the
the values we do know. The values we know are referred to as
<em>observed</em> while the values we forecast as <em>expected</em>. The math
convention to denote expected values is with the
<a href="https://en.wikipedia.org/wiki/Circumflex">circumflex</a> a.k.a. “hat”: $\hat{y}$</p>

<p>For example, if we have a series that looks like <code>[1,2,3]</code>, we might
forecast the next value to be 4. Using this terminology, given
observed series <code>[1,2,3]</code> the next expected value ${\hat{y}_4}$ is 4.</p>

<h3 id="method"><em>Method</em></h3>

<p>We may have intuited based on <code>[1,2,3]</code> that in this series each value
is 1 greater than the previous, which in math notation can
be expressed as and $\hat{y}_{x + 1} = y_x + 1$.  This equation, the
result of our intuition, is known as a forecast <em>method</em>.</p>

<p>If our method is correct then the next observed value would indeed be
4, but if <code>[1,2,3]</code> is actually part of a
<a href="https://en.wikipedia.org/wiki/Fibonacci_number">Fibonacci sequence</a>, then where we
expected ${\hat{y}_4 = 4}$, we would observe $y_4 = 5$. Note the hatted
${\hat{y}}$ (expected) in the former and $y$ (observed) in the latter expression.</p>

<h3 id="error-sse-and-mse"><em>Error</em>, <em>SSE</em> and <em>MSE</em></h3>

<p>It is perfectly normal to compute expected values where we already
have observed values. Comparing the two lets you compute the <em>error</em>,
which is the <em>difference</em> between observed and expected and is an
indispensable indication of the accuracy of the method.</p>

<p>Since difference can be negative or positive, the common convention is
to use the absolute value or square the error so that the number is always
positive. For a whole series the squared errors are typically summed
resulting in <em><a href="https://en.wikipedia.org/wiki/Residual_sum_of_squares">Sum of Squared Errors</a> (SSE)</em>.
Sometimes you may come across <em><a href="https://en.wikipedia.org/wiki/Residual_sum_of_squares">Mean Squared Error</a>
(MSE)</em> which is simply $\sqrt{SSE}$.</p>

<h2 id="and-now-the-methods-where-the-fun-begins">And Now the Methods (where the fun begins!)</h2>

<p>In the next few examples we are going to be using this tiny series:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">series</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">13</span><span class="p">,</span><span class="mi">12</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">12</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>(Feel free to paste it and any of the following code snippets into your Python
<a href="https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop">repl</a>)</p>

<h3 id="naive-method">Naive Method</h3>

<p>This is the most primitive forecasting method. The premise of the
<em>naive</em> method is that the expected point is equal to the last
observed point:</p>

<script type="math/tex; mode=display">
\hat{y}_{x+1} = y_x
</script>

<p>Using this method we would forecast the next point to be 12.</p>

<h3 id="simple-average">Simple Average</h3>

<p>A less primitive method is the <a href="https://en.wikipedia.org/wiki/Arithmetic_mean">arithmetic average</a>
of all the previously observed data points. We take all the values we
know, calculate the average and bet that that’s going to be the next value. Of course it won’t be it exactly,
but it probably will be somewhere in the ballpark, hopefully you can see the reasoning behind this
simplistic approach.</p>

<script type="math/tex; mode=display">
\hat{y}_{x+1} = \dfrac{1}{x}\sum_{i=1}^{x}y_i
</script>

<p>(Okay, this formula is only here because I think the <a href="https://en.wikipedia.org/wiki/Summation">capital Sigma</a>
looks cool. I am sincerely hoping that the average requires no explanation.) In Python:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">average</span><span class="p">(</span><span class="n">series</span><span class="p">):</span>
</span><span class="line">    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">series</span><span class="p">))</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">series</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="c"># Given the above series, the average is:</span>
</span><span class="line"><span class="c"># &gt;&gt;&gt; average(series)</span>
</span><span class="line"><span class="c"># 10.285714285714286</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>As a forecasting method, there are actually situations where it’s spot
on. For example your final school grade may be the average of all the
previous grades.</p>

<h3 id="moving-average">Moving Average</h3>

<p>An improvement over simple average is the average of $n$ last
points. Obviously the thinking here is that only the recent values
matter. Calculation of the moving average involves what is sometimes
called a “sliding window” of size $n$:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="c"># moving average using n last points</span>
</span><span class="line"><span class="k">def</span> <span class="nf">moving_average</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
</span><span class="line">    <span class="k">return</span> <span class="n">average</span><span class="p">(</span><span class="n">series</span><span class="p">[</span><span class="o">-</span><span class="n">n</span><span class="p">:])</span>
</span><span class="line">
</span><span class="line"><span class="c"># &gt;&gt;&gt; moving_average(series, 3)</span>
</span><span class="line"><span class="c"># 11.333333333333334</span>
</span><span class="line"><span class="c"># &gt;&gt;&gt; moving_average(series, 4)</span>
</span><span class="line"><span class="c"># 11.75</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>A moving average can actually be quite effective, especially if you
pick the right $n$ for the series. Stock analysts adore it.</p>

<p>Also note that simple average is a variation of a moving average, thus
the two functions above could be re-written as a single recursive one
(just for fun):</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">average</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
</span><span class="line">    <span class="k">if</span> <span class="n">n</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
</span><span class="line">        <span class="k">return</span> <span class="n">average</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">series</span><span class="p">))</span>
</span><span class="line">    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">series</span><span class="p">[</span><span class="o">-</span><span class="n">n</span><span class="p">:]))</span><span class="o">/</span><span class="n">n</span>
</span><span class="line">
</span><span class="line"><span class="c"># &gt;&gt;&gt; average(series, 3)</span>
</span><span class="line"><span class="c"># 11.333333333333334</span>
</span><span class="line"><span class="c"># &gt;&gt;&gt; average(series)</span>
</span><span class="line"><span class="c"># 10.285714285714286</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="weighted-moving-average">Weighted Moving Average</h3>

<p>A <em>weighted</em> moving average is a moving average where within the
sliding window values are given different weights, typically so that
more recent points matter more.</p>

<p>Instead of selecting a window size, it requires a list of weights
(which should add up to 1). For example if we picked <code>[0.1,
0.2, 0.3, 0.4]</code> as weights, we would be giving 10%, 20%, 30% and 40%
to the last 4 points respectively. In Python:</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="c"># weighted average, weights is a list of weights</span>
</span><span class="line"><span class="k">def</span> <span class="nf">weighted_average</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
</span><span class="line">    <span class="n">result</span> <span class="o">=</span> <span class="mf">0.0</span>
</span><span class="line">    <span class="n">weights</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
</span><span class="line">    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)):</span>
</span><span class="line">        <span class="n">result</span> <span class="o">+=</span> <span class="n">series</span><span class="p">[</span><span class="o">-</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">weights</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
</span><span class="line">    <span class="k">return</span> <span class="n">result</span>
</span><span class="line">
</span><span class="line"><span class="c"># &gt;&gt;&gt; weights = [0.1, 0.2, 0.3, 0.4]</span>
</span><span class="line"><span class="c"># &gt;&gt;&gt; weighted_average(series, weights)</span>
</span><span class="line"><span class="c"># 11.5</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Weighted moving average is fundamental to what follows, please take a
moment to understand it, give it a think before reading on.</p>

<p>I would also like to stretch the importance of the weights adding up
to 1. To demonstrate why, let’s say we pick weights <code>[0.9, 0.8, 0.7,
0.6]</code> (which add up to 3.0). Watch what happens:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">&gt;&gt;&gt; weighted_average(series, [0.9, 0.8, 0.7, 0.6])
</span><span class="line">&gt;&gt;&gt; 35.5  # &lt;--- this is clearly bogus</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="picture-time">Picture time!</h3>

<p>Here is a picture that demonstrates our tiny series and all of the above
forecasts (except for naive).</p>

<p><img src="http://grisha.org/images/hw01.png" /></p>

<p>It’s important to understand that which of the above methods is better
very much depends on the nature of the series. The order in which I
presented them was from simple to complex, but “more complex” doesn’t
necessarily mean “better”.</p>

<h3 id="single-exponential-smoothing">Single Exponential Smoothing</h3>

<p>Here is where things get interesting. Imagine a weighted average where
we consider <em>all</em> of the data points, while assigning exponentially
smaller weights as we go back in time. For example if we started with
0.9, our weights would be (going back in time):</p>

<script type="math/tex; mode=display">
0.9^1, 0.9^2, 0.9^3, 0.9^4, 0.9^5, 0.9^6... \\
\mbox{or: } 0.9, 0.81, 0.729, 0.6561, 0.59049, 0.531441, ...
</script>

<p>…eventually approaching the big old zero. In some way this is very
similar to the weighted average above, only the weights are dictated
by math, decaying uniformly. The smaller the starting weight, the
faster it approaches zero.</p>

<p>Only… there is a problem: weights do not add up to 1. The sum of
the first 3 numbers alone is already 2.439! (Exercise for the reader: what number
does the sum of the weights approach and why?)</p>

<p>What earned Poisson, Holts or Roberts a permanent place in the history
of Mathematics is solving this with a succinct and elegant formula:</p>

<script type="math/tex; mode=display">
\hat{y}_x = \alpha \cdot y_x + (1-\alpha) \cdot \hat{y}_{x-1} \\
</script>

<p>If you stare at it just long enough, you will see that the expected
value $\hat{y}_x$ is the sum of two products: $\alpha \cdot y_x$ and
$(1-\alpha) \cdot \hat{y}_{x-1}$. You can think of $\alpha$ (alpha)
as a sort of a starting weight 0.9 in the above (problematic)
example. It is called the <em>smoothing factor</em> or <em>smoothing
coefficient</em> (depending on who wrote your text book).</p>

<p>So essentially we’ve got a weighted moving average with two weights:
$\alpha$ and $1-\alpha$.  The sum of $\alpha$ and $1-\alpha$ is 1, so
all is well.</p>

<p>Now let’s zoom in on the right side of the sum. Cleverly, $1-\alpha$
is multiplied by the <em>previous</em> expected value
$\hat{y}_{x-1}$. Which, if you think about it, is the result of the
same formula, which makes the expression recursive (and programmers
love recursion), and if you were to write it all out on paper you would
quickly see that $(1-\alpha)$ is multiplied by itself again and again
all the way to beginning of the series, if there is one, infinitely
otherwise. And this is why this method is called
<em>exponential</em>.</p>

<p>Another important thing about $\alpha$ is that its value dictates how
much weight we give the most recent observed value versus the last
expected. It’s a kind of a lever that gives more weight to the left
side when it’s higher (closer to 1) or the right side when it’s lower
(closer to 0).</p>

<p>Perhaps $\alpha$ would be better referred to as <em>memory decay rate</em>: the
higher the $\alpha$, the faster the method “forgets”.</p>

<h4 id="why-is-it-called-smoothing">Why is it called “smoothing”?</h4>

<p>To the best of my understanding this simply refers to the effect these
methods have on a graph if you were to plot the values: jagged lines
become smoother.  Moving average also has the same effect, so it
deserves the right to be called smoothing just as well.</p>

<h4 id="implementation">Implementation</h4>

<p>There is an aspect of this method that programmers would appreciate
that is of no concern to mathematicians: it’s simple and efficient to
implement. Here is some Python. Unlike the previous examples, this
function returns expected values for the whole series, not just one
point.</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="c"># given a series and alpha, return series of smoothed points</span>
</span><span class="line"><span class="k">def</span> <span class="nf">exponential_smoothing</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
</span><span class="line">    <span class="n">result</span> <span class="o">=</span> <span class="p">[</span><span class="n">series</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="c"># first value is same as series</span>
</span><span class="line">    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">series</span><span class="p">)):</span>
</span><span class="line">        <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">series</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">result</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span class="line">    <span class="k">return</span> <span class="n">result</span>
</span><span class="line">
</span><span class="line"><span class="c"># &gt;&gt;&gt; exponential_smoothing(series, 0.1)</span>
</span><span class="line"><span class="c"># [3, 3.7, 4.53, 5.377, 6.0393, 6.43537, 6.991833]</span>
</span><span class="line"><span class="c"># &gt;&gt;&gt; exponential_smoothing(series, 0.9)</span>
</span><span class="line"><span class="c"># [3, 9.3, 11.73, 12.873000000000001, 12.0873, 10.20873, 11.820873]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The figure below shows exponentially smoothed version of our series
with $\alpha$ of 0.9 (red) and $\alpha$ of 0.1 (orange).</p>

<p><img src="http://grisha.org/images/hw02.png" /></p>

<p>Looking at the above picture it is apparent that the $\alpha$ value of 0.9
follows the observed values much closer than 0.1. This isn’t going to
be true for any series, each series has its best $\alpha$ (or
several). The process of finding the best $\alpha$ is referred to as
<em>fitting</em> and we will discuss it later separately.</p>

<h2 id="quick-review">Quick Review</h2>

<p>We’ve learned some history, basic terminology (series and how it knows
no time, method, error SSE, MSE and fitting). And we’ve learned some
basic forecasting methods: naive, simple average, moving average,
weighted moving average and, finally, single exponential smoothing.</p>

<p>One very important characteristic of all of the above methods is that
remarkably, they can only forecast a <em>single</em> point. That’s correct,
just one.</p>

<p>In <a href="http://grisha.org/blog/2016/02/16/triple-exponential-smoothing-forecasting-part-ii/">Part II</a> we will focus on methods that can forecast more than
one point.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Storing Time Series in PostgreSQL efficiently]]></title>
    <link href="http://grisha.org/blog/2015/09/23/storing-time-series-in-postgresql-efficiently/"/>
    <updated>2015-09-23T22:01:00-04:00</updated>
    <id>http://grisha.org/blog/2015/09/23/storing-time-series-in-postgresql-efficiently</id>
    <content type="html"><![CDATA[<p>With the latest advances in PostgreSQL (and other db’s), a relational
database begins to look like a very viable TS storage platform. In
this write up I attempt to show how to store TS in PostgreSQL. (2016-12-17 Update:
there is a <a href="http://grisha.org/blog/2016/12/16/storing-time-series-in-postgresql-part-ii/">part 2</a> of this article.)</p>

<p>A TS is a series of [timestamp, measurement] pairs, where measurement
is typically a floating point number. These pairs (aka “data points”)
usually arrive at a high and steady rate. As time goes on, detailed
data usually becomes less interesting and is often consolidated into
larger time intervals until ultimately it is expired.</p>

<h2 id="the-obvious-approach">The obvious approach</h2>

<p>The “naive” approach is a three-column table, like so:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"> <span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">ts</span> <span class="p">(</span><span class="n">id</span> <span class="nb">INT</span><span class="p">,</span> <span class="n">time</span> <span class="n">TIMESTAMPTZ</span><span class="p">,</span> <span class="n">value</span> <span class="nb">REAL</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>(Let’s gloss over some details such as an index on the time column and
choice of data type for time and value as it’s not relevant to this
discussion.)</p>

<p>One problem with this is the inefficiency of appending data. An insert
requires a look up of the new id, locking and (usually) blocks until
the data is synced to disk. Given the TS’s “firehose” nature, the
database can quite quickly get overwhelmed.</p>

<p>This approach also does not address consolidation and eventual
expiration of older data points.</p>

<h2 id="round-robin-database">Round-robin database</h2>

<p>A better alternative is something called a <em>round-robin database</em>.  An
RRD is a circular structure with a separately stored pointer denoting
the last element and its timestamp.</p>

<p>A everyday life example of an RRD is a week. Imagine a structure of 7
slots, one for each day of the week. If you know today’s date and day
of the week, you can easily infer the date for each slot. For example
if today is Tuesday, April 1, 2008, then the Monday slot refers to
March 31st, Sunday to March 30th and (most notably) Wednesday to March
26.</p>

<p>Here’s what a 7-day RRD of average temperature might look as of
Tuesday, April 1:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="n">Week</span> <span class="k">day</span><span class="p">:</span> <span class="n">Sun</span>  <span class="n">Mon</span>  <span class="n">Tue</span>  <span class="n">Wed</span>  <span class="n">Thu</span>  <span class="n">Fri</span>  <span class="n">Sat</span>
</span><span class="line"><span class="nb">Date</span><span class="p">:</span>     <span class="mi">3</span><span class="o">/</span><span class="mi">30</span> <span class="mi">3</span><span class="o">/</span><span class="mi">31</span> <span class="mi">4</span><span class="o">/</span><span class="mi">1</span>  <span class="mi">3</span><span class="o">/</span><span class="mi">26</span> <span class="mi">3</span><span class="o">/</span><span class="mi">27</span> <span class="mi">3</span><span class="o">/</span><span class="mi">28</span> <span class="mi">3</span><span class="o">/</span><span class="mi">29</span>
</span><span class="line"><span class="n">Temp</span> <span class="n">F</span><span class="p">:</span>   <span class="mi">79</span>   <span class="mi">82</span>   <span class="mi">90</span>   <span class="mi">69</span>   <span class="mi">75</span>   <span class="mi">80</span>   <span class="mi">81</span>
</span><span class="line">                    <span class="o">^</span>
</span><span class="line">                    <span class="k">last</span> <span class="n">entry</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Come Wednesday, April 2nd, our RRD now loooks like this:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="n">Week</span> <span class="k">day</span><span class="p">:</span> <span class="n">Sun</span>  <span class="n">Mon</span>  <span class="n">Tue</span>  <span class="n">Wed</span>  <span class="n">Thu</span>  <span class="n">Fri</span>  <span class="n">Sat</span>
</span><span class="line"><span class="nb">Date</span><span class="p">:</span>     <span class="mi">3</span><span class="o">/</span><span class="mi">30</span> <span class="mi">3</span><span class="o">/</span><span class="mi">31</span> <span class="mi">4</span><span class="o">/</span><span class="mi">1</span>  <span class="mi">4</span><span class="o">/</span><span class="mi">2</span>  <span class="mi">3</span><span class="o">/</span><span class="mi">27</span> <span class="mi">3</span><span class="o">/</span><span class="mi">28</span> <span class="mi">3</span><span class="o">/</span><span class="mi">29</span>
</span><span class="line"><span class="n">Temp</span> <span class="n">F</span><span class="p">:</span>   <span class="mi">79</span>   <span class="mi">82</span>   <span class="mi">90</span>   <span class="mi">92</span>   <span class="mi">75</span>   <span class="mi">80</span>   <span class="mi">81</span>
</span><span class="line">                         <span class="o">^</span>
</span><span class="line">                         <span class="k">last</span> <span class="n">entry</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Note how little has changed, and that the update required no
allocation of space: all we did to record 92F on Wednesday is
overwrite one value. Even more remarkably, the previous value
automatically “expired” when we overwrote it, thus solving the
eventual expiration problem without any additional operations.</p>

<p>RRD’s are also very space-efficient. In the above example we specified
the date of every slot for clarity. In an actual implementation only
the date of the last slot needs to be stored, thus the RRD can be kept
as a sequence of 7 numbers plus the position of the last entry and
it’s timestamp. In Python syntax it’d look like this:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="p">[[</span><span class="mi">79</span><span class="p">,</span><span class="mi">82</span><span class="p">,</span><span class="mi">90</span><span class="p">,</span><span class="mi">92</span><span class="p">,</span><span class="mi">75</span><span class="p">,</span><span class="mi">80</span><span class="p">,</span><span class="mi">81</span><span class="p">],</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1207022400</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="round-robin-in-postgresql">Round-robin in PostgreSQL</h2>

<p>Here is a naive approach to having a round-robin table. Carrying on
with our 7 day RRD example, it might look like this:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">week_day</span> <span class="o">|</span> <span class="n">temp_f</span>
</span><span class="line"><span class="o">---------+--------</span>
</span><span class="line">     <span class="mi">1</span>   <span class="o">|</span>   <span class="mi">79</span>
</span><span class="line">     <span class="mi">2</span>   <span class="o">|</span>   <span class="mi">82</span>
</span><span class="line">     <span class="mi">3</span>   <span class="o">|</span>   <span class="mi">90</span>
</span><span class="line">     <span class="mi">4</span>   <span class="o">|</span>   <span class="mi">69</span>
</span><span class="line">     <span class="mi">5</span>   <span class="o">|</span>   <span class="mi">75</span>
</span><span class="line">     <span class="mi">6</span>   <span class="o">|</span>   <span class="mi">80</span>
</span><span class="line">     <span class="mi">7</span>   <span class="o">|</span>   <span class="mi">81</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Somewhere separately we’d also need to record that the last entry is
week_day 3 (Tuesday) and it’s 2008-04-01. Come April 2, we could
record the temperature using:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="k">UPDATE</span> <span class="n">series</span> <span class="k">SET</span> <span class="n">temp_f</span> <span class="o">=</span> <span class="mi">92</span> <span class="k">WHERE</span> <span class="n">week_day</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>This might be okay for a 7-slot RRD, but a more typical TS might have
a slot per minute going back 90 days, which would require 129600
rows. For recording data points one at a time it might be fast enough,
but to copy the whole RRD would require 129600 UPDATE statements which
is not very efficient.</p>

<p>This is where using PostgrSQL <em>arrays</em> become very useful.</p>

<h2 id="using-postgresql-arrays">Using PostgreSQL arrays</h2>

<p>An array would allow us to store the whole series in a single
row. Sticking with the 7-day RRD example, our table would be created
as follows:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">ts</span> <span class="p">(</span><span class="n">dp</span> <span class="n">DOUBLE</span> <span class="k">PRECISION</span><span class="p">[]</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="k">DEFAULT</span> <span class="s1">&#39;{}&#39;</span><span class="p">,</span>
</span><span class="line">                 <span class="n">last_date</span> <span class="nb">DATE</span><span class="p">,</span>
</span><span class="line">                 <span class="n">pos</span> <span class="nb">INT</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>(Nevemind that there is no id column for now)</p>

<p>We could populate the whole RRD in a single statement:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span><span class="p">(</span><span class="s1">&#39;{79,82,90,69,75,80,81}&#39;</span><span class="p">,</span> <span class="s1">&#39;2008-08-01&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>…or record 92F for Wednesday as so:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="k">UPDATE</span> <span class="n">ts</span> <span class="k">SET</span> <span class="n">dp</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="mi">92</span><span class="p">,</span> <span class="n">last_date</span> <span class="o">=</span> <span class="s1">&#39;2008-04-02&#39;</span><span class="p">,</span> <span class="n">pos</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>(In PostgreSQL arrays are 1-based, not 0-based like in most
programming languages)</p>

<h2 id="but-it-could-be-even-more-efficient">But it could be even more efficient</h2>

<p>Under the hood, PostgreSQL data is stored in pages of 8K. It would
make sense to keep chunks in which our RRD is written to disk in line
with page size, or at least smaller than one page. (PostgreSQL provides
configuration parameters for how much of a page is used, etc, but this
is way beyond the scope of this article).</p>

<p>Having the series split into chunks also paves the way for some kind
of a caching layer, we could have a server which waits for one row
worth of data points to accumulate, then flushes then all at once.</p>

<p>For simplicity, let’s take the above example and expand the RRD to 4
weeks, while keeping 1 week per row. In our table definition we need
provide a way for keeping the order of every row of the TS with a
column named n, and while we’re at it, we might as well introduce a
notion of an id, so as to be able to store multiple TS in the same
table.</p>

<p>Let’s start with two tables, one called rrd where we would store the
last position and date, and another called ts which would store the
actual data.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">rrd</span> <span class="p">(</span>
</span><span class="line">  <span class="n">id</span> <span class="nb">SERIAL</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="k">PRIMARY</span> <span class="k">KEY</span><span class="p">,</span>
</span><span class="line">  <span class="n">last_date</span> <span class="nb">DATE</span><span class="p">,</span>
</span><span class="line">  <span class="n">last_pos</span> <span class="nb">INT</span><span class="p">);</span>
</span><span class="line">
</span><span class="line"><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">ts</span> <span class="p">(</span>
</span><span class="line">  <span class="n">rrd_id</span> <span class="nb">INT</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span>
</span><span class="line">  <span class="n">n</span> <span class="nb">INT</span> <span class="k">NOT</span> <span class="k">NULL</span><span class="p">,</span>
</span><span class="line">  <span class="n">dp</span> <span class="n">DOUBLE</span> <span class="k">PRECISION</span><span class="p">[]</span> <span class="k">NOT</span> <span class="k">NULL</span> <span class="k">DEFAULT</span> <span class="s1">&#39;{}&#39;</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>We could then populate the TS with fictitious data like so:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">rrd</span> <span class="p">(</span><span class="n">id</span><span class="p">,</span> <span class="n">last_date</span><span class="p">,</span> <span class="n">last_pos</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;2008-04-01&#39;</span><span class="p">,</span> <span class="mi">24</span><span class="p">);</span>
</span><span class="line">
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;{64,67,70,71,72,69,67}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;{65,60,58,59,62,68,70}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;{71,72,77,70,71,73,75}&#39;</span><span class="p">);</span>
</span><span class="line"><span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">ts</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;{79,82,90,69,75,80,81}&#39;</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>To update the data for April 2, we would:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="sql"><span class="line"><span class="k">UPDATE</span> <span class="n">ts</span> <span class="k">SET</span> <span class="n">dp</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="mi">92</span> <span class="k">WHERE</span> <span class="n">rrd_id</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">AND</span> <span class="n">n</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>
</span><span class="line"><span class="k">UPDATE</span> <span class="n">rrd</span> <span class="k">SET</span> <span class="n">last_date</span> <span class="o">=</span> <span class="s1">&#39;2008-04-02&#39;</span><span class="p">,</span> <span class="n">last_pos</span> <span class="o">=</span> <span class="mi">25</span> <span class="k">WHERE</span> <span class="n">id</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The last_pos of 25 is n * 7 + 1 (since arrays are 1-based).</p>

<p>This article omits a lot of detail such as having resolution finer
than one day, but it does describe the general idea. For an actual
implementation of this you might want to check out a project I’ve been
working on: <a href="https://github.com/tgres/tgres">tgres</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Time Series Accuracy - Graphite vs RRDTool]]></title>
    <link href="http://grisha.org/blog/2015/05/04/recording-time-series/"/>
    <updated>2015-05-04T17:40:00-04:00</updated>
    <id>http://grisha.org/blog/2015/05/04/recording-time-series</id>
    <content type="html"><![CDATA[<p>Back in my ISP days, we used data stored in RRDs to bill our
customers. I wouldn’t try this with Graphite. In this write up I try
to explain why it is so by comparing the method of recording time series
used by
<a href="http://graphite.readthedocs.org/en/latest/overview.html">Graphite</a>,
with the one used by <a href="https://oss.oetiker.ch/rrdtool/">RRDTool</a>.</p>

<p>Graphite uses
<a href="http://graphite.wikidot.com/whisper">Whisper</a> to store data, which in
the FAQ is portrayed as a <a href="http://graphite.wikidot.com/whisper#toc1">better alternative</a> to RRDTool, but
this is potentially misleading, because the flexibility afforded by the
design of Whisper comes at the price of inaccuracy.</p>

<p>A time series is most often described as a sequence of <code>(time, value)</code>
tuples [1]. The most naive method of recording a time series is to
store timestamps as is. Since the data points might arrive at
arbitrary and inexact intervals, to correlate the series with a
particular point in time might be tricky. If data points are arriving
somewhere in between one minute bounaries (as they always naturally
would), to answer the question of what happened during a particular
minute would require specifying a range, which is not as clean as
being able to specify a precise value. To join two series on a range
is even more problematic.</p>

<p>One way to improve upon this is to divide time into equal intervals
and assign data points to the intervals. We could then use the
beginning of the interval instead of the actual data point timestamp,
thereby giving us more uniformity. For example, if our interval size
is 10 seconds (I may sometimes refer to it as the <em>step</em>), we could
divide the entire timeline starting from the
<a href="http://en.wikipedia.org/wiki/Unix_time">beginning of the epoch</a>
and until the end of
universe into 10 second slots. Since the first slot begins at 0, any
10-second-step time series will have slots starting at the exact same
times. Now correlation across series or other time values becomes much
easier.</p>

<p>Calculating the slot is trivially easy: <code>time - time % step</code> (<code>%</code> being
the <a href="https://docs.python.org/3.4/reference/expressions.html#index-51">modulo operator</a>).
There is, however, a subtle complexity lurking when it comes to
storing the datapoint with the adjusted (or <em>aligned</em>) timestamp.
Graphite simply changes the timestamp of the data point to the
aligned one. If multiple data points arrive in the same
step, then the last one “wins”.</p>

<p>On the surface there is little wrong with Graphite’s approach. In fact,
under right circumstances, there is absolutely nothing wrong with
it. Consider the following example:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class=""><span class="line">Graphite, 10 second step.
</span><span class="line">
</span><span class="line">Actual Time   Aligned Time
</span><span class="line">1430701282    1430701280     50  &lt;-- This data point is lost
</span><span class="line">1430701288    1430701280     10
</span><span class="line">1430701293    1430701290     30
</span><span class="line">1430701301    1430701300     30</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Let’s pretend those values are some system metric like the number of
files open. The consequence of the 50 being dropped is that we will
never know it existed, but towards the end of the 10 second interval
it went down to 10, which is still a true fact. If we really wanted to
know about the variations within a 10 second interval, we should have
chosen a smaller step, e.g. 1 second. By deciding that the step is
going to be 10 seconds, we thus declared that <em>variations within a
smaller period are of no interest</em> to us, and from this perspective,
Graphite <em>is correct</em>.</p>

<p>But what if those numbers are the price of a stock: there may be
hundreds of thousand of trades within a 10 second interval, yet we do
not want to (or cannot, for technical reasons) record every single one
of them? In this scenario having the last value override all previous
ones doesn’t exactly seem correct.</p>

<p>Enter RRDTool which uses a different method. RRDTool keeps track of
the last timestamp and calculates a weight for every incoming
data point based on time since last update or beginning of the step and
the step length. Here is what the same sequence of points looks like
in RRDTool. The lines marked with a <code>*</code> are not actual data points,
but are the last value for the preceding step, it’s used for
computing the value for the remainder of the step after a new one has
begun.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
</pre></td><td class="code"><pre><code class=""><span class="line">RRDTool, 10 second step.
</span><span class="line">
</span><span class="line">  Time          Value       Time since  Weight  Adjusted   Recorded
</span><span class="line">                            last                value      value
</span><span class="line">  1430701270    0           N/A
</span><span class="line">* 1430701280    50         10s          1       50* 1= 50
</span><span class="line">                                                           50
</span><span class="line">  1430701282    50          2s          .2      50*.2= 10
</span><span class="line">  1430701288    10          6s          .6      10*.6= 6
</span><span class="line">* 1430701290    30          2s          .2      30*.2= 6
</span><span class="line">                                                           10+6+6= 22
</span><span class="line">  1430701293    30          3s          .3      30*.3= 9
</span><span class="line">* 1430701300    30          7s          .7      30*.7= 21
</span><span class="line">                                                           9+21=   30
</span><span class="line">  1430701301    30   # this data point is incomplete</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Note, by the way, that the Whisper FAQ says that “RRD will store your
updates in a temporary workspace area and after the minute has passed,
aggregate them and store them in the archive”, which to me sounds like
there is some sort of a temporary storage area holding all the unsaved
updates. In fact, to be able to compute the weighted average, RRD only
needs to store the time of the last update and the current sum, i.e.
exactly just two variables, regardless of the number of updates in a
single step. This is evident from the above figure.</p>

<p>So to compare the results of the two tools:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class=""><span class="line">Time Slot     Graphite    RRDTool
</span><span class="line">1430701270       N/A        50
</span><span class="line">1430701280       10         22
</span><span class="line">1430701290       30         30
</span><span class="line">1430701300       N/A        N/A
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Before you say “so what, I don’t really understand the difference”,
let’s pretend that those numbers were actually the rate of sale of
trinkets from our website (per second). Here is a horizontal ascii-art
rendition of our timeline, 0 is 1430701270.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class=""><span class="line">0         10        20        30    time (seconds)
</span><span class="line">+.........+.........+.........+.....
</span><span class="line">|           |     |    |       |
</span><span class="line">0           50    10   30      30   data points</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>At 12 seconds we recorded selling 50 trinkets per second. Assuming we
started selling at the beginning of our timeline, i.e. 12 seconds
earlier, we can state that during the first step we sold exactly 500
trinkets. Then 2 seconds into the second step we sold another 100
(we’re still selling at 50/s). Then for the next 6 seconds we were
selling at 10/s, thus another 60 trinkets, and for the last 2 seconds
of the slot we sold another 60 at 30/s. In the third step we were
selling steadily at 30/s, thus exactly 300 were sold.</p>

<p>Comparing RRDTool and Graphite side-by-side, the stories are quite different:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class=""><span class="line">Trinkets per second and sold:
</span><span class="line">   Time Slot     Graphite Trinkets     RRDTool Trinkets
</span><span class="line">1. 1430701270      N/A      N/A          50      500
</span><span class="line">2. 1430701280       10      100          22      220 (100+60+60)
</span><span class="line">3. 1430701290       30      300          30      300
</span><span class="line">4. 1430701300       30      N/A          N/A     N/A
</span><span class="line">                          -----                -----
</span><span class="line">   TOTAL SOLD:              400                 1020
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Two important observations here:</p>

<ol>
  <li>The totals are vastly different.</li>
  <li>The rate recorded by RRDTool for the second slot (22/s), yields
<em>exactly</em> the number of trinkets sold during that period: 220.</li>
</ol>

<p>Last, but hardly the least, consider what happens when we consolidate
data points into larger intervals by averaging the values. Let’s say
20 seconds, twice our step. If we consolidate the second and the third
steps, we would get:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class=""><span class="line">Graphite:  average(10,30) = 20  =&gt; 400 trinkets in 20 seconds
</span><span class="line">RRDTool:   average(22,30) = 26  =&gt; 520 trinkets in 20 seconds</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Since the Graphite numbers were off to begin with, we have no reason
to trust the 400 trinkets number. But using the RRDTool data, the new
number happens to still be 100% accurate even after the data points
have been consolidated. This is a very useful property of <em>rates</em> in
time series. It also explains why RRDTool does not permit updating
data prior to the last update: RRD is <em>always accurate</em>.</p>

<p>As an exercise, try seeing it for yourself: pretent the value of 10 in
the second step never arrived, which should make the final value of
the second slot 34. If the 10 arrived some time later, averaging it in
will not give you the correct 22.</p>

<p>Whisper allows past updates, but is quasi-accurate to begin with - I’m
not sure I understand which is better - <em>inaccurate</em> data with a data
point missing, or the <em>whole inaccurate</em> data. RRD could accomplish
the same thing by adding some <code>--inaccurate</code> flag, though it would
seem like more of a bug than a feature to me.</p>

<p>If you’re interested in learning more about this, I recommend reading
the documentation for
<a href="http://oss.oetiker.ch/rrdtool/doc/rrdcreate.en.html">rrdtool create</a>, in
particular the “It’s always a Rate” section, as well as
<a href="http://www.vandenbogaerdt.nl/rrdtool/process.php">this post</a>
by Alex van den Bogaerdt.</p>

<p>P.S. After this post was written, someone suggested that instead of
storing a rate, we coud store a <em>count delta</em>. In other words, instead
of recording that we’re selling 10 trinkets per second for the past 6
seconds, we would store the total count of trinkets sold, i.e. 60. At
first this seems like the solution to being able to update historical
data accurately: if later we found out that we sold another 75
trinkets in the second time slot, we could just add it to the total
and all would be well and most importantly <em>accurate</em>.</p>

<p>Here is the problem with this approach: note that in the previous
sentence I had to specify that the additional trinkets were sold <em>in
the second time slot</em>, a small, but crucial detail. If time series
data point is a timestamp and a value, then there isn’t even a way to
relay this information in a single data point - we’d need two
timestamps. On the other hand if every data point arrived with two
timestamps, i.e. as a duration, then which to store, rate or count,
becomes a moot point, we can infer one from the other.</p>

<p>So perhaps another way of explaining the historical update problem is
that it <em>is</em> possible, but the datapoint must specify a <em>time
interval</em>. This is something that neither RRDTool or Graphite
currently support, even though it’d be a very useful feature in my
opinion.</p>

<p>[1] Perhaps the biggest misconception about time series is that it is
a series of data points. What time series represent is <em>continuous</em>
rather than <em>descrete</em>, i.e. it’s the line that connects the points
that matters, not the specific points themselves, they are just
samples at semi-random intervals that help define the line. And as we
know, a line cannot be defined by a single point.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Time Series]]></title>
    <link href="http://grisha.org/blog/2015/03/28/on-time-series/"/>
    <updated>2015-03-28T15:40:00-04:00</updated>
    <id>http://grisha.org/blog/2015/03/28/on-time-series</id>
    <content type="html"><![CDATA[<h2 id="is-it-even-a-thing">Is it even a thing?</h2>

<p>Time Series is on its way to becoming a buzzword in the Information
Technology circles. This has to do with the looming Internet of Things
which shall cause the Great Reversal of Internet whereby upstream flow
of data produced by said Things is expected to exceed the downstream
flow. Much of this data is expected to be of the Time Series kind.</p>

<p>This, of course, is a money-making opportunity of the Big Data
proportions all over again, and I predict we’re going to see a lot of
Time Series support of various shapes and forms appearing in all
manners of (mostly commercial) software.</p>

<p>But is there really such a thing as the problem specifically inherent
to Time Series data which warrants a specialized solution? I’ve been
pondering this for some time now, and I am still undecided. This
here is my attempt at arguing that TS is <em>not</em> a special problem and
that it can be done by using a database like PostgreSQL.</p>

<h2 id="influx-of-data-and-write-speeds">Influx of data and write speeds</h2>

<p>One frequently cited issue with time series data is that it arrives in
large volumes at a steady pace which renders buffered writes
useless. The number of incoming data streams can also be large
typically causing a disk seek per stream and further complicating the
write situation. TS data also has a property where often more data is
written than read because it’s possible for a datapoint to be
collected and examined only once, if ever. In short, TS is very
write-heavy.</p>

<p>But is this unique? For example logs have almost identical
properties. The real question here is whether our tried and true
databases such as PostgreSQL are ill-equipped to deal with large
volumes of incoming data requiring an alternative solution.</p>

<p>When considering incoming data I am tempted to imagine every US
household sending it, which, of course, would require massive
infrastructure. But this (unrealistic) scenario is not a TS data
problem, it’s one of scale, the same one from which the Hadoops and
Cassandras of this world were born. What is really happening here is
that TS happens to be yet another thing that requires the difficult to
deal with “big data” infrastructure and reiterates the need for an
easy-to-setup horizontally scalable database (which PostgreSQL isn’t).</p>

<h2 id="the-backfill-problem">The backfill problem</h2>

<p>This is the problem of having to import vast amounts of historical
data. For example OpenTSDB goes to great lengths to optimize
back-filling by structuring it in specific ways and storing compressed
blobs of data.</p>

<p>But just like the write problem, it’s not unique to TS. It
is another problem that is becoming more and more pertinent as our
backlogs of data going back to when we stopped using paper keep
growing and growing.</p>

<h2 id="downsampling">Downsampling</h2>

<p>Very often TS data is used to generate charts. This is an artifact of
the human brain being spectacularly good at interpreting a visual
representation of a relationship between streams of numbers while
nearly incapable of making sense of data in tabular form. When
plotting, no matter how much data is being examined, the end result is
limited to however many pixels are available on the display. Even
plotting aside, most any use of time series data is in an aggregated
form.</p>

<p>The process of consolidating datapoints into a smaller number (e.g.
the pixel width of the chart), sometimes called <em>downsampling</em>, involves
aggregation around a particular time interval or simply picking every
Nth datapoint.</p>

<p>As an aside, selecting every Nth row of a table is an interesting SQL
challenge, in PostgreSQL it looks like this (for every 100th row):</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class=""><span class="line"> SELECT time, data FROM
</span><span class="line">   (SELECT *, row_number() OVER (ORDER BY time) as n FROM data_points) dp
</span><span class="line">      WHERE dp.n % 100 = 0 ORDER BY time</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Aggregation over a time interval similar to how InfluxDB does it with
the <code>GROUP BY time(1d)</code> syntax can be easily achieved via the
<code>date_trunc('day', time)</code>.</p>

<p>Another aspect of downsampling is that since TS data is immutable,
there is no need to repeatedly recompute the consolidated version. It
makes more sense to downsample immediately upon the receipt of the
data and to store it permanently in this form. RRDTool’s Round-Robin
database is based entirely on this notion. InfluxDB’s continuous
queries is another way persistent downsampling is addressed.</p>

<p>Again, there is nothing TS-specific here. Storing data in summary form
is quite common in the data analytics world and a “continuous query”
is easily implemented via a trigger.</p>

<h2 id="derivatives">Derivatives</h2>

<p>Sometimes the data from various devices exists in the form of a
counter, which requires the database to derive a rate by comparing
with a previous datapoint. An example of this is number of bytes sent
over a network interface. Only the rate of change of this value is
relevant, not the number itself. The rate of change is the difference
with the previous value divided over the time interval passed.</p>

<p>Referring to a previous row is also a bit tricky but perfectly doable
in SQL. It can accomplished by using windowing functions such as
<code>lag()</code>.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class=""><span class="line">SELECT time,
</span><span class="line">  (bytes - lag(bytes, 1) OVER w) / extract(epoch from (time - lag(time, 1) OVER w))::numeric
</span><span class="line">    AS bytes_per_sec
</span><span class="line">  FROM data_points
</span><span class="line">  WINDOW w AS (ORDER BY time)
</span><span class="line">  ORDER BY time</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="expiration">Expiration</h2>

<p>It is useful to downsample data to a less granular form as it ages,
aggregating over an ever larger period of time and possibly purging
records eventually. For example we might want to store minutely data
for a week, hourly for 3 months, daily for 3 years and drop all data
beyond 3 years.</p>

<p>Databases do not expire rows “natively” like Cassandra or Redis, but it
shouldn’t be too hard to accomplish via some sort of a periodic cron
job or possibly even just triggers.</p>

<h2 id="heartbeat-and-interval-filling">Heartbeat and Interval Filling</h2>

<p>It is possible for a time series stream to pause, and this can be
interpreted in different ways: we can attempt to fill in missing data,
or treat it as unknown. More likely we’d want to start treating it as
unknown after some period of silence. RRDTool addresses this by
introducing the notion of a <em>heartbeat</em> and the number of missed beats
before data is treated as unknown.</p>

<p>Regardless of whether the value is unknown, it is useful to be able to
fill in a gap (missing rows) in data. In PostgreSQL this can be
accomplished by a join with a result set from the <code>generate_series()</code>
function.</p>

<h2 id="data-seclusion">Data Seclusion</h2>

<p>With many specialized Time Series tools the TS data ends up being
secluded in a separate system not easily accessible from the rest of
the business data. You cannot join your customer records with data in
RRDTool or Graphite or InfluxDB, etc.</p>

<h2 id="conclusion">Conclusion</h2>

<p>If there is a problem with using PosgreSQL or some other database for
Time Series data, it is mainly that of having to use advanced SQL
syntax and possibly requiring some cookie-cutter method for managing
Time Series, especially when it is a large number or series and high
volume.</p>

<p>There is also complexity in horizontally scaling a relational database
because it involves setting up replication, sharding, methods for
recovery from failure and balancing the data. But these are not
TS-specific problems, they are scaling problems.</p>

<p>Having written this up, I’m inclined to think that perhaps there is
no need for a specialized “Time Series Database”, instead it can be
accomplished by an application which uses a database for storage and
abstracts the users from the complexities of SQL and potentially even
scaling, while still allowing for direct access to the data via the
rich set of tools that a database like PostgreSQL provides.</p>

]]></content>
  </entry>
  
</feed>
